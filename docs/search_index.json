[["index.html", "Utrecht Summer School S23 Advanced course on using Mplus Course", " Utrecht Summer School S23 Advanced course on using Mplus Jeroen D. Mulder, Ellen L. Hamaker, Noémi Schuurman, and Caspar J. van Lissa July 11th - 15th, 2022 Course This course material is part of the Advanced course on using Mplus, a five-day summer school course hosted by Utrecht University’s department of Methodology and Statistics. If you already know how to analyse your data in Mplus but want to learn more about what you are actually doing, and especially if you want to know more about advanced longitudinal analyses, this course is for you. The course consists of in-depth lectures on the fundamentals of Mplus and advanced longitudinal models. "],["day-1-mplus-and-the-lisrel-model.html", "1 Day 1: Mplus and the LISREL model", " 1 Day 1: Mplus and the LISREL model These exercises are for day 1 of S23. In the first exercise we investigate measurement invariance, while in the second exercise the focus is on path analysis. You can choose which of these you want to focus on, and start with that. In both exercises we will focus on: a) determining the number of degrees of freedom (df) by counting the number of sample statistics (i.e., unique pieces of information in our data) and the number of free parameters; and b) checking the TECH1 output to see where the free parameters are in the diverse underlying model matrices. You can navigate through these excises by using the left-hand menu or the arrows on left- and right-hand side of this screen. Answers are included below each exercise in a drop down option. The data and Mplus input files can found in the SURFdrive folder. "],["measurement-invariance.html", "Measurement invariance", " Measurement invariance Measurement invariance is important if we want to compare individuals from different groups, or the means of different groups. Measurement invariance implies that two individuals from different groups who have the same latent score, have the same expected observed scores. It also means that if there are observed mean differences between two groups, these can only stem from latent mean differences. When measurement invariance does not hold, we call the test (i.e., measurement instrument) biased. We may then look for the source of the bias, and try to account for this in our analyses. Here we will show how to specify a sequence of models to test whether measurement invariance holds. These steps include: configural invariance; this implies the same model in each group without any constraints across the groups weak factorial invariance; this implies the factor loadings are constrained across the groups to be the same strong factorial invariance; this implies the factor loadings and the intercepts are constrained to be the same across the groups, while the latent means in the second (and subsequent) group(s) are allowed to be estimated freely Getting started We start with drawing the model as a path diagram. The data come from: Sabatelli, R. M., and Bartle-Haring (2003). Family-of-origin and adjustment in married couples. Journal of Marriage and Family, 65, 159-169. https://doi.org/10.1111/j.1741-3737.2003.00159.x They obtained measures from 103 married couples regarding their marital adjustment and their family of origin. Here we analyze these data using a multiple group approach, although the individuals in the two groups are not independent of each other, and there are other approaches that would be more appropriate for this (such as described in the original paper, where the cases are couples, and the data of each couple consists of variables measured in the hubsand and other variables are measured in the wives). The variables included are: Satisfaction (S): higher levels imply fewer complaints Intimacy (I): higher scores imply more self-disclosures, experiences of empathy and affection, and feelings of emotional closeness toward the marital partner Father (F): higher scores imply a better relationship between the participant and his/her father Mother (M): higher scores imply a better relationship between the participant and his/her mother Father-mother (FM): higher scores a better relationship between the parents of the participant The idea is that the first two variables measure Marital Adjustment (MA) and the latter three variables measure the quality of relationships in the Family of Origin (FO). Furthermore, it is assumed that FO is a predictor of MA. Question 1 Draw the path diagram for this structural equation model. Click to show answers Measurement part of the model: S and I are indicators of MA; F, M, and FM are indicators of FO. Structural part of the model: MA is regressed on FO. Before doing the actual model that includes the structural relation between the latent variables, we start with only the measurement model; this means that we specify a two-factor model in which the latent variables are allowed to covary (i.e., a two-headed arrow between MA and FO). We use this model to investigate whether strong factorial invariance holds by testing whether the assumptions of this model hold. Question 2 The data for this exercise are included in the file named Family.dat; note it only contains the summary statistics, that is, it contains the means, standard deviations, and correlation matrices for each group (men first, then women), that were printed in the original paper. Have a look at these. Click to show answers You can open the data either in Mplus, or with a program like notepad. This is what you see: 161.779 138.382 86.229 86.392 85.046 32.936 22.749 13.390 13.679 14.382 1 .740 1 .265 .422 1 .305 .401 .791 1 .315 .351 .662 .587 1 155.547 137.971 82.764 85.494 81.003 31.168 20.094 11.229 11.743 13.220 1 .658 1 .288 .398 1 .171 .295 .480 1 .264 .305 .554 .422 1 Question 3 Typically when you have data, you will have the raw data. In that case you will have the observed variables and a grouping variable in one file. See example 5.14 in the Mplus Users Guide for how to specify the DATA and VARIABLE commands in that case. Here we only have the summary data. To specify the DATA and VARIABLE commands in this case, use: DATA: NGROUPS ARE 2; TYPE IS MEANS STD CORR; FILE IS Family.dat; NOBSERVATIONS ARE 103 103; VARIABLE: NAMES ARE S I F M FM; We will begin with using the automatic option in Mplus that allows us to run all three models that are needed to investigate measurement invariance. This can be done by adding: ANALYSIS: MODEL = CONFIGURAL METRIC SCALAR; where CONFIGURAL is the model without any constraints across the groups; METRIC is the model we refer to as weak factorial invariance, that is, equal factor loadings across groups; and SCALAR is what we refer to as strong factorial invariance, that is, equal factor loadings and intercepts across groups, and freely estimated latent means in group 2 (and subsequent groups, if there are any). Use the code above, and add: TITLE command MODEL command, in which you just specify the general factor model (so no need to specify separate models for separate groups!) OUTPUT command Run the model and check the output. Describe what you see. Click to show answers In the top menu in Mplus you can change the format of the output file by going to Mplus and choosing HTML output, and then run the model. This will result in output with links that makes it easier to navigate through it. At the beginning of the output, you get to see: OUTPUT SECTIONS Input Instructions Input Warnings And Errors Summary Of Analysis Sample Statistics Model Fit Information - For The Configural Model - For The Metric Model - For The Scalar Model Model Results - For The Configural Model - For The Metric Model - For The Scalar Model Technical 1 Output - For The Configural Model - For The Metric Model - For The Scalar Model Technical 9 Output Hence, we see that for each of the three models we get information about model fit, we get the parameter estimates, and the additional output (here, we asked for TECH1). We also get TECH9 which contains the warnings for the three models. While this automatic option is of course very convenient in practice, we will now focus in this exercise on how to specify and run these three models ourselves. The point of this is that we see how we can overrule defaults in Mplus, and we consider the models one by one (and check the TECH1 output), and consider alternative ways of scaling these models. Step 1: Configural invariance Question 4 If we specify the model for configural invariance: how many sample statistics are there? how many free parameters are there? how many df are there? Click to show answers Sample statistics. We have 5 observed variables in each group. Hence, we have 5*6/2 = 15 unique elements in the covariance matrix S for each group, plus 5 observed means, so 20 sample statistics per group. That makes 40 sample statistics in total. Free parameter. In each group we estimate: 3 factor loadings (there are 5 factor loadings, but 2 are used for scaling) 2 factor variances 1 factor covariance 5 residual variances 5 intercepts That makes 16 parameters per group; hence, 32 free parameters in total. Degrees of freedom. The degrees of freedom are therefore: df = 40-32=8. Question 5 Specify the two-factor model for configural invariance. Click to show answers MODEL: MA BY S I; FO BY F M FM; MODEL g2: MA BY S@1 I; FO BY F@1 M FM; [S I F M FM]; [MA@0 FO@0]; where the first MODEL: command is the general model specification, and the second part MODEL g2; is overruling the multiple group factor analysis defaults through: freeing the factor loadings (so they are not identical to the factor loadings in g1), and using @1 to ensure the factors are scaled freeing the intercepts in the second group (so they are not identical to the intercepts in g1) fixing the latent means to zero (to ensure identification) Alternatively, one could also say: MODEL: MA BY S I; FO BY F M FM; MODEL g2: MA BY I; FO BY M FM; [S I F M FM]; [MA@0 FO@0]; Here, we are doing the same thing, but not overruling the default for the factor loadings of the first indicator of each latent variable (hence the initial scaling remains in tact). In addition to this MODEL command, we specify the OUTPUT command as: OUTPUT: TECH1 MOD(4); Question 6 Run this model, and check whether the TECH1 output matches your answer under Question 4 regarding where the free parameters are. Also check the warning(s); is there a reason for concern? Click to show answers We get this warning: THE MODEL ESTIMATION TERMINATED NORMALLY WARNING: THE RESIDUAL COVARIANCE MATRIX (THETA) IN GROUP G1 IS NOT POSITIVE DEFINITE. THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR AN OBSERVED VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE BETWEEN TWO OBSERVED VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO OBSERVED VARIABLES. CHECK THE RESULTS SECTION FOR MORE INFORMATION. PROBLEM INVOLVING VARIABLE I. This implies that the residual covariance matrix contains a combination of numbers (i.e., parameter estimates) that are not possible in a covariance matrix. We can start with checking the relevant parameter estimates in the first group: Residual Variances S 528.470 130.512 4.049 0.000 I -39.883 109.198 -0.365 0.715 F 21.613 10.983 1.968 0.049 M 53.509 11.710 4.570 0.000 FM 103.074 16.168 6.375 0.000 It shows that the residual variance for the indicator I (intimacy) is negative; this is not possible (as variances are by definition zero or larger). This is referred to as a Heywood case, and is typically interpreted as meaning that the model is too complicated for the data (for instance because the model is really wrong, or because the sample size is too small). I is an indicator of MA, which only has one other indicator (i.e., S); this is often a difficult situation in terms of estimation. One action we could take is setting this residual variance to zero (note the parameter is not significantly different from zero). That would mean this variable is a perfect indicator of the latent variable MA, as there would be no measurement error at all; this would in turn mean we only need this indicator, and there is no need for the second indicator to measure the latent variable. But for now, we will just leave the variable in, and consider the model fit before moving on to testing weak factorial invariance. Question 7 For now, we ignore this warning. What is the model fit? Click to show answers Chi-Square Test of Model Fit Value 6.025 Degrees of Freedom 8 P-Value 0.6444 The chi-square test indicates the model fits well (note btw that the degrees of freedom are indeed 8). We see this chi-square is simply the sum of the chi-squares that are obtained for each group, as presented in the output: Chi-Square Contribution From Each Group G1 4.688 G2 1.337 The other fit measures also indicate the model fits very well: RMSEA (Root Mean Square Error Of Approximation) Estimate 0.000 90 Percent C.I. 0.000 0.095 Probability RMSEA &lt;= .05 0.786 CFI/TLI CFI 1.000 TLI 1.000 SRMR (Standardized Root Mean Square Residual) Value 0.019 Step 2: Weak factorial invariance Question 8 Next, specify the model for weak factorial invariance. How many df would this model have? Run this model and report on the model fit. Click to show answers In the model for weak factorial invariance, we set the factor loadings invariant across groups, while not constraining the mean structure. In practice, this implies we no longer have to overrule the defaults for the factor loadings, but we still need to overrule the defaults for the intercepts and latent means. Hence, the model specification becomes: MODEL: MA BY S I; FO BY F M FM; MODEL g2: [S I F M FM]; [MA@0 FO@0]; While in the previous model we were estimating 3 factor loadings in each group (so 6 factor loadings in total), we now estimate 3 factor loadings for both groups. Hence, this model has 3 free parameters less, and thus 3 df more than the model for configural invariance; the df should thus be 8+3=11. This also becomes clear when looking at the TECH1 output of this model (see the numbers that identify the free parameters in the matrix LAMBDA). We see this in the chi-square test: Chi-Square Test of Model Fit Value 8.735 Degrees of Freedom 11 P-Value 0.6463 We see indeed the number of df is 11. Question 9 Do a chi-square difference test to determine whether the assumption of weak factorial invariance (i.e., equal factor loadings across groups) holds. Click to show answers \\(\\Delta \\chi^2 = 8.735 - 6.025 = 2.710\\) \\(\\Delta df = 11 - 8 = 3\\) Hence, the chi-square difference is 2.710 with df=3. The p-value for this is 0.4385 (for an online chi-square calculator, see for instance: https://www.fourmilab.ch/rpkp/experiments/analysis/chiCalc.html). This means that our H0 (i.e., weak factorial invariance) is not rejected. Put differently, the constraints for weak factorial invariance can be imposed. Step 3: Strong factorial invariance Question 10 Next, specify the model for strong factorial invariance. Again, indicate how many df this model will have, run the model, and report on the model fit. Click to show answers Strong factorial invariance is the default multiple group factor model that Mplus runs. Hence, it does not require us to overrule any of its defaults. Compared to the previous model, this means that it will constrain all five intercepts to be identical across the two groups, but at the same time, it will freely estimate the two latent means in the second group. Hence, the difference in df is 5-2=3; the new model with have 3 df more than the one we had before. The MODEL command for this model is very simple; we only need: MODEL: MA BY S I; FO BY F M FM; The chi-square of this model is: Chi-Square Test of Model Fit Value 15.647 Degrees of Freedom 14 P-Value 0.3354 We see that indeed the df are 3 more than before (11+3=14). Exercise 11 Do a chi-square difference test to determine whether the assumption of strong factorial invariance (i.e., equal intercepts; only latent mean differences) holds. Click to show answers We compare the current model fit to that of the previous model (i.e., the one for weak factorial invariance), to determine whether the additional constraints are tenable. Hence we have: \\(\\Delta \\chi^2 = 15.647 - 8.735 = 6.912\\) \\(\\Delta df = 14 - 11 = 3\\) A chi-square difference test of 6.912 with 3 df has a p-value of 0.0748. Hence, again, the H0 is not rejected, which now means we can assume that strong factorial invariance holds. Exercise 12 Check the TECH1 output for the latter model. How do you see the constraints that were imposed? Click to show answers You can see the intercepts and factor loadings are constrained across the two groups, because the same numbers are used to show which ones are estimated freely: NU S I F M FM ________ ________ ________ ________ ________ 1 2 3 4 5 LAMBDA MA FO ________ ________ S 0 0 I 6 0 F 0 0 M 0 7 FM 0 8 Alternative way of scaling Above, we have used the usual way of scaling: first factor loading of each latent variable fixed to 1 (in each group) all latent means fixed to 0 (in each group), combined with estimating the intercepts for the observed variables freely (in each group) In this case, the step from configural to weak factorial invariance now consists of only adding more constraints, which makes it easy to see these two models are nested (i.e., the model for weak factorial invariance is nested under the model for configural invariance). However, it is less obvious that the model for strong factorial invariance is nested under the model for weak factorial invariance, because it includes constraining parameters (i.e., the intercepts have to be equal across groups), but also requires freeing parameters (i.e., the latent means in the second group are freed). To ensure that these models are nested, we use an alternative way of specifying these models, based on a different way of scaling. The key issue here is that these alternative model specification are simply reparameterizations of the the same models; they are equivalent models, as we can see because they lead to the exact same model fit. Question 13 Instead of scaling with the latent means fixed to zero and the intercepts all estimated freely, scale the latent variable in the model for configural invariance through setting the intercept for the first indicator to zero, while allowing the latent mean to be estimated freely. Compare the model fit to the one obtained above for the configural invariance model. Click to show answers The MODEL command can be specified as: MODEL: MA BY S I; FO BY F M FM; MODEL g1: [S@0 F@0]; [MA FO]; MODEL g2: MA BY S@1 I; FO BY F@1 M FM; [S@0 I F@0 M FM]; When running the model like this, it does not converge within the default number of iterations. We get this message NO CONVERGENCE. NUMBER OF ITERATIONS EXCEEDED. and there is no model fit, standard errors, or p-values. This can mean the model is too complicated. It can also mean you need to specify (better) starting values. As a first step, we can just increase the number of iterations, by adding: ANALYSIS: ITERATIONS ARE 20000; In this case, this solves it, that is, the model now converges. When considering the model fit, we see it is exactly the same as that of the model discussed in Question 7. Chi-Square Test of Model Fit Value 6.025 Degrees of Freedom 8 P-Value 0.6444 Because the chi-square is exactly the same (and the df), this implies these models are statistically equivalent; they are identical, just parameterized differently. You cannot distinguish between them on statistical grounds. Hence, this shows that this alternative way of scaling the latent variables gives a model that is equivalent. Question 14 Next, use this alternative way of scaling and specify the model for weak factorial invariance. Click to show answers The MODEL command can be specified as: MODEL: MA BY S I; FO BY F M FM; MODEL g1: [S@0 F@0]; [MA FO]; MODEL g2: [S@0 I F@0 M FM]; That is, we no longer overrule the defaults for the factor loadings. Note that for this model to converge, we do not need to increase the number of iterations. When considering the model fit, we see it is exactly the same as that of the model discussed in Question 8: Chi-Square Test of Model Fit Value 8.735 Degrees of Freedom 11 P-Value 0.6463 This means that the current model is statistically equivalent to the model we had before to impose weak factorial invariance. Question 15 And now, the Moment Suprême: We will specify the model for strong factorial invariance using this alternative way of scaling. The key issue to notice here is that in going from weak factorial invariance to strong factorial invariance, we will now only add constraints, which makes it very clear that the latter model must be nested under the former. Remember that before, we were adding constraints (i.e., fixing the intercepts to be identical across the groups), but also were freeing parameters (i.e., allowing the latent means in the second group to be estimated freely); this makes it difficult to see that the model for strong factorial invariance is nested under that of weak factorial invariance. But with this alternative way of scaling, which leads to statistically equivalant models (i.e., models with the exact fit, and which are thus indistinguishable), we now only add constraints on parameters when going from weak to strong factorial invariance, such that it is very obvious that (and how) they are nested. Specify the model for strong factorial invariance using this alternative way of scaling. Click to show answers The MODEL command can be specified as: MODEL: MA BY S I; FO BY F M FM; MODEL g1: [S@0 F@0]; [MA FO]; MODEL g2: [S@0 F@0]; This model leads to the exactly same model fit as that of the model discussed in Question 10: Chi-Square Test of Model Fit Value 15.647 Degrees of Freedom 14 P-Value 0.3354 This means that the current model is statistically equivalent to the model we had before to impose strong factorial invariance. This also means that we can now be certain that the model for strong factorial invariance is nested under the model for weak factorial invariance; this means we can do a chi-square difference test to compare them (as we already did above). Question 16 While this alternative way of specifying the series of models is useful to seeing their nestedness, the first way of specifying the models also has advantages. One of these advantages is that it requires fewer defaults to be overruled. But more importantly, it allows us to easily determine in the strong factorial invariance model whether there are latent mean differences between the groups. Report and interpret these. Click to show answers In the first approach, the model for strong factorial invariance is based on constraining the factor loadings and intercepts across the groups, and freeing the latent means in the second group, while the means in the first group are fixed to zero. That is, for G1 we get: Means MA 0.000 0.000 999.000 999.000 FO 0.000 0.000 999.000 999.000 and for G2 we get: Means MA -0.415 3.118 -0.133 0.894 FO -3.140 1.655 -1.898 0.058 This implies that the significance test of the latter can be used to determine whether there are latent mean differences between the second and the first group. Here we get a p-value of 0.894 for MA, and a p-value of 0.058 for FO; hence for both we do not find evidence that they differ from zero, which means that for both we do not find evidence that the two groups differ. Full model As both the test for weak and for strong factorial invariance were non-significant, we can conclude that strong factorial invariance holds. This means we can compare individuals from these groups, and we can compare the means of these groups. It also means that the constructs “Marital Adjustment” and “Family of Origin” are measured in the same way in these two groups, and that we can specify a structural model for these latent variables in the two groups to investigate how they are related. Question 17 Specify the model as initially intended, with FO as a predictor of MA at the latent level, while assuming strong factorial invariance. Click to show answers The model is now specified as: MODEL: MA BY S I; FO BY F M FM; MA ON FO; Question 18 Run this model, and compare the model fit to that of the model for strong factorial invariance that we had before. What do you conclude? Click to show answers These models have the exact same model fit (same chi-square and df). This means these models are statistically equivalent. Hence, it does not matter whether you estimate the covariance between the two latent variables, or a regression coefficient. Question 19 When comparing the TECH1 output of these two models, what difference do you spot? Click to show answers In the two-factor model we have for G1: BETA MA FO ________ ________ MA 0 0 FO 0 0 PSI MA FO ________ ________ MA 14 FO 15 16 that is, no structural parameters, and a covariance is Psi; in contrast in the regression model we have for G1: BETA MA FO ________ ________ MA 0 14 FO 0 0 PSI MA FO ________ ________ MA 15 FO 0 16 showing there is a structural parameter in Beta (going to MA, coming from FO), and there is no covariance estimated in Psi. The same is true for G2. Question 20 As a final step, we want to investigate whether the regression coefficient is different in the two groups or not. How can you investigate this? Click to show answers In the model above, the regression parameter was not constrained across the groups. We can now specify a model in which we constrain the parameter to be invariant across the two groups; that model will be nested under the previous model, and we can thus do a chi-square difference test to see whether the constraint holds. To constrain the parameter across the groups, we only have to give it a label (i.e., a name). Here we will give it the label c (you could als give it a longer name, such as coeff). The model is now specified as: MODEL: MA BY S I; FO BY F M FM; MA ON FO (c); To see that this leads to having the same regression coefficient in both groups, we can check the TECH1 output. For G1 we have (only showing part of it): ALPHA MA FO ________ ________ 0 0 BETA MA FO ________ ________ MA 0 14 FO 0 0 PSI MA FO ________ ________ MA 15 FO 0 16 and for G2: ALPHA MA FO ________ ________ 22 23 BETA MA FO ________ ________ MA 0 14 FO 0 0 PSI MA FO ________ ________ MA 24 FO 0 25 It shows that the structural parameter in both cases is the same parameter (number 14). The model fit is: Chi-Square Test of Model Fit Value 16.315 Degrees of Freedom 15 P-Value 0.3614 showing it has 1 df more than the model we had before (because we estimate 1 parameter less). Doing a chi-square difference test we get: \\(\\Delta \\chi^2 = 16.315 - 15.647 = 0.688\\) with \\(df-1\\), which gives a p-value of 0.4137, which means the test is not significant. Hence, H0 does not have to be rejected, and we can therefore assume that the regression coefficient is identical across the two groups. Conclusion To summarize what we did in this exercise: we were interested in investigating a full SEM model (with both a measurement model and a structural model), in two groups before we could investigate the structural part of the model (i.e., the latent regression), we had to determine whether there was measurement invariance across the groups to this end we ran a series of three models: configural invariance, weak factorial invariance and strong factorial invariance; these models are increasingly more restrictive, and we compared each subsequent model with the preceding one (using a chi-square different test) to see whether the additional constraints were tenable since neither of the two chi-square difference test reached significance, we can conclude that strong factorial invariance holds; this means we are measuring the same constructs in both groups, and we can compare their latent means we also considered an alternative way to scale the models (based on setting one of the intercepts per factor to zero, rather than the latent means), which more clearly shows that the model for strong factorial invariance is a special case of the model for weak factorial invariance the first way of scaling has the advantage that we can immediately see whether the means of the two groups on the latent variables differ or not; here we found no significant difference since the latent variables are measured in the same way in both groups, we continue with our actual research question, which concerns the latent regression model; regressing the latent variables on each other resulted in a model that is equivalent to the model for strong factorial invariance subsequently, we constrained the regression coefficient across the two groups to see whether the effect of family of origin (FO) has the same effect on marital adjustment (MA) in the two groups; again, by doing a chi-square difference test we could determine whether or not this constraint was tenable; since the test was not significant, we may assume that the two regression slopes are the same across the groups note that in the end, we still have the same warning as for the first model about a Heywood case (negative variance) in the first group; we should present such results in a paper; we could constrain this variance to zero (and we could do the same thing in the other group, because it is not significantly different from zero there either), which would make this indicator and the latent variable it measures identical; put differently, this implies that we can measure marital adjustment with this one variable, and we do not need the other one for it "],["path-analysis.html", "Path analysis", " Path analysis In this exercise, we consider a path model in which observed variables are regressed on each other. The data come from the paper: Hale, W. W., Van der Valk, I., Engels, R., and Meeus, W. (2005). Does perceived parental rejection make adolescents sad and mad? The association of perceived parental rejection with adolescent depression and aggression. –Journal of Adolescent Health, 36_, 466-474. https://doi.org/10.1016/j.jadohealth.2004.04.007 We collected the means, standard deviations, and correlation matrix from that paper for the group of older boys (n=275) in the file BoysDep.dat. We have the following four variables (in this order): perceived parental rejection (PPR) adolescent depression (AD) adolescent aggression (AA) adolescent withdrawal (AW) The model that the researchers proposed, is presented below: Their question is whether perceived parental rejection (meaning the adolescent feels rejected by the parents), leads adolescents to feel sad (as operationalized with adolescent withdrawal), or mad (as operationalized with adolescent aggression), and to what extent these effects are mediated through adolescent depression. The path model proposed by Hale et al. (2005) Question 1 Determine: a) how many sample statistics there are; b) how many free parameters there are: and c) how many degrees of freedom this model has. Click to show answers There are four observed variables, so 4*5/2 = 10 unique elements in the covariance matrix S, and 4 observed means; that makes 14 sample statistics in total. The number of free parameters in this model are: 1 variance of the exogenous variable (PPR), 3 residual variance of the endogenous variables (AD, AA and AW), 5 structural parameters (i.e., regression coefficients), 1 mean for the exogenous variable (PPR), and 3 intercepts for the endogenous variables (AD, AA, and AW). That makes 13 free parameters in total. The number of degrees of freedom should therefor equal 14-13=1. Question 2 To specify the above model, make use of this code for the DATA command: DATA: TYPE IS MEANS STDEVIATIONS CORRELATION; FILE = BoysDep.dat; NOBSERVATIONS = 275; Note that when we have summary data, we have to tell Mplus how many observations there are, because it is not possible to know this in any other way. Also, make use of this code for the MODEL command: MODEL: AD ON PPR; AA ON AD PPR; AW ON AD PPR; Finish the code and run the model. Consider the model fit results: Do they make sense to you? Click to show answers Below are the two most notable parts of the model fit output. MODEL FIT INFORMATION Number of Free Parameters 12 ... Chi-Square Test of Model Fit Value 0.000 Degrees of Freedom 0 P-Value 0.0000 It indicates that there are 12, rather than 13, free parameters, and that there are 0, rather than 1, degree of freedom. At first sight, this makes no sense: 12+0=12, but this should equal the number of sample statistics, which we determined is 14. Question 3 There are actually two things going on at once here. Check the TECH1 output to see whether you can figure out what the two issues are. Click to show answers Considering the first three matrices in `TECH1: TECHNICAL 1 OUTPUT PARAMETER SPECIFICATION NU AD AA AW PPR ________ ________ ________ ________ 0 0 0 0 LAMBDA AD AA AW PPR ________ ________ ________ ________ AD 0 0 0 0 AA 0 0 0 0 AW 0 0 0 0 PPR 0 0 0 0 THETA AD AA AW PPR ________ ________ ________ ________ AD 0 AA 0 0 AW 0 0 0 PPR 0 0 0 0 These three matrices are associated with the measurement equation and contain no free parameters for a path model. Consider the second set of three model matrices: ALPHA AD AA AW PPR ________ ________ ________ ________ 1 2 3 0 BETA AD AA AW PPR ________ ________ ________ ________ AD 0 0 0 4 AA 5 0 0 6 AW 7 0 0 8 PPR 0 0 0 0 PSI AD AA AW PPR ________ ________ ________ ________ AD 9 AA 0 10 AW 0 11 12 PPR 0 0 0 0 Here we see where the free parameters are (adding up to 12, which was the number indicated in the Mplus output). There are three things to notice here: the order of the variables has been changed by Mplus, and the exogenous variable PPR is placed at the end in these matrices; this may be somewhat inconvenient when looking at these matrices, but is not a problem the mean and the variance for this exogenous variable are not counted as free parameters; this is because they are exactly the same as the observed mean and variance, which in turn are not counted as sample statistics (hence, the free parameters + df add up to 12 rather than 14); while this does not affect model fit here, we can decide to overrule this, asking for the means and/or variance of PPR, which changes its status to endogenous there is a covariance between the residuals of AW and AA (the off-diagonal element, parameter 11 in the Psi matrix); apparently, this is a default that Mplus imposes for path models, that the variables at the end (i.e., the endogenous variables that are only dependent variables, and do not predict anything themselves) have correlated residuals; if we don’t want that, we have to actively set this covariance to zero Regarding the latter point, we may also look at the parameter estimate for this covariance: AW WITH AA 1.173 1.358 0.864 0.388 This covariance is not significantly different from zero; hence, we can decide that it can be omitted from the model (which is the same as fixing it to zero). Question 4 Specify a model that overrules the defaults we ran into in the previous question. Discuss the model fit. Check the TECH1 output and notice the differences with what you saw before. Click to show answers We use the following MODEL command: MODEL: AD ON PPR; AA ON AD PPR; AW ON AD PPR; AA WITH AW@0; PPR; The fit information we get with this code is: MODEL FIT INFORMATION Number of Free Parameters 13 ... Chi-Square Test of Model Fit Value 0.750 Degrees of Freedom 1 P-Value 0.3865 So now we see there are 13 free parameters in this model and there is 1 df; this is what we determined in the beginning (and 13+1=14, so it nicely adds up to the total number of sample statistics that we counted to begin with). When checking the TECH1 output, what we notice is: the free parameters are counting up to 13 the mean and variance of the exogenous variable PPR are now both counted as free parameters the covariance between the residuals of AA and AW is no longer estimated (not a free parameter) Question 5 We are actually interested not so much in overall model fit here (the model has only 1 df, so it is very unlikely that will not fit well), but rather in its parameter estimates, and even more so, in the mediated and direct effects. To get information about the indirect (i.e., mediated) effects, we have to add these lines to the code: MODEL INDIRECT: AA IND PPR; AW IND PPR; Run the model with this code added, and report on the indirect effects. Click to show answers Note that the model itself has not changed (you can also tell by the fact that the model fit and parameter estimates are the same as before); we just have additional output. The nonstandardized additional output starts with: TOTAL, TOTAL INDIRECT, SPECIFIC INDIRECT, AND DIRECT EFFECTS Two-Tailed Estimate S.E. Est./S.E. P-Value Effects from PPR to AA Total 0.538 0.247 2.174 0.030 Total indirect 0.221 0.085 2.608 0.009 Specific indirect 1 AA AD PPR 0.221 0.085 2.608 0.009 Direct AA PPR 0.317 0.240 1.320 0.187 It reports all there is to know about the effect of PPR on AA: the direct effect is not significant (p=0.187) the indirect effect through AD is significant and positive (p=0.009), meaning that higher perceived parental rejection leads to higher aggression the total indirect effect is the same, as there is only one indirect effect (there can be multiple indirect through different series of mediators in more complicated models) the total effect is the total indirect effect (i.e., all indirect effects) plus the direct effect Because the direct effect is not significant, we could decide to take this out of the model (which is the same as setting it to zero). For the second outcome variable we get: Effects from PPR to AW Total 0.035 0.070 0.498 0.619 Total indirect 0.042 0.019 2.249 0.025 Specific indirect 1 AW AD PPR 0.042 0.019 2.249 0.025 Direct AW PPR -0.007 0.070 -0.103 0.918 Pretty much the same picture: The direct effect is non-significant and could thus be fixed to zero. The indirect effect is significantly different from zero, and positive, meaning more perceived parental rejection is followed by more adolescent withdrawal. We can also look at the standardized effects, but let’s first fix the non-significant direct effects to zero. Question 6 Fix the non-significant direct effects to zero, and run the model again. Consider the standardized indirect effects in this model: What can you conclude with regard to the researchers’ question: Does perceived rejection make adolescents sad or mad? Click to show answers The standardized indirect effect of PPR on AA is: Specific indirect 1 AA AD PPR 0.056 0.021 2.680 0.007 The standardized indirect effect of PPR on AW is: Specific indirect 1 AW AD PPR 0.036 0.016 2.281 0.023 We see the effect of PPR on AA (aggression) is larger than that on AW (withdrawal). Hence, we could say that perceived parental rejection makes adolescents more mad than sad, although it also makes them sad. Note however that these effects are both quite small. Question 7 Consider the parameter estimates from the non-standardized solution and write down the regression equations for the three dependent variables in the model; fill in the actual parameter estimates for the intercepts and slopes (i.e., regression coefficients). Click to show answers For adolescent depression we have: \\[AD_i = 22.096 + 0.609*PPR_i + \\zeta_{ADi}\\] For adolescent aggression we have: \\[AA_i = 16.739 + 0.379*AD_i + \\zeta_{AAi}\\] \\[ = 16.739 + 0.379*(22.096 + 0.609*PPR_i + \\zeta_{ADi})+ \\zeta_{AAi}\\] For adolescent withdrawal we have: \\[AW_i = 6.842 + 0.0.069*AD_i + \\zeta_{AWi}\\] \\[= 6.842 + 0.069*(22.096 + 0.609*PPR_i + \\zeta_{ADi})+ \\zeta_{AWi}\\] Conclusion When doing a path analysis with only observed variables, there are several defaults that are operating. It can be helpful to check the TECH1 output to see what and where they are (rather than trying to memorize all of them). Some aspects regarding observed exogenous variables to keep in mind: observed exogenous variables are observed variables that do not have any one-headed arrows pointing towards them; this means that they are not predicted by anything Mplus treats such variables differently than other variables; specifically: a) their observed variances, covariances and means are not counted as sample statistics; and b) their estimated variances, covariances and means are not counted as free parameters; note these two cancel each other out (in terms of sample statistics - free parameters = degrees of freedom) When there are no missing data, the observed means, variances and covariances for observed exogenous variables are identical to their estimated means, variances and covariances When there are missing data, Mplus will use case-wise deletion for cases that have missings on the observed exogenous variables; this may be undesirable, and can be avoided by changing the status of these variables in Mplus to endogenous by asking for their means and/or variances (then Mplus will keep all cases and use ML to deal with the missing observations) Another scenario in which we need to be concerned about observed exogenous variables being treated differently, is when we want to compare such a model to a model in which one or more of these variables are not exogenous; the AIC and BIC of these two models will not be comparable; you can tell by looking at the loglikelihood value for H1 (i.e., for the saturated model), just above the Information Criteria in the output; if these are not the same, the AIC and BIC are not comparable! Some issues regarding additional defaults to keep in mind: In a path model with observed variables only, you have exogenous variables and endogenous variables; the latter can be further distinguished into mediators (i.e., they are dependent variables, but also predictors of other variables), and outcome variables (i.e., they have only arrows pointing towards them, not out of them) The exogenous variables in such models are by default allowed to covary (i.e., there is a two-headed arrow between them); typically, that is fine as we do not have a specific theory about how the predictors are related to each other; however, if you do not want them to be correlated, you can set their covariance to zero with the WITH statement (note this will also change their status from exogenous to endogenous) The residuals of mediators in such models are uncorrelated, unless you specify they should covary (using the WITH statement) The residuals of outcome variables in such models are by default allowed to be correlated (or: to covary); in terms of a path diagram this implies Mplus automatically adds a two-headed arrow between these residuals You can use the TECH1 output to trace these defaults Some issues regarding indirect effects to keep in mind: In this exercise we let Mplus compute the indirect (i.e., mediated) effects by simply multiplying the parameter estimates; the p-value that is reported for this, is known as the Sobel test; however, it is also known that this test is not correct A better approach to determine whether the indirect effect differs from zero or not, is through using bootstrapping and checking the 95% confidence interval for the indirect effect; this can be easily done in Mplus, but requires you to have the raw data (here we only have the summary data, which makes it impossible); in that case you may add to your code: ANALYSIS: BOOTSTRAP IS 1000; OUTPUT: CINTERVAL; "],["day-2-latent-growth-curve-modeling-lgcm.html", "2 Day 2: Latent growth curve modeling (LGCM)", " 2 Day 2: Latent growth curve modeling (LGCM) In this computer lab session you can practice with specifying latent growth models in Mplus and interpreting the output. All of the input files for the exercises described in this GitBook are provided with the course materials on SURFdrive. "],["exercise-1-burn-survivors.html", "2.1 Exercise 1: Burn survivors", " 2.1 Exercise 1: Burn survivors The file PTSD.dat contains data on burn survivors, specifically: gender (gender), percentage total body surface burned (tvlo), SVL at wave 1 (2 weeks after burn injury; W1), SVL at wave 2 (4 weeks after burn injury; W2), SVL at wave 3 (2 months after burn injury; W3), SVL at wave 4 (4 months after burn injury; W4), SVL at wave 5 (6 months after burn injury; W5), SVL at wave 6 (9 months after burn injury; W6), SVL at wave 7 (12 months after burn injury; W7), SVL at wave 8 (18 months after burn injury; W8), and BPAS at wave 9 (24 months after burn injury; pain), in this order. 2.1.1 Exercise 1a: Specifying a LGCM Specify a latent growth curve model. Consider different specifications discussed in the lecture, and try to find the best specification. Use only the time measurements, not including additional predictor variables. Think about which metric of time to use and the shape of the function (linear or quadratic). Base your decision of the best model on plots (!), model fit indices, model comparison tools, and interpretation of the model parameters. If you have reason to believe that another type of LGCM fits the data better, feel free to specific and estimate that model. Click to show answers Deciding on the metric of time Based on these descriptions, I’ve chosen for the following specification of time in the LGM: i s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18; In this specification I set the first time point to 0.5 months after burn injury (approximation of 2 weeks after burn injury), the second time point to 1 month after burn injury (approximation of 4 weeks after burn injury), etc. Plots You can enable the plot functionality of Mplus by specifying PLOT: TYPE = PLOT3; SERIES = W1 W2 W3 W4 W5 W6 W7 W8 (s); The TYPE = PLOT3; function ensures that all kinds of different types of plots are available in Mplus (see the Mplus User Guide for an overview of the different types of plots). The SERIES = ...; function tells Mplus to draw a line through the named variables in that order, for each individual. Deciding on linear vs. linear and quadratic slope Some example syntaxes for running models with different trajectory shapes are available in SURFdrive. These include: A LGCM with only a linear slope. A LGCM with an added quadratic slope. A LGCM with an added quadratic slope but no quadratic slope factor variance. For the model with a quadratic slope, it was necessary to fix the variance of Q at 0 to ensure convergence. For both models, only CFI and TLI indicate adequate fit. Model Parameters AIC BIC RMSEA CFI TLI SRMR exercise1a.out 13 14051 14096 .14 .93 .94 .08 exercise1a_Q.out - - - - - - - exercise1a_Q0.out 14 14037 14085 .13 .94 .94 .08 Model comparison tools To see which model fit the data better, we can do a \\(\\Delta \\chi^{2}\\) (i.e., Chi-square difference) test (e.g., using the function chisq_sb() from the tidySEM package in R, or using on online \\(\\chi^{2} calculator\\)): \\(\\Delta \\chi^{2} = 16.14\\), \\(\\Delta df = 1\\), \\(p &lt; .001\\). Furthermore, both AIC and BIC are lower in the model with a quadratic slope. Thus, model misfit is significantly lower when the quadratic slope is added although the fit indices still do not indicate adequate fit. We can use the plots, RES option in Mplus, or modification indices to see what the source of the misfit is. Model parameters The mean of the quadratic slope factor is significant (q = 0.02, \\(p &lt; .001\\)), indicating that, on average, the growth curve does follow a quadratic curve (see exercise1a_Q0.out). 2.1.2 Exercise 1b: Adding covariates Using the best fitting LGM model found above, regress the growth parameters on TVLO and regress pain on the growth components. Then investigate if there are gender differences in the regression of the growth parameters on TVLO and in the regression of pain on the growth parameters? Click to show answers Rephrasing the question, we are asked to investigate if gender moderates the predictive relationship of TVLO on the growth components, as well as the relationship between the growth components and Pain. As such, we can do a multigroup analysis by gender, resulting in the addition of the following syntax to the VARIABLE: command: GROUPING = gender (1 = male 2 = female); Since we needed to fix the quadratic slope variance to 0, we cannot estimate any regressions on the quadratic slope or use the quadratic slope as a predictor of some outcome. We therefore focus on the intercept and linear slope. The file exercise1B.inp on SURFdrive contains the Mplus syntax on how to specify this model, including the MODEL TEST command to test between-group (i.e., between-gender) differences in the effect of TVLO on the growth components, and the growth components on pain. This is only an illustrative example for how to approach this analysis; your specific execution may differ (e.g., you could specify 2 models, and with across group constraints and one without, and then use the \\(\\Delta \\chi^{2}\\) test to see if the improvement of model fit is significant). Note that in this example, the Wald \\(\\chi^2\\) p-value is not significant. That means that there are no significant gender differences in the effect of the growth trajectory on pain. Note that the Wald test is an overall test of all comparisons that we specify in MODEL TEST. Thus, if you want a separate test for the regression of TVLO on the growth parameters, you need to re-run the analysis but with a different MODEL TEST argument. Conclusion: There are no gender differences in the regression of growth parameters on TVLO and in the regression of Pain on the growth parameters. "],["exercise-2-alcohol-use.html", "2.2 Exercise 2: Alcohol use", " 2.2 Exercise 2: Alcohol use The figure below depicts the basic LGCM for the alcohol use data from Duncan, Duncan, and Strycker (2006), example 8_1. Latent growth curve model for alcohol use. The data are in the file DDS8_1.dat, with variables ALC1YR1 ALC1YR2 ALC1YR3 ALCPROB5 AGE1 and GENDER1 (in that order). Missing values are coded as -99. The variable ALCPROB5 is categorical, it indicates alcohol problems in year 5 of the study (0 = no, 1 = yes). 2.2.1 Exercise 2a: Specify a LGCM Set up the LGCM as depicted in the figure above in Mplus using the | notation (rather than specifying a CFA by using the BY statement). Inspect the output carefully with special attention for a) the pattern of missing values, b) the model fit, and c) the interpretation of the parameter estimates. How well does the model predict alcohol use of the years? Click to show answers The input and output file (exercise2A.inp and exercise2A.out) can be found on SURFdrive. The table under PROPORTION OF DATA PRESENT in the output file shows that the majority of the cases is complete, but that there is a small amount of attrition (panel dropout). You can also inspect the coverage matrix to inspect how much information you have for different parts of the model. Regarding model fit, the model fits well overall with the chi-square test of model fit \\(\\chi^{2}(1) = 2.781\\), \\(p = 0.095\\), and the CFI and TLI above their recommended cutoff points. However, the RMSEA implies some some degree of misfit at \\(0.062\\). The intercept and slope means indicate a relatively high starting point (3.68, \\(SE = .081\\)) and a growth of 0.92 (\\(SE = .053\\)) per year. The intercept and slope factors show considerable variance, indicating that the starting points and rates of growth differ considerably across individuals. Interestingly, the explained variance \\(R^{2}\\) is high for years 1 and 3, but lower for year 2. 2.2.2 Exercise 2b: Predicting growth We will now explore how different predictor variables affect the model fit. Include gender and age in the model as predictors of the intercept and slope. Interpret the fit of the model and the output. Feel free to estimate several models, including or excluding certain covariates. Make a model fit table by hand in a spreadsheet, reporting on the fit indices you deem to be appropriate. Which model do you consider to be best? 2.2.2.1 Exploratory vs confirmatory research Note that when you conduct confirmatory research, and are testing theoretical hypotheses, you should not add and omit paths based on exploratory analyses and model fit. It is fine to add and remove paths in exploratory research. Model fit indices, like AIC and BIC, are suitable for selecting well-fitting models in exploratory research. p-values are not designed for variable selection, and using them for that purpose may lead to sub-optimal models. It is good scientific practice to clearly separate confirmatory and exploratory research. When you conduct exploratory research, you should not perform inference on the resulting parameters based on p-values (because inference generalizes your findings to the population, and exploratory findings tend to be tailored toward this specific sample). You should also not present exploratory results as if they were testing a post-hoc theory (also referred to as “Hypothesizing After the Results are Known”, or HARKing). This is a questionable research practice and can lead to false-positive (spurious) findings. Click to show answers The files exercise2B_M1.inp, exercise2B_M2.inp, and exercise2B_M3.inp, on SURFdrive contain various models in which we predict the growth components using AGE1 and GENDER1. The model fit remains excellent. After removing non-significant paths from exercise2B_M1.inp (order based on magnitude of standardized effect size), gender and age only predict the starting point but not the slope. However, after having removed the effect of gender and age on the slope, the model suddenly fits very badly (exercise2B_M2.inp). Careful inspection of the output shows that the covariance between intercept and slope has disappeared from the model (it is now the covariance between a latent variable and a residual, Mplus automatically puts these at zero). Mplus automatically constrains these to zero. If we add the statement I WITH S to the model, we obtain a good fit with significant effects of both gender and age on the intercept (exercise2B_M3.inp). This illustrates the importance of checking the output carefully to find out if Mplus is actually doing what you think it does! 2.2.3 Exercise 2c: Categorical distal outcome Include alcohol problems in year 5 in the model. Let the intercept and slope factors predict alcohol problems in year 5. Declare the variable as categorical in the variable section (CATEGORICAL = ALCPROB5). Inspect if the effect of age and gender on alcohol problems year 5 is completely mediated by the growth factors, or if there are additional direct paths from age and gender on the alcohol problems. Click to show answers The model fit is still good. Note that after adding a categorical dependent variable to the model, Mplus switches to a robust estimator (MLR, and the exact type of regression the Mplus uses now is a logit regression). Both intercept and slope predict alcohol problems (see exercise2c_M1.inp on SURFdrive). Age also predicts alcohol problems directly (see exercise2c_M2.inp on SURFdrive). Since age predicts alcohol problems both directly and via the intercept, a mediation analysis is in order. This shows that the indirect effect of age via the intercept on alcohol problems is still significant when the direct effect is added to the model. "],["exercise-3-level-and-shape-parameterization.html", "2.3 Exercise 3: Level and shape parameterization", " 2.3 Exercise 3: Level and shape parameterization The file GPA.dat holds the following variables (in that order): grade point average (GPA) data with GPA scores of 200 students in 6 consecutive semesters (gpa1, …, gpa6) high school GPA highpa gender sex admitted to university of choice (missing if not applied for university, student) In this exercise you will use the GPA data to set up a level and shape model (i.e., a LGCM with estimated time scores). 2.3.1 Exercise 3a Use a parameterization with GPA1@0 and GPA6@1. The loadings for the other time points should be freely estimated. This can be done with, for example, the syntax GPA2* as shown in the handout. Interpret the factor loadings and estimate for S. Click to show answers The Mplus model syntax for this LGCM can be found in exercise3A.inp on SURFdrive. The factor loadings indicate the proportion of change for a 1 unit change in time (here, a 1 unit change of time is specified as the change between the first and the last time points). The predicted change in the outcome for a 1 unit change in time is the mean of the slope, \\(\\alpha_{S} = 0.55\\). Therefore, when looking at the factor loadings, 24% of the total change occurs between GPA1 and GPA2.. The intercept at GPA1 = 2.575. So the estimated score at GPA2 is \\(GPA1 = 2.575 + 0.239*0.549 = 2.706\\). The estimated score at GPA3 is \\(GPA3 = 2.575 + 0.450*0.549 = 2.822\\), etc. 2.3.2 Exercise 3b Now use a parameterization with GPA1@0 and GPA2@1. The other GPA’s should be freely estimated. Interpret the factor loadings and estimate for S. Click to show answers The Mplus model syntax for this parametrization of the LGCM with freely estimated time scores can be found in exercise3B.inp. The mean of the slope factor \\(\\alpha_{S}\\) now indicates the difference between GPA1 and GPA2. The estimated factor loadings indicate the distance in units from the starting point, where 1 unit is S. In other words, every distance compares to the increase between GPA1 and GPA2. Which parameterization do you like best? 2.3.3 Exercise 3c Draw the development of GPA over time, using the parametrization of your choice) based on your own calculations (by hand). Compare this to the estimated means plot that you can get with the plot command: PLOT: SERIES = GPA1-GPA6 (s); TYPE = PLOT3; Don’t forget that you need to rescale that plot, since S is linear while the location of the estimated points is based on the factor loadings. Click to show answers The estimated means plot for the parametrization (0 1 * * * *) is shown below, and can be generated by clicking the plots button, and selecting “Estimated means”. Estimated means 2.3.4 Exercise 3d Use sex as a predictor of the intercept and slope and interpret the result (with 0 = boys, 1 = girls). Click to show answers The Mplus model syntax for the LGCM with time scores (0 * * * * 1) and gender predicting the growth components can be found in exercise3D.inp. Sex is a significant predictor of the intercept and a significant predictor of development, with girls having a higher initial level (\\(b = .079\\), \\(SE = .037\\)), and a greater development over time (\\(b = .136\\), \\(SE = .054\\)). Who run the world? "],["exercise-4-latent-growth-curve-model-on-gpa-data.html", "2.4 Exercise 4: Latent growth curve model on GPA data", " 2.4 Exercise 4: Latent growth curve model on GPA data 2.4.1 Exercise 4a Continuing with the data used for the previous exercise, set up a latent growth model for GPA for the 6 consecutive occasions and run this model. Obtain the following parameters: AIC, BIC, \\(\\chi^{2}\\), RMSEA, CFI, and TLI; The mean of the intercept factor \\(\\alpha_{I}\\) and slope factor \\(\\alpha_{S}\\); The variance of the intercept facor \\(\\psi_{I}\\) and slope factor \\(\\psi_{S}\\). Click to show answers The Mplus model syntax for this can be found in exercise4A.inp. 2.4.2 Exercise 4b Then, set up a latent growth curve model for 3 years where each year is a latent variable measured by the GPA of two consecutive semesters. The factor loadings for GPA2, GPA4 and GPA6 ought to be constrained to be equal with a label (a) behind the loading in the syntax. As such, the scores relate in the same way to the year score over time. The GPA intercepts are constrained at 0. If you get the error message below, can you find out what the problem is? WARNING: THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE DEFINITE. THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. A rough way to deal with this problem may be to fix the problematic parameter to a particular value (e.g., .001), try this and rerun the model. Now examine the same parameters as for exercise 4a, and compare the two. Are there major differences? Click to show answers The Mplus model syntax for this can be found in exercise4B_M2.inp. Note that, without year3@.001 (see exercise4B_M1.inp), this code gives an error message: The variance of the latent variable year3 is estimated negatively which is problematic since variances should always be positive. A simple way to deal with the problem of the latent variance of year3 is to fix it to a very small value (.001) for instance, as it would also be illogical to fix a variance to 0. To do this, simply add this to your input file under model: year3@.001; If you inspect the output carefully (and provided you have requested standardized estimates) you will notice that the latent variables year2 and year3 have a correlation of 1. So the negative variance is the result of a multicolinearity problem. It is apparently better to analyze these data using only the observed variables gpa1-gpa6. Creating latent variables per year does not work well. In line with this interpretation, the fit and results of the simple latent growth model look better than the 2nd order latent growth curve model. "],["day-3-longitudinal-mixture-modeling.html", "3 Day 3: Longitudinal mixture modeling", " 3 Day 3: Longitudinal mixture modeling The exercises in this lab session are designed, in the first place, for use of Mplus exclusively. However, for those interested, we have the option to run the latent growth mixture models in batch, using the R-package MplusAutomation. This package allows you to automate part of your workflow (like making plots and tables), and provides functions for plots that are, and now I’m politically correct, more aesthetically pleasing, as well as more insightful. The exercises using MplusAutomation can be found with the course materials on SURFdrive. All of the input files using Mplus that I refer to in these exercises are provided with the course material on SURFdrive. "],["exercise-1-latent-growth-mixture-modeling.html", "3.1 Exercise 1: Latent growth (mixture) modeling", " 3.1 Exercise 1: Latent growth (mixture) modeling The goal of this exercise is to subpopulations with different alcohol use trajectories. To this end, we start with an exploratory latent class growth analysis, and work towards a growth mixture model. 3.1.1 Exercise 1a: Exploratory LCGA First, we perform an exploratory latent class growth analysis (LCGA) as initial exploratory option. Set up LCGA models models for 1, 2, 3, and 4 classes for the data in DDS8_1.dat. Specify the model using the | notation, and constrain the variances of the intercept and slope factors to be equal to 0. Furthermore, request TECH11, and TECH14 to help evaluate model fit. Click to show answers Mplus model syntax for the LCGA models for 1, 2, 3, and 4 classes are in exercise1A_1C.inp, exercise1A_2C.inp, exercise1A_3C.inp, exercise1A_4C.inp, respectively. 3.1.2 Exercise 1b These models use random starting values. Several independent random starts are made, to ensure that the model converges on the proper solution. The default is 20 random sets of starting values, of which 4 are run to completion. Inspect the output, and look carefully if the model estimation has converged, especially for the larger number of classes. Look for warning and error messages, make sure you understand what they are telling you. The STARTS option is used to specify the number of initial random starting values and final stage optimizations. Now, increase the number of starts to ensure proper convergence. Once you are confident that the model has converged to the proper solution, compare the different models using the available fit information (e.g., BIC, LMR-LRT, BLRT, entropy, min. N in classes, etc.). Which model do you prefer, and why? Click to show answers You can inspect the convergence of the model by checking that the best final state loglikelihood value has been replicated using different starting values. See the output section RANDOM STARTS RESULTS RANKED FROM THE BEST TO THE WORST LOGLIKELIHOOD VALUES. Increasing the number of random starts can be done by specifying STARTS = 50 10; in the ANALYSIS command, where the first number specifies the initial number of random starts, and the second number specifies the number of initial starts that will be converged to the final stage. Based on the fit indices of the fitted LCGA models, I would select a 3-class model. The fit indices and (LMR-LRT tests essentially indicate that you can keep adding classes and improve the model, which makes it difficult to decide. However, if we look at the counts in each class, we see that from 4 classes onward, the smallest class has less than 10% of cases assigned to it. The minimum posterior classification probability and entropy are best for the 3-class model, which means that this model can reasonably accurately assign individuals to classes. 3.1.3 Exercise 1c: Growth mixture models Set up the same models as analyzed in the previous exercise, but now allow the means and variances of the intercept and slope factors to be freely estimated in each class (i.e., a growth mixture model). You do this by mentioning the intercept and slope explicitly in the class-specific part of the syntax. This is a more complex model, and we might therefore expect that we will need fewer classes for a good description of the data. This analysis will also take more computing time, so add PROCESSORS = 4 to the analysis section. Make a table of the fit indices, look at BIC, the LMR-LRT (TECH11), and the bootstrapped LRT value (TECH14). Click to show answers Mplus model syntax for the GMM models for 1, 2, 3, and 4 classes are in exercise1C_1C.inp, exercise1C_2C.inp, exercise1C_3C.inp, exercise1C_4C.inp, respectively. The BLRT for the GMM with 3 classes warns that OF THE 10 BOOTSTRAP DRAWS, 7 DRAWS HAD BOTH A SMALLER LRT VALUE THAN THE OBSERVED LRT VALUE AND NOT A REPLICATED BEST LOGLIKELIHOOD VALUE FOR THE 3-CLASS MODEL. You can increase the number of random starts for the BLRT using LRTSTARTS = 0 0 40 10; in the ANALYSIS command. Also note the convergence problems for the GMM with 4 classes. This indicates that a model with 4 classes is likely to be too complex for the data. Furthermore, since the GMM with only a single class is equivalent to a “simple” LGCM, we focus on the GMM with 2 and 3 classes in the next exercises. 3.1.4 Exercise 1d: Model-predicted trajectory plots Plotting the model-predicted trajectories makes it easier to interpret the model. Moreover, visualizing the raw data provides yet another way to evaluate the fit of your mixture model to the data. With this in mind, plot the GMM models with 2 and 3 classes you created in exercise 1c, and interpret what you see. First, plot only the predicted trajectories. Then, plot raw data as well. Explain the benefit of plotting the raw data in your own words. Click to show answers Plotting the raw data helps us understand how representative the average trajectory for each class captures the individual trajectories of individuals in that class. It helps us see how separable the classes are visually, instead of just relying on statistics like entropy. To get plots, make sure you include: PLOT: TYPE = PLOT3; SERIES = ALC1YR1(1) ALC1YR2(2) ALC1YR3(3); when running the model. Then press the “plot” button and select “Estimated mean and observed individual values” and “Estimated means and estimated individual values”. Below you can find these plots for the GMM with 2 classes. Estimated means and individual values. Estimated means and estimated invidivual trajectories Admittedly, this plot looks chaotic. Primarily because the individual values are not colored according to the class to which they are assigned. Alternatively, you could get the estimated means and (individual) values per class in a seperate window as well. However, MplusAutomation has some useful plotting functions that I recommend you to explore, for example plotGrowthMixtures(), in which you can color the lines according to their class membership. 3.1.5 Exercise 1e Covariates are often added to mixture models, to predict 1) class membership 2) to explain variation in the growth parameters within the classes, or 3) as a distal outcome. Whenever covariates are however added to the model, they change the latent class solution. Sometimes, this is fine, as the covariates can help to improve the classification. In other cases, you would use a 3-step approach, which Mplus has automated: Fit an unconditional LCA (without covariates). A “most likely class variable” is created using the posterior distribution of step 1. This most likely class variable is then regressed on (a) covariate. There are a few options for how to do 3-step analysis. They all rely on adding to the VARIABLE command. For more info, see https://www.statmodel.com/download/webnotes/webnote15.pdf. 3.1.5.1 Commands for conducting a 3-step model You can add the following options to the VARIABLE command: AUXILIARY = x(R) This is actually a 1-step method for predicting latent class memberships using Pseudo-Class draws. AUXILIARY = x(R3step); A 3-step procedure, where covariates predict the latent class. AUXILIARY = y(e) A 1-step method, where the latent class predicts a continuous distal outcome. AUXILIARY = y(de3step); A 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and equal variances. AUXILIARY = y(du3step); A 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and variances. AUXILIARY = Y(dcon); Procedure for continuous distal outcomes as suggested by Lanza et al (2013). AUXILIARY = Y(dcon); Procedure for categorical distal outcomes as suggested by Lanza et al (2013). AUXILIARY = y(BCH); Improved and currently best 3-step procedure with continuous covariates as distal outcomes. Pick your final model from 1c, and add both age and gender as auxiliary variables in the model. Try to think what 3-step model you want, and if you are not sure, run different models, so you can evaluate how the different procedures make a difference. What is the effect of both age and gender? Click to show answers I’m providing an example using the 3-step procedure in exercise1E.inp. The results of adding these covariate to the model as predictors of the latent class can be found under the heading TESTS OF CATEGORICAL LATENT VARIABLE MULTINOMIAL LOGISTIC REGRESSIONS USING THE 3-STEP PROCEDURE. It can be seen, from the overall test and the pairwise comparisons, that the third group is significantly older, and has a significantly lower proportion of girls than the other two classes. "],["exercise-2-latent-transition-analysis-lta.html", "3.2 Exercise 2: Latent transition analysis (LTA)", " 3.2 Exercise 2: Latent transition analysis (LTA) In this exercise we will explore the development of dating status over time using a latent transition analysis. Use the data in DatingSex.dat, which holds data on five dating indicators measured at two occasions (u11, …, u15, u21, …, u25), as well as the variable gender. The u-variables represent five yes/no items measured at two time points (first digit represents time point, second digit represents the item). 3.2.1 Exercise 2a Set up a model with two latent class variables for the two time points. Exclude the variable gender for now (i.e., explore the LTA without covariates first), and assume there are 2 latent classes. Restrict the thresholds (and hence response probabilities) across the two time points by first repeating the thresholds for each latent class (2), in both model c1 and model c2. To be sure Mplus does what you want, include equality constraints on the five thresholds of %c1#1% and %c2#1%, and similarly for %c1#2% and %c2#2%. Note that these constraints can be interpreted as imposing measurement invariance over time. Although we don’t test the assumption of measurement invariance in these exercises, it is definitely something you would want to check in practice. After running the analysis, inspect the proportions of yes/no answers for each of the indicators in the latent classes (look at probability scale in Mplus output). Click to show answers The Mplus syntax should is given in exercise2A.inp. The parameters in probability scale can be found in under the heading RESULTS IN PROBABILITY SCALE in the output file. For example, we find that the probability of falling into category 1 (i.e., answering yes/no) is 0.434 (\\(SE = .024\\)) if you are in class 1 at the first time point, and 0.566 (\\(SE = .024\\)) for falling into category 2 (i.e., answering yes/no). Because of the imposed constraints, the probabilities also apply to time point 2, see Latent Class C2#1. 3.2.2 Exercise 2b Examine the proportions of participants in each class, based on the estimated model. Note that for each latent variable, the total proportions add up to 1. Next, examine the latent transition probabilities based on the estimated model. What do these probabilities signify? Click to show answers You can find proportions of participants in each class under the heading FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE BASED ON ESTIMATED POSTERIOR PROBABILITIES. These probabilities represent the proportion of the total sample that is assigned to each class. Note that an individual can have a non-zero probability of being assigned to both classes. E.g., there might be a 70% probability that the person belongs to class 1, and a 30% probability that the person belongs to class 2. The proportions here are a sum across those probabilities for all participants. Thus, this person would contribute for 30% to the proportion of the sample in class 2. You can find the latent transition probabilities based on the estimated model under the heading TECHNICAL 15 OUTPUT. These probabilities represent the probability that an individual assigned to one class at time one, will be assigned to another class at time 2. So for example, we see that people in class 1 at time 1 also tend to be in class 1 at time 2 (.76 probability). 3.2.3 Exercise 2c If there is time, you can conduct additional analyses. Include gender as a control variable on the observed variables. Click to show answers You could include gender as a control variable on the observed variables, by adding it to the USEVARIABLES, and including the following lines: u11-u15 ON gender; u21-u25 ON gender; See exercise2C.inp. Alternatively, you could regress class membership on gender, to see whether men are more likely to be in a particular class than women, or vice versa. This is only allowed when you’re NOT using probability parametrization. So, you would have to remove this line: PARAMETERIZATION = PROBABILITY; And add this line: c1 c2 ON gender; 3.2.4 Exercise 2d We are going to extend the LTA to a Mover-Stayer LTA. This model assumes that there is a subpopulation of “stayers” that stay in the same class, and a subpopulation of “movers” that is free to transition to a different class over time. Answer the below questions: Continuing with the 2 classes at both time points. Then, for movers, there is no restriction on the 2 by 2 transition matrix. However, what does the transition matrix for the stayers look like in terms of probabilities? Furthermore, what does the transition matrix for stayers look like in terms of thresholds? Add a Movers-Stayers class (i.e., an additional latent categorical factor with 2 classes, namely a movers class and a stayers class) to the LTA specified in the previous exercise. Make sure that for the movers class the transition matrix has no restrictions, and that the stayers class has the restrictions as discussed above. Run the Movers-Stayers class and look in the output. Which proportion of people is categorized as movers/stayers? Click to show answers By definition, for stayers who are in category 1 at time point 1, there is a probability of 1 for being in category 1 at time point 2 as well, and a probability of 0 for transitioning to category 2. For stayers who are in category 2 at time point 1, there is a probability of 0 for being in category 1 at time point 2, but a probability of 1 for being in category 2. Translating this to thresholds, a large negative threshold represents a very high probability of being into that category, whereas a large positive threshold represents a low probability. So stayers who are in category 1 at time point 1 should have a large negative threshold for category 1 at time point 2, and a large positive threshold for category 2, etc. Mplus model syntax for the mover-stayer model can be found in exercise2D.inp. Looking at TECHNICAL 15 OUTPUT, we can clearly see that we have specified a movers and a stayers class: P(C2=1|CM=1,C1=1)=0.271 P(C2=2|CM=1,C1=1)=0.729 P(C2=1|CM=1,C1=2)=0.542 P(C2=2|CM=1,C1=2)=0.458 P(C2=1|CM=2,C1=1)=1.000 P(C2=2|CM=2,C1=1)=0.000 P(C2=1|CM=2,C1=2)=0.000 P(C2=2|CM=2,C1=2)=1.000 Looking at the information under FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE BASED ON THEIR MOST LIKELY LATENT CLASS PATTERN, we see that 66.8% is classified as a mover, and 33.2% as a stayer. 3.2.5 Exercise 2e We have not investigated whether 2 classes is the right number for this dataset. Investigate how many classes at each time point you would choose. Think about: Whether you think there should be an equal number of classes at both time points (this is mostly a theoretical decision). How to build the model. Should you start by comparing unconstrained or constrained models? How to decide what solution you prefer. "],["day-4-cross-lagged-relations.html", "4 Day 4: Cross-lagged relations", " 4 Day 4: Cross-lagged relations This computer lab session consist roughly of 2 parts: First we will focus on the quasi-simplex model, and second we will focus on the random intercept cross-lagged panel model. For the quasi-simplex model we are going to study the concept of life satisfaction. The covariance matrix is in the file Coenders.dat and comes from 1724 children and adolescents that participated in the National Survey of Child and Adolescent Well-Being (NSCAW) in Russia. They indicated how satisfied they were with their lives as a whole on a 10-point scale (1 = not at all satisfied, 10 = very satisfied). There were three waves (1993, 1994 and 1995). At the third wave, the question was asked twice (with 40 minutes in between). Hence, in total there are four measurements obtained at three waves. The data and variables commands for these data should read: DATA: TYPE = COVARIANCE; FILE = Coenders.dat; NOBSERVATIONS = 1724; VARIABLE: NAMES = Y1 Y2 Y3 Y4; The researchers are interested in fitting a quasi-simplex model to these data, that is, a simplex model at the latent level, thus accounting for measurement error in the observations. This model is graphically represented in slide 19. All of the input files for the exercises described in this GitBook are provided with the course materials on SURFdrive. "],["quasi-simplex-model.html", "4.1 Quasi-simplex model", " 4.1 Quasi-simplex model 4.1.1 Exercise A Provide the names of the variances (i.e., indicate in which model matrix, and which position in this matrix they have) in the quasi-simplex graph in the slides. What is the difference between the \\(e\\)’s and the \\(\\zeta\\)’s? Click to show answers \\(e\\)’s are residuals at the measurement level and can be found in the \\(\\theta\\)-matrix. They only influence the observation at a single occasion in time. \\(\\zeta\\)’s are residuals of the simplex process and can be found in the \\(\\psi\\)-matrix. Their effect is carried forward to future observation through the autoregressive relationships. This difference allows Mplus to estimate both types of ``errors’’. 4.1.2 Exercise B How would you specify the model in Mplus? Click to show answers See the Mplus input file Exercise B.inp. 4.1.3 Exercise C Determine the number of degrees of freedom for this model (indicate how you obtained this number). Is it possible to estimate this model? Click to show answers There are \\(\\frac{4 \\times 5}{2} = 10\\) unique elements in \\(S\\). Free parameters: 4 residual variances at measurement level 1 factor variance 3 residual factor variances 3 regression parameters 11 parameters in total. Therefore, we have \\(10 - 11 = -1\\) df. It is not possible to estimate this model because we are trying to estimate more parameters than we have information in the data. 4.1.4 Exercise D To make sure a quasi-simplex model is identified, often the variances of the measurement errors are constrained to be equal over time. How can you do this in Mplus? How many df does this model have? Click to show answers See the Mplus input file Exercise E.inp for how to constrain the measurement error variances over time. With constrained measurment error variances, we estimate 3 parameters less. So, we estimate \\(11 - 3 = 8\\) and therefore have \\(10 - 8 = 2\\) df. 4.1.5 Exercise E Run the model and report on the model fit. Click to show answers We find the below fit indices: \\(\\chi^{2}\\) = 13.29 with df = 2, \\(p = .0013\\), RMSEA = .057, CFI = .994, and TLI = .981. Except for \\(\\chi^{2}\\) test of model fit, the model seems to fit the data well. Note, however, that the sample size is very large and therefore the \\(\\chi^{2}\\) is likely to be significant, even for minor problems with model fit. 4.1.6 Exercise F The quasi-simplex model you just ran, led to the following warning: WARNING: THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE DEFINITE. THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. PROBLEM INVOLVING VARIABLE ETA4. What is the problem? Click to show answers In your output, look at the reported (estimated) residual variances. We find that the residual variance of ETA4 is estimated to be negative. This is a Heywood case and it is causing the warning to appear. Note however, that it is significant, so ``just” fixing it to 0 as a solution is probably not warrented here. 4.1.7 Exercise G As indicated in the description of the data, the third and fourth measurement were obtained at the same measurement wave (with only 40 minutes in between). Hence, the researchers proposed the following model instead of the regular quasi-simplex model. Explain why this model makes more sense for these data than the regular quasi-simplex model. Tip: check the description of the study at the beginning of this exercise. Adjusted quasi-simplex model. Click to show answers At each occasion there is a latent variable which represents Life Satisfaction. At the first two occasions there was only a single indicator of this latent variable, but at the third occasion there were two indicators. 4.1.8 Exercise H How many df does this model have? Note that we keep the constraint on the variances of the measurement errors. Click to show answers There are \\(\\frac{4*5}{2} = 10\\) unique elements in S. We freely estimate: 1 constrained residual variances at measurement level 1 factor variance 2 residual factor variances 2 regression parameters 1 factor loading 7 parameters in total. Therefore, we have \\(10 - 7 = 3\\) df. 4.1.9 Exercise I Are these two models nested? If so, how? If not, why not, and how could we compare them? Click to show answers Yes, they are nested: this model is a special case of the previous model, as it is based on having ETA3 and ETA4 from the previous model now being a single latent variable. That is, we can constrain the residual variance of ETA4 to zero to get the alternative model. This gives us 1 df for the difference. 4.1.10 Exercise J Specify this model in Mplus and run it. Report on the model fit. Click to show answers See the Mplus input file Excercise J.inp for the model specification in Mplus. Apart from the \\(\\chi^{2}\\)-test of model fit, the model fits well: \\(\\chi^{2} (3) = 27.37\\), with \\(p &lt; .001\\), RMSEA = 0.069, CFI = 0.987, TLI = 0.973, and SRMR = 0.039. 4.1.11 Exercise K Compare the two models to each other. What can you conclude? Click to show answers Comparing both models using the \\(\\Delta \\chi^{2}\\)-test gives us \\(27.37 – 13.29 = 14.0\\) with 1 df such that \\(p &lt; .001\\). This implies that imposing the restriction is not tenable. You can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool Comparing the models using information criteria gives us AIC = 29593 and BIC = 29637 for the first model, and AIC = 29605 and BIC = 29643 for the second. In conclusion, all measures indicate the first model is better. However, the current model makes more theoretical sense, and the negative variance estimate in the first model is a problem. For these 2 reasons, we should prefer the current model. 4.1.12 Exercise L Can you improve the second model in any way? Indicate which parameter you would add to your model, and what this parameter represents in substantive terms. Click to show answers You can get the modification indices by adding MOD to the OUTPUT command. Here, the suggested BY statements make no sense (later life satisfaction as an indicator of previous life satisfaction). With regards to the ON statement, only the suggested effect of ETA3 ON ETA1 makes sense as we then predict forwards in time. The WITH statement suggests adding a covariance between the residuals of y3 and y4. If we add this covariance and look at the standardized results, we get a correlation. This correlation actually quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). 4.1.13 Exercise M Run a model in which you include the Y3 WITH Y4 parameter. Where will this relationship end up in the model? Does it lead to a significant improvement? How would you interpret this additional parameter? Click to show answers See Exercise M.inp for the Mplus specification of this model. The Y3 WITH Y4 parameter is an additional covariance between the residuals of y3 and y4 (so not between y3 and y4 themselves). Model fit is quite good (except for the \\(\\chi^{2}\\)-test of model fit): \\(\\chi^{2} (2) = 7.077\\), \\(p = .0291\\), RMSEA = 0.038, CFI = 0.997, TLI = 0.992, and SRMR = 0.011. To compare this model to the previous model, we can do a the \\(\\Delta \\chi^{2}\\)-test: \\(27.37 – 7.08 = 20.29\\), with 1 df such that \\(p &lt; .001\\), which implies that adding the covariance between the residuals leads to a significant improvement in model fit. This additional parameter implies that y3 and y4 have more in common with each other than what would be expected based on their common dependence on ETA3. Note that in the standardized results, the WITH statement can be interpreted as a correlation, and it is quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). "],["clpm-ri-clpm.html", "4.2 CLPM &amp; RI-CLPM", " 4.2 CLPM &amp; RI-CLPM For the cross-lagged panel model (CLPM) and the random intercept cross-lagged panel model (RI-CLPM) we are going to analyze data that were reported in Davies, Martin, Coe and Cummings (2016). The summary data (means, standard deviations and correlation matrix) are included in Davies.dat, and contains the means, standard deviations, and the correlation matrix. The number of observations is 232. There are 5 waves of data, taken when the child was 7, 8, 13, 14, and 15 years old. The order of the variables is: Child gender Parental education Interparental hostility (waves 1-5): composite score based on observational data and questionnaires, reflecting the degree of hostility between the parents Interparental dysphoria (waves 1-5): based on composite score based on observational data and questionnaires, reflecting the degree of dysphoria Child/adolescent insecurity in the relationship with the parents (waves 1-5) Psychological problems (waves 1-5): based on the subscales anxious/depressed, withdrawal, aggressive behaviors, and delinquency scales of the Child Behavior Checklist (CBCL), filled out by both parents. Here we will focus on Interparental dysphoria and Psychological problems of the child. The DATA and VARIABLE commands should be: DATA: TYPE = MEANS STDEVIATIONS CORRELATION; FILE = Davies.dat; NOBSERVATIONS = 232; VARIABLE: NAMES = ChildGen ParentEd Hos1 Hos2 Hos3 Hos4 Hos5 Dys1 Dys2 Dys3 Dys4 Dys5 Ins1 Ins2 Ins3 Ins4 Ins5 PsPr1 PsPr2 PsPr3 PsPr4 PsPr5; USEVARIABLES = Dys1-Dys5 PsPr1-PsPr5; 4.2.1 Exercise A How many sample statistics are there for this data set (focusing on the 5 measures of dysphoria and the 5 measures of psychological problems? Click to show answers There are 10 observed variables such that there are \\(\\frac{10*11}{2} = 55\\) unique elements in the observed covariance matrix S, and 10 observed means in M. Therefore, there are 65 sample statistics in total. 4.2.2 Exercise B We begin with an RI-CLPM (see slide 53). For now, do not impose any constraints on the parameters across time. Draw the model, and indicate which parameters will be estimated freely. How many parameters will be estimated in total? So how many df are there? Click to show answers In the RI-CLPM we estimate: 2 variances for the random intercepts, 1 covariance between the random intercepts, 2 variances for the within-person centered variables at wave 1, 1 covariance between the within-person centered variables at wave 1, 8 residual variances (for the dynamic errors of both variables at wave 2-5), 4 covariances between the residuals (for the dynamics errors at waves 2-5), 16 lagged parameters (4 for each interval), and 10 means. In total, we estimate 44 parameters such that we have \\(65 - 44 = 21\\) df. 4.2.3 Exercise C Run the model. Check whether the number of df is correct. Also look at the TECH1 output, to see if you understand where the free parameters are. What is the model fit? Click to show answers The input for this model is in RICLPM.inp. The model means are estimated in the \\(\\nu\\)-matrix, no parameters are estimated in the \\(\\theta\\)-matrix (measurement error variances), \\(\\lambda\\)-matrix (factor loadings), or \\(\\alpha\\)-matrix (means/intercepts of the latent variables). The variances and covariance of the random intercepts, the within-person centered variables at wave 1, and the dynamic errors at subsequent waves are all estimated in the \\(\\psi\\)-matrix. The lagged regression coefficients are estimated in \\(\\beta\\). Apart from the \\(\\chi^{2}\\)-test of model, all fit indices indicate at least acceptable fit. \\(\\chi^{2} (21) = 41.451\\), \\(p = .005\\), RMSEA = 0.065, CFI = 0.979, TLI = 0.956, and SRMR = 0.029. 4.2.4 Exercise D Include the significant standardized parameter estimates for the covariances (i.e., the WITH statements) and the lagged regression parameters (i.e., the ON statements) in the figure below. Indicate which part of the model is considered the between-person part, and which part is the within-person part. The bivariate random-intercept cross-lagged panel model with 5 repeated measures (waves). 4.2.5 Exercise E Omit the random intercepts. How many parameters and df does this model have? What is the model fit? Click to show answers The input for this model is CLPMasRICLPM.inp. The model has three parameters less (and thus 3 df more) than the previous model: 2 variances and the covariance for the random intercepts. The model fit indices show that this model does not fit well: \\(\\chi^{2} (24) = 73.374\\), \\(p &lt; .001\\), RMSEA = 0.094, CFI = 0.950, TLI = 0.907, and SRMR = 0.061. 4.2.6 Exercise F Specify the CLPM and run this model. Compare it to the previous two models. How are these models related? Click to show answers The input for this model is in CLPM.inp. This model is statistically identical to the previous model; these are different parameterizations of the same model. The model fit is therefore also exactly the same. Hence, this model is a special case of the RI-CLPM. Comparing the two models using a chi-square difference test gives: \\(\\Delta \\chi^{2} = 73.37 - 41.45 = 31.92\\) with \\(24 – 21 = 3\\) df, \\(p &lt; .001\\). Hence, the random intercepts should not be omitted; put differently, there are stable, trait-like difference between families in the two variables (parental dysphoria and psychological problems). However, when constraints are placed on the bound of the parameter space (which is the case here, fixing a variance to 0 is its absolute minimum value), we should actually use the chi-bar-square test (\\(\\bar{\\chi}^{2}\\)-test; Stoel et al. 2006). The traditional \\(\\Delta \\chi^{2}\\)-test does not take into account that variances can only be positive and is therefore conservative. This means that if it is significant, we are certain that the correct test (i.e., the \\(\\bar{\\chi}^{2}\\) test) would also be significant. On the other hand, when the usual chi‐square test is not significant, we do not know anything about the result of the correct test (it can be significant or not significant). If you are working in R with the lavaan-package, you can find more information about the \\(\\bar{\\chi}^{2}\\)-test at jeroendmulder.github.io/RI-CLPM/lavaan.html#(bar{chi}^{2})-test. For Mplus users, there is a Shiny app by Rebecca Kuiper available as well. 4.2.7 Exercise G Include the significant standardized parameter estimates for the covariances and the lagged regression parameters in the figure below. The bivariate cross-lagged panel model with 5 repeated measures (waves). 4.2.8 Exercise H Discuss how the model results differ. Click to show answers Cross-lagged relationships In the RI-CLPM none of the cross-lagged parameters are significant. In contrast, in the CLPM there is a positive relationship from PsPr1 to Dys2. This implies that higher levels of children’s psychological problems at age 7 are followed by higher levels of interparental dysphoria at age 8. Moreover, from age 14 to 15 both cross-lagged parameters are significant and positive, indicating that psychological problems are followed by increases in interparental dysphoria, but also that increased interparental dysphoria is followed by an increase in psychological problems for the adolescent. Autoregressive parameters The autoregressive parameters in the RI-CLPM are lower, and have larger SE’s, such that fewer reach significance. This is expected as within-person stability is now captures in the random intercepts, rather than in the autoregressive effects in the CLPM. Correlations In the CLPM only the residual correlation at wave 2 is significant; it is negative, indicating that external effects tend to have an opposite effect on these two processes; increases in Dysphoria are accompanied by decreases in psychological problems and vice versa. In the RI-CLPM, the within-person correlation at wave 1 is not significantly different from zero; however, at waves 2, 3 and 4 the correlations between the residuals is significant and negative. At wave 5 the residual variance is not significant. In the RI-CLPM there is also the correlation between the random intercepts (i.e., the trait-like difference between families). This turns out to be a very substantial correlation of .63: Hence, in contrast to the results from the CLPM and the within-level results from the RI-CLPM, there is a strong positive relationship between trait-like levels of interparental dysphoria and trait-like levels of psychological problems. .answer { background-color:#f5fcfb; color: #005c4f; border: 2px solid black; margin: 20px; padding: 20px; } "],["day-5-dynamic-sem-dsem.html", "5 Day 5: Dynamic SEM (DSEM)", " 5 Day 5: Dynamic SEM (DSEM) In this exercise we focus on analysing intensive longitudinal data (ILD) obtained with experience sampling (also referred to as ecological momentary assessments). We will use data from Bringmann et al. (2013), stored in file Bringmann1.dat. It contains data from 129 persons, with each between 20 to 60 repeated measurements per variable. Throughout these exercises we will focus on two variables: Somber (to what degree are you feeling somber right now?), and Event (report on the most important event since the previous beep and indicate how unpleasant-pleasant is was). Bringmann, L. F., Vissers, N., Wichers, M., Geschwind, N., Kuppens, P., Peeters, F., … &amp; Tuerlinckx, F. (2013). A network approach to psychopathology: new insights into clinical longitudinal data. PloS one, 8(4), e60188. "],["random-intercept-model-with-implicit-lagged-effects-not-dsem.html", "5.1 Random Intercept Model with Implicit Lagged Effects (not DSEM)", " 5.1 Random Intercept Model with Implicit Lagged Effects (not DSEM) In Model 1 we first decompose each variable at each time point (occasion) in two parts: a person-specific mean, which has the same value at each occasion but differs from person to person a deviation from that mean for each person and occasion. Hence, we decompose the variables into two latent variables: One with person-specific means, at the between level. One with deviations from these means unique to each occasion and person, at the within level. These deviations can be seen as simply the within-person centered scores for a person at each occasion. Next, we add two regression relationships: Between level: the person means of Somber are regressed on the person means of Event Within level: the person-mean centered variable Somber is regressed on the person-mean centered variable Event. Note that this is not a dynamic SEM model yet in terms of the Mplus specification, because there are no explicit lagged relationships in the model. But note that there is an implicit lagged relationship: Although the two variables are measured at the same occasion (as indicated by the subscript t), the variable Event refers to the interval between t-1 and t, while the variable Somber is referring to the specific time point t. Hence, the reported on events take place before the somber feelings. This model can be represented as depicted below, with on the left this decomposition, and on the right the regression models specified at each level. 5.1.1 Specify the Mplus Model To run this model, use the input file model1.inp. In the ANALYSIS command you will find a number of commands that set up the Bayesian multilevel estimation procedure: ANALYSIS: TYPE = TWOLEVEL; ESTIMATOR = BAYES; PROC = 2; BITER= (2000); BSEED = 9556; Make sure the following commands for OUTPUT and PLOT are included: OUTPUT: TECH1 STDYX; PLOT: TYPE = PLOT3; FACTORS = ALL; Check out the model specification (i.e., the MODEL command). What do the commands on the within person level and on the between person level do? Click to show answers Via ‘Somber ON Event’ at the within level, for each person in the model their somber within-person centered scores are regressed on their within-person centered event scores on the same measurement occasion. The regression coefficients and other model parameters – except for the means of somber and event - are the same for all persons. Via ‘Event’ we tell Mplus to make Event endogenous like Somber, such that means and variances are estimated for this variable as well - and Event is decomposed in a between person level and within-person level as well. That is, for both Somber and Event we now estimate the mean score over time for each individual inside the model. On the within level the deviations from these means (within-person centered scores) at each time point are modeled. At the between level the relationships among these means, that vary from individual to individual, are modeled. Via ‘Somber ON Event’ at the between level, it is specified that the person-specific means for Somber are regressed on the person-specific means for Event. 5.1.2 Model Equations &amp; Parameters While the model is running, write down the model in equations. Start with the decomposition, i.e., \\(E_{it}=\\) … Click to show answers \\[S_{it} = \\mu_{S i} + S_{it}^{(w)}\\] \\[E_{it} = \\mu_{E i} + E_{it}^{(w)}\\] Write down the within level model. Which parameters are estimated at this level? Click to show answers \\[S_{it}^{(w)} = b \\times E_{it}^{(w)} + \\zeta_{S it}\\] Parameters estimated at this level: Fixed within-person slope b (same for each person) Residual within-person variance for S, the variance of \\(\\zeta_Sit\\) Within-person variance of the (made endogenous) predictor \\(E^{(w)}_{it}\\) Write down the between level model. Which parameters are estimated at this level? Click to show answers \\[\\mu_{S i} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\zeta_{Si} \\] Parameters estimated at this level: Grand intercept \\(\\gamma_{00}\\) Between-person slope \\(\\gamma_{01}\\) Between-person residual variance of \\(\\zeta_{Si}\\) Mean of the between-person predictor \\(\\mu_{Ei}\\) Variance of the between-person predictor \\(\\mu_{Ei}\\) 5.1.3 Convergence When the model is finished running, we first need to check the trace plots of the Bayesian estimation procedure to see if there are signs for non-convergence. Go to the icon with the two graphs, and click on this. Then, choose the option “Bayesian posterior parameter trace plots” and click “View”. By clicking “OK” in the next window, the trace plot of parameter 1 appears. You can use the icons with the histograms and the left and right headed arrows to move backward and forward through the parameters (their names are in the headings of the plots). Write down how these parameters relate to the ones you identified above (in questions c. and d.), Are there any problems with convergence based on these plots? Can you tell what parameter from question b each plot is about? Click to show answers Parameter 1, %WITHIN%: SOMBER ON EVENT → within-person regression coefficient b Parameter 2, %WITHIN%: SOMBER → within-person residual variance for somber Parameter 3, %WITHIN%: EVENT → within-person variance on Event Parameter 4, %BETWEEN%: [SOMBER] → between-person intercept on Somber (\\(\\gamma_{00}\\)) Parameter 5, %BETWEEN%: [EVENT] → between-person mean on Event Parameter 6, %BETWEEN%: SOMBER ON EVENT → between-person regression coefficient (\\(\\gamma_{01}\\)) Parameter 7, %BETWEEN%: SOMBER → between-person residual variance of somber Parameter 8, %BETWEEN%: EVENT → between-person variance on Event Convergence looks fine for the parameters. 5.1.4 Interpret the Results Go to the output, and consider the parameter estimates. Interpret the findings for the within-person and the between-person slopes (e.g., do they differ from zero, are they positive or negative, what about their size?). Click to show answers Within Level SOMBER ON EVENT -0.203 0.010 0.000 -0.223 -0.184 * Between Level SOMBER ON EVENT -0.953 0.159 0.000 -1.266 -0.651 * Both slopes are negative, implying that: Within person: People’s increased (relative to their mean level) Event scoretends to be followed by a decreased (relative to their mean level) temporary somberness score. A 1 unit higher event score tends to be followed by a decrease of .20 units in their somber score. Between person: People a relatively high (compared to other people) mean for event, tend to have a relatively low (compared to other people) mean for somberness. A 1 unit higher mean would imply about a .95 units lower mean for Somber. The between-person slope is more than 4 times steeper: Note however that the between-person variance in Event is about 10 times smaller than the within-person variance in Event (0.278 vs. 2.844). Hence, in the next step we look at the standardized results. 5.1.5 Standardized Results Check the standardized results to compare the size of the slopes within and between. Click to show answers SOMBER ON EVENT -0.259 0.012 0.000 -0.284 -0.236 * SOMBER ON EVENT -0.529 0.074 0.000 -0.656 -0.374 * The standardized between slope is more than twice as steep than the within slope. In terms of \\(R^{2}\\): 6.7% of the momentary within-person variability in Somber is explained by within-person variability in Events. 28.0% of the stable between-person variability in Somber is predicted by between-person differences in average Event. "],["random-intercept-and-slopes-model-with-implicit-lagged-effects-not-dsem.html", "5.2 Random Intercept and Slopes Model with Implicit Lagged Effects (not DSEM)", " 5.2 Random Intercept and Slopes Model with Implicit Lagged Effects (not DSEM) In Model 2, we extend Model 1 to allow for individual differences in the within-person slope. This implies that people may respond differently to a temporary increase in the variable Event; this can be interpreted as individual differences in reactivity. This random slope b1 becomes another latent variable at the between-person level, where we can use it as a predictor of the person-specific means of the variable Somber. We will also allow this slope variable to correlate with the means of Event. Model 2 can be represented as depicted below, with on the left the within-between decomposition, and on the right the regression models specified at each level. Note the black dot on the arrow to indicate a random slope at the within level. 5.2.1 Specify the Mplus Model Write down the model command for this model. When your are done, check whether you specified it correctly by looking at the provided answers, and/or the input file model2.inp. Note that under command ‘ANALYSIS’ in the input file, we now need to specify type = TWOLEVEL RANDOM. Click to show answers MODEL: %WITHIN% b1 | Somber ON Event; Event; %BETWEEN% Somber ON Event b1; b1 WITH Event; 5.2.2 Model Equations While the model is running, write down the model equations. The decomposition into within and between will be the same as for Model 1. Write down the within level model. What parameters are estimated at this level? Click to show answers \\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + \\zeta_{S it}\\] The difference is that now the regression coefficient has a subject index i, because it now differs from person to person. The mean and variance of b1i are estimated at the between person level. Parameters estimated at this level: - Residual within-person variance of \\(\\zeta_{Sit}\\) - Within-person variance of the predictor \\(E^{(w)}_{it}\\) Write down the between level model. Which parameters are estimated at this level? Click to show answers \\[\\mu_{Si} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\gamma_{02} \\times b_{1i} + \\zeta_{Si}\\] Parameters estimated at this level: Grand intercept \\(\\gamma_{00}\\) Between-person slope \\(\\gamma_{01}\\) Between-person slope \\(\\gamma_{02}\\) Between-person residual variance of \\(\\zeta_{Si}\\) Mean of the between-person predictor \\(\\mu_{Ei}\\) Variance of the between-person predictor \\(\\mu_{Ei}\\) Mean of the between-person predictor \\(b_{1i}\\) (i.e., within-person slope) Variance of the between-person predictor \\(b_{1i}\\) Covariance of \\(b_{1i}\\) and \\(\\mu_{Ei}\\) (with statement in mplus code) 5.2.3 Convergence Check the trace plots of the posteriors for the parameters of the model. Can you link them to the free parameters you identified above? Are there signs of non-convergence? Click to show answers All looks good. 5.2.4 Interpret the Results Which parameter is the one we should focus on when interested in the average of the person-specific within-person slopes b1? Click to show answers Between Level Means B1 -0.206 0.014 0.000 -0.234 -0.179 * It is the mean B1 reported at the between level. There are two ON statements at the between level now. Report the results for these regressions, and indicate how to interpret these results. Click to show answers Between Level SOMBER ON B1 -1.966 1.079 0.020 -4.366 -0.095 * SOMBER ON EVENT -0.839 0.176 0.000 -1.188 -0.490 * As before: People with a relatively high (compared to other people) mean for event, tend to have a relatively low (compared to other people) mean for somberness. In addition: People that have a relatively low mean for somber (compared to other people), tend to have a lower within-person slope b1. Interpreting the effect of b1 on Somber is challenging for most people. What may be helpful is to make a plot of the (bivariate) relationship between b_1i and the within-person mean on somber. Click for instructions Go to the plotting options and choose “Between-level scatterplots…” Click View. Then select “B1, mean” (the posterior means of each person’s B1 coefficient) as the X variable and “SOMBER (estimated cluster mean)” (each person’s mean for Somber) as the Y variable: Click OK. This produces the scatter plot. Interpret the relationship you see in the scatterplot. Click to show answers The correlation is negative (about -0.503), indicating that a higher b1 (within-person slope) tends to go together with a lower person-mean on somber. Note that the individual differences in b1 run from -0.5 to about 0. Hence, the closer b_1i is to zero, the lower the person’s average score on somber. Put differently, people who tend to be less reactive to momentary changes in Events (b_1i closer to zero), are also characterized by a lower trait score on somber. Note that this plot is just presenting the bivariate relationship between the two random effects; in contrast, the regression coefficient in the output also is based on a regression model with multiple predictors (in this case, also the person mean on Event). Hence the scatter plot may be helpful, but is not a direct reflection of the regression coefficient (this is the same as in normal multiple linear regression analysis). Let us look at the person-specific slopes (the random effect b1) that were estimated. Click for instructions To this end, go to the plot menu again and choose the option “Two-level cluster-specific observed and estimated values plots”. Click “View”, and click “OK” in the next window: Now you have a scatter plot of the data of a single individual, with the variable Event on the x-axis and Somber on the between-axis. The slope of the red line is the individual’s b1 (the individual specific regression coefficient for regressing Somber on Event). To fix the axes (which makes it easier to compare the results across individuals, go to the plot menu at the top, choose “Axis properties” and then “Edit settings”: In the next window, choose the “Axes Range” tab, click the “Fixed scale” option (at the top), and set the scale range for X from -4 to 4 (because Event was measured on a scale running from -3 to 3), and set the scale of Y from 0 to 8 (because it was measured on a scale from 0 to 7). Then click “OK”. Now, you can go through the plots of different individuals by clicking the person buttons on the top (with the left arrow to go back, and the right arrow to go forward). Because you fixed the axes, you can easily compare the slopes for different people. This illustrates that every person has his/her own slope. "],["dynamic-sem---including-random-autoregressive-effects..html", "5.3 Dynamic SEM - including random autoregressive effects.", " 5.3 Dynamic SEM - including random autoregressive effects. Next, we include a dynamic relationship in our model. First, create a lagged version of Somber, by using the LAGGED = in the VARIABLE command). In the next step, we’ll include the lagged variable as a predictor at the within level, allowing for a random slope - this produces a random autoregressive effect (each individual will get their own autoregressive effect). This model can be represented as: 5.3.1 Specify the Mplus Model Write out the model command for this model. Check with the input file model3.inp if you specified it correctly. Click to show answers MODEL: %WITHIN% s1 | Somber ON Event; ! random regression s2 | Somber ON somber&amp;1; ! random autoregression %BETWEEN% Somber ON Event s1 s2; The command &amp;1 attached to a variable indicates this should be a lag 1 variable. The parameter label followed by | produces a random effect like before. 5.3.2 Model Equations While the model is running, write down the model equations. Write down the within level model. What parameters are estimated at this level? Click to show answers \\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + b_{2i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\] Parameters estimated at this level: Residual within-person variance of \\(\\zeta_{Sit}\\) Within-person variance of the predictor \\(E^{(w)}_{it}\\) Write down the between level model. Which parameters are estimated at this level? Click to show answers \\[\\mu_{Si} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\gamma_{02} \\times b_{1i} + \\gamma_{03} \\times b_{2i} + \\zeta_{Si}\\] Parameters estimated at this level: Grand intercept \\(\\gamma_{00}\\) Between-person slope \\(\\gamma_{01}\\) Between-person slope \\(\\gamma_{02}\\) Between-person slope \\(\\gamma_{03}\\) Between-person residual variance of \\(\\zeta_{Si}\\) Mean of the between-person predictor \\(\\mu_{Ei}\\) Variance of the between-person predictor \\(\\mu_{Ei}\\) Mean of the between-person predictor \\(b_{1i}\\) (i.e., within-person slope) Variance of the between-person predictor \\(b_{1i}\\) Mean of the between-person predictor \\(b_{2}\\) (i.e., autoregressive slope) Variance of the between-person predictor \\(b_{2i}\\) Covariances between \\(b_{1i}\\), \\(b_{2i}\\), and \\(\\mu_{Ei}\\) 5.3.3 Convergence &amp; Interpret the Results Again, check the trace plots. If they look okay, consider the parameter estimates. What can you say about the autoregressive effects? Click to show answers Means B2 0.340 0.022 0.000 0.300 0.383 * Variances B2 0.031 0.007 0.000 0.020 0.047 * The average autoregressive effect is 0.34, with SD=0.18 (=sqrt(0.031)). On average, about .34 of the previous Somber score carries over to the next Somber score. The actual autoregressive effects will however differ from person to person. Hence, on average across persons, about 12% (0.34^2=.12) of the within-person variability in somberness is predicted by the autoregressive effect. The exact numbers will however differ from person to person. To obtain some idea of the individual differences in the autoregressive parameter, we will consider diverse plots. One plot that might be of interest is the histogram of the individual parameter values. Click for instructions Again, go to the plotting options, and now select the option: Between-level histogram (etc.) Click View. In the next window, select the random autoregressive parameter (B2): Click “OK”. This shows you the sample distribution of the autoregressive parameter. Note that the individual scores are based on the mean of an individual’s posterior distribution for this parameter. What is the highest and the lowest person-specific autoregressive effect? Click to show answers The lowest is about 0.08 (so close to zero), the largest is about 0.7, so strong and positive. Most effects are around .2 to .45. Consider the level 2 effects where the within-person means of Somber are predicted by the within-person mean on Event, the random slope b1, and by the random slope b2. How would you interpret these results? Click to show answers Between Level SOMBER ON B1 -2.342 1.403 0.037 -5.405 0.153 B2 0.181 0.626 0.377 -1.013 1.473 SOMBER ON EVENT -0.831 0.183 0.000 -1.194 -0.476 * Hence, only the person mean on Event is a significant predictor. The effect is negative, so people with relatively high person-specific means for ‘pleasant Event’ (report higher pleasant Event scores on average compared to others), tend to have relatively low person-specific means for Somber. While the effect of b1 was significant in a previous model, it no longer is in this model. "],["dynamic-sem---including-random-autoregressive-and-cross-lagged-effects..html", "5.4 Dynamic SEM - including random autoregressive and cross-lagged effects.", " 5.4 Dynamic SEM - including random autoregressive and cross-lagged effects. Until now, we have treated Event as a predictor only. However, it is also possible that the experience of negative and positive Events is affected by a person’s momentary somberness. Moreover, there may be an autoregressive effect for Events. Hence, we are interested in the following model: Thus, we have added two random slopes to the model: b3 and b4, the autoregressive and cross-lagged effect respectively. At the between level, we allow the now 6 random effects to be correlated, rather than that we predict one from the other as we did before. Note that while the figure does not include a relationship between S and E at t-1, these predictors are related in the model (as the model that is specified at time point t, equally applies to all other time points - so we could have added the same b1 arrow there); the current representation simply represents which model statements are needed. 5.4.1 Specify the Mplus Model How do you specify this model? Check your specification with the model4.inp input file. Click to show answers MODEL: %WITHIN% s1 | Somber ON Event; ! lagged random regression s2 | Somber ON somber&amp;1; ! random autoregression for somber s3 | Event ON Event&amp;1; ! random autoregression for Event s4 | Event ON somber&amp;1; ! lagged regression from Somber to Event %BETWEEN% Somber Event s1 s2 s3 s4 WITH Event s1-s4; 5.4.2 Model Equations While running the model, write down the regression equation for the within level. Click to show answers \\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + b_{2i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\] \\[E^{(w)}_{it}=b_{3i}\\times E^{(w)}_{it-1} + b_{4i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\] In contrast to typical cross-lagged models that we covered in the lecture, we are not including a covariance between the residuals here. Why not? Click to show answers The concurrent (lag 0) relationship is already accounted for by the (random) regression of \\(S_{it}\\) on \\(E_{it}\\). The residual of \\(S_{it}\\) is the part that cannot be predicted from \\(E_{it}\\) (and \\(S_{it-1}\\)); hence it would not make sense to correlate this residual with the residual of \\(E_{it}\\). How many parameters are estimated at each level? Click to show answers Within: 2 residual variances Note that because Event is now not only a predictor, but also an outcome, we no longer estimate its variance, but instead its residual variance; the variance of Event is now a function of the residual variance, the regression coefficients, and the variances of the predictors. Between: 4 fixed slopes (mean slopes) 2 fixed intercepts (grand means) 6 variances of the 4 slopes and 2 intercepts (random effects) 15 covariances between these random effects 29 parameters in total. 5.4.3 Convergence &amp; Interpret the Results When the model is finished, check the trace plots for signs of non-convergence. Look at the estimated effects. What can you conclude about the autoregressive and cross-lagged coefficients? Click to show answers Means B1 -0.169 0.014 0.000 -0.195 -0.142 * B2 0.342 0.022 0.000 0.298 0.382 * B3 0.118 0.020 0.000 0.078 0.159 * B4 -0.126 0.024 0.000 -0.176 -0.081 * All of the average coefficients differ from zero. The average autoregressive coefficients, b2 and b3, are positive. So for on average, there is carryover from one moment to the next both for feelings of somberness and the experienced pleasantness of events. The average Cross-lagged coefficients b1 and b4 are negative, implying: More positive Events tend to be followed by less somberness an occassion later, while increased somberness tends to by followed by less positively experienced events. To compare the strengths of the cross-lagged effects, we need to consider the standardized parameters. Check the standardized output, and interpret the regression coefficients there. Click to show answers B1 | SOMBER ON EVENT -0.211 0.013 0.000 -0.237 -0.187 * B2 | SOMBER ON SOMBER&amp;1 0.341 0.014 0.000 0.312 0.370 * B3 | EVENT ON EVENT&amp;1 0.119 0.015 0.000 0.091 0.149 * B4 | EVENT ON SOMBER&amp;1 -0.105 0.015 0.000 -0.137 -0.077 * The standardized autoregressive parameters should be (approximately) the same as the unstandardized ones. The reason for this is that the variances for \\(y_{t}\\) and \\(y_{t-1}\\) in a stationary model are the same by definition. Slight differences in the point estimates might occur due to the calculation procedure of the standardized effects. Note however that the standard errors are smaller for the standardized fixed effects. This is because the standardized fixed effect is a sample mean of the person-specific effects, and disregards sampling variability. Significance of fixed effects should hence be based on the unstandardized fixed effects. This also applies to the fixed cross-lagged effects. This is not an issue for the person-specific standardized effects. The standardized average (fixed) effect from Event to Somber (-.211) is twice the size of the one from Somber to Event (-.105); so on average, the effect from Events on mood is stronger than the other way around. This however may be different from person to person. Consider the R-square output as well. How can you interpret this? Click to show answers Within-Level R-Square Averaged Across Clusters Posterior One-Tailed 95% C.I. Variable Estimate S.D. P-Value Lower 2.5% Upper 2.5% SOMBER 0.227 0.012 0.000 0.204 0.250 EVENT 0.057 0.008 0.000 0.043 0.073 On average, 23% of within-person variability in Somber can be accounted for by the lagged relationships; for Event this is 6%. These numbers may however differ from person to person. Consider the covariances and correlations between the random effects. For which of these correlations is there evidence that they deviate from zero? Click to show answers There are a few significant correlations: SOMBER WITH B1 -0.346 0.132 0.007 -0.585 -0.071 * B3 0.342 0.151 0.017 0.027 0.623 * B3 WITH B4 0.571 0.198 0.011 0.102 0.865 * SOMBER WITH EVENT -0.523 0.083 0.000 -0.663 -0.346 * People with relatively high person-specific means for somber tend to have relatively low values for the effect of event on somber; and relatively high autoregressive effects for Event. People with relatively higher autoregressive effects for Event tend to have relatively high values for the cross-lagged effect of somber on event. People with relatively high person-specific means for somber tend to have relatively low person-specific means for event. To interpret these effects further, we’ll look at some plots in the following exercise. For each of these correlations, get a scatter plot and interpret the result (use the “Between-level scatterplots” option). Click to show answers Somber with b1: A higher mean level for Somber is related to lower b1 (effect of Event on Somber), which is negative on average; hence people with a lower level on somber, tend to have a b1 closer to zero, while individuals with a higher level on Somber tend to have a b1 that is more negative. Somber with b3: Individuals with relatively high person-specific means of Somber tend to have relatively high positive autoregressive effects in their Events. b3 with b4: People with relatively higher autoregressive effects for Event (b3) tend to have a relatively high b4 - Since the average b4 is negative, it means: higher autoregression for Event is a b4 closer to zero, while a lower autoregression for Event is associated with a stronger negative effect of Somber on Event. People with relatively high person-specific means for somber tend to have relatively low person-specific means for event. "],["bonus-dynamic-sem---adding-an-implicit-lag-2-effect..html", "5.5 Bonus: Dynamic SEM - adding an implicit lag 2 effect.", " 5.5 Bonus: Dynamic SEM - adding an implicit lag 2 effect. As mentioned before, due to the time interval that the variable Event is referring to, you can think of this as a variable that is situated in time between two consecutive measurements of somber. Hence the lag 0 regression (b1) is in a way already a lagged relationship, and we have therefore not included the regression of Somber at occasion t on Event at occasion t-1, but only a “concurrent” relationship of Somber t on Event t (and hence no residual correlation between the residuals of somber t and event t). However, we could add the lagged effects to the model, which would than imply an implicit ‘lag 2’ effect. We then get the following model: 5.5.1 Additional parameters How many additional parameters does this model have in comparison to the previous one? Click to show answers The mean (fixed effect) of B5 and its variance (random effect) and the covariance between this random effect and the other 6 random effects; so 8 additional parameters. 5.5.2 Run the Mplus Model &amp; Interpret the Results Run this model, and interpret the results for the fixed effects of the lagged parameters. Click to show answers Means B1 -0.162 0.014 0.000 -0.190 -0.135 * B2 0.324 0.022 0.000 0.279 0.367 * B3 0.116 0.021 0.000 0.076 0.156 * B4 -0.131 0.025 0.000 -0.182 -0.083 * B5 -0.056 0.013 0.000 -0.080 -0.029 * They all differ significantly from zero. The autoregressive parameters (b2 and b3) are positive. The cross-lagged relationships are all negative. The new lagged effect (b5: delayed effect of Event on somber) is also negative; however, it is less strong than the other effect of Event on Somber (b1). "],["bonus-dynamic-sem---adding-a-between-level-factor-structure..html", "5.6 Bonus: Dynamic SEM - adding a between level factor structure.", " 5.6 Bonus: Dynamic SEM - adding a between level factor structure. Instead of simply correlating the random effects at the between level, we may also consider modeling these variables more explicitly. For instance, we can specify a factor model to try to capture what these level 2 variables have in common. This can be represented like this: How many parameters does this model have at each level? Click to show answers Within: 2 residual variances Between: 7 residual variances for the indicators 6 factor loadings (one is fixed to 1 for scaling the latent variable) 1 latent variance for eta (mean of zero) 7 intercepts (means) for the indicators 5.6.1 Specify the Mplus Model To specify the factor model at the between level, use: %BETWEEN% eta BY somber@1 Event b1*1 b2 b3 b4 b5; (The b1*1 is required in the Mplus v8.1; it is probably not necessary any more in a future version.) While running the model, indicate how you would interpret the factor \\(\\eta\\). Click to show answers It is a latent variable which explains the shared variance among the random effects. Without further theory about what kind of latent variable would cause variation in all these random effects it is hard to give it a more meaningful label! Looking at the factor loadings may help interpret the factor here (akin to an EFA). 5.6.2 Convergence &amp; Interpret the Results If the model converged, check the parameter estimates. Which factor loadings are significant, and what do they mean? Click to show answers Between Level ETA BY SOMBER 1.000 0.000 0.000 1.000 1.000 EVENT -0.529 0.257 0.000 -1.365 -0.271 * ETA BY B1 -0.062 0.038 0.014 -0.158 -0.006 * B2 -0.016 0.055 0.353 -0.140 0.084 B3 0.095 0.058 0.020 0.005 0.249 * B4 0.078 0.063 0.069 -0.025 0.240 B5 -0.032 0.034 0.159 -0.111 0.031 People with higher eta tend to have: Higher mean levels of somberness Lower mean levels of unpleasant-pleasant Event More negative effects of Event t on Somber t (b1) (more reactive to events) Higher carry-over in Event (b3) (more intertia in event) Perhaps the latent variable could be called something like ‘negative outlook’ or ‘neuroticism’. But it would be better to apply a model like this when one has a specific theory in mind! "],["bonus-dynamic-sem---making-the-residual-variance-person-specific..html", "5.7 Bonus: Dynamic SEM - making the residual variance person-specific.", " 5.7 Bonus: Dynamic SEM - making the residual variance person-specific. In this model, we allow the residual variances to be random. This is often not an option in multilevel software, but within the Bayesian approach of DSEM this is fairly doable. We do still assume normal distributions for the random effects, which is not 100% appropriate for variances as they should not be able to become negative. To avoid issues with this, we model logtransformed random variances instead. The model is depicted below - note that we have also kept the factor structure at the between level from exercise 6: 5.7.1 Specify the Mplus Model Specify this model (or sneak a peak at our input file) and run it. While it is running, determine the number of parameters that are estimated in this model. Click to show answers Within level: 0 parameters Between level: - 9 fixed effects - 9 variances - 8 factor loadings - 1 factor variance 27 parameters in total 5.7.2 Convergence Check the trace plots for signs of nonconvergence. Are there signs that indicate convergence may be slow? Click to show answers Some of the trace plots show there is a lot of autocorrelation in the Bayesian samples (iterations) over time. This means the chains ‘mix’ slowly - the two chains are not covering each other all the time, and only move slowly along the y-axis. However, the chains do vary around the same constant (which would be the posterior mean estimate). Essentially, there is no evidence that the procedure is not converging, but that it is going relatively slowly. As a result, we’ll need more iterations than if we have lower autocorrelations. One could decide to increase the number of iterations. This can be done by simply increasing the iteration number, or by use the thin option here. When using THIN=10; Mplus saves only every tenth sample of the MCMC chain, and it also means that 10 times as many iterations are used. Thinning reduces (visible) autocorrelation in the chains, and as a result you can more easily see if the chains are mixing well. 5.7.3 Interpret the Results Consider the factor loading estimates: What do you conclude? Click to show answers Between Level ETA BY SOMBER 1.000 0.000 0.000 1.000 1.000 EVENT -0.371 0.103 0.000 -0.595 -0.187 * ETA BY B1 -0.088 0.024 0.000 -0.143 -0.047 * B2 0.046 0.048 0.153 -0.039 0.147 B3 0.060 0.040 0.051 -0.012 0.144 B4 -0.002 0.056 0.489 -0.115 0.105 B5 -0.028 0.013 0.014 -0.055 -0.004 * LOGVS 1.412 0.403 0.000 0.856 2.448 * LOGVE 0.057 0.107 0.282 -0.132 0.289 B3 no longer loads significantly on \\(\\eta\\). People with relatively high scores on \\(\\eta\\), tend to have: relatively high person-specific means for somberness relatively low person-specific means for event more negative effects of \\(Event_{t}\\) on \\(Somber_{t}\\) (b1) more negative delayed effects of \\(Event_{t-1}\\) on \\(Somber_{t}\\) (b5) Have a larger (log) residual variance for somberness Consider the R-square in the standardized results: What do you conclude? Click to show answers Within: On average across persons, 24% of the within-person variance of momentary somberness and 5% of momentary Events is explained Between: the factor eta accounts for a substantial proportion of between-person variability in average somberness (54%), direct reactivity (b1; 43%), and residual within-person variance in somberness (RVS; 45%). It accounts for a smaller proportion of variance in the average pleasantness of Events (22%) and delayed reactivity (b5; 20%). The other R-squares are closer to zero. "],["bonus-dynamic-sem---adding-a-level-2-between-level-predictor..html", "5.8 Bonus: Dynamic SEM - Adding a level 2 (between level) predictor.", " 5.8 Bonus: Dynamic SEM - Adding a level 2 (between level) predictor. Finally, we consider a between level observed predictor for the nine random effects. For instance, we may consider a personality trait like Neuroticism as a useful predictor of individual differences in person-specific average somberness, and person-specific average experienced unpleasantness-pleasantness of events. Furthermore, we can investigate whether it predicts individual differences in inertia (autoregression), reactivity (cross-lagged regressions), and residual variances. 5.8.1 Specify the Mplus Model Specify the model and run it. While it is running indicate how many parameters this model has. Click to show answers Within level: 0 parameters Between level: 9 fixed effects 9 variances 9 regression coefficients 1 mean for the between level predictor N 1 variance for the between level predictor N 29 parameters in total (….but see the next exercise) Check the number of free parameters in the output (under model fit). Is this correct? If it is not correct, which parameter is added/deleted by default by Mplus? Click to show answers It is 30 rather than 29. The additional parameter that is estimates is the covariance between the residuals of the mean Somber and mean Events at the between level. 5.8.2 Interpret the Results Interpret the resulting parameter estimates - focus on the regression coefficients of the model that was estimated. Click to show answers Between Level B1 ON NEUROTIC -0.004 0.002 0.004 -0.008 -0.001 * LOGVS ON NEUROTIC 0.051 0.016 0.001 0.019 0.082 * SOMBER ON NEUROTIC 0.056 0.011 0.000 0.035 0.077 * EVENT ON NEUROTIC -0.018 0.007 0.005 -0.032 -0.004 * People that score relatively high on Neuroticism tend to have relatively: high person-specific means for Somber low person-specific means for Event (on average less pleasant momentary events) stronger reactivity to Event (i.e., a more negative b1) larger residual variance for the variable Somber (more unexplained momentary fluctuations for Somberness) End of the exercises for Day 5. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
