[
  {
    "objectID": "day1_exercises.html",
    "href": "day1_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Measurement invariance is important if we want to compare individuals from different groups, or the means of different groups. Measurement invariance implies that two individuals from different groups who have the same latent score, have the same expected observed scores. It also means that if there are observed mean differences between two groups, these can only stem from latent mean differences.\nWhen measurement invariance does not hold, we call the test (i.e., measurement instrument) biased. We may then look for the source of the bias, and try to account for this in our analyses.\nHere we will show how to specify a sequence of models to test whether measurement invariance holds. These steps include:\n\nconfigural invariance; this implies the same model in each group without any constraints across the groups\nweak factorial invariance; this implies the factor loadings are constrained across the groups to be the same\nstrong factorial invariance; this implies the factor loadings and the intercepts are constrained to be the same across the groups, while the latent means in the second (and subsequent) group(s) are allowed to be estimated freely.\n\nWe start with drawing the model as a path diagram. The data come from Sabatelli and Bartle-Haring (2003). They obtained measures from 103 married couples regarding their marital adjustment and their family of origin. Here we analyze these data using a multiple group approach, although the individuals in the two groups are not independent of each other, and there are other approaches that would be more appropriate for this (such as described in the original paper, where the cases are couples, and the data of each couple consists of variables measured in the hubsand and other variables are measured in the wives).\nThe variables included are:\n\nSatisfaction (S): higher levels imply fewer complaints\nIntimacy (I): higher scores imply more self-disclosures, experiences of empathy and affection, and feelings of emotional closeness toward the marital partner\nFather (F): higher scores imply a better relationship between the participant and his/her father\nMother (M): higher scores imply a better relationship between the participant and his/her mother\nFather-mother (FM): higher scores a better relationship between the parents of the participant\n\nThe idea is that the first two variables measure Marital Adjustment (MA) and the latter three variables measure the quality of relationships in the Family of Origin (FO). Furthermore, it is assumed that FO is a predictor of MA.\n\n\nDraw the path diagram for this structural equation model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMeasurement part of the model: S and I are indicators of MA; F, M, and FM are indicators of FO. Structural part of the model: MA is regressed on FO.\n\n\n\n\nBefore doing the actual model that includes the structural relation between the latent variables, we start with only the measurement model; this means that we specify a two-factor model in which the latent variables are allowed to covary (i.e., a two-headed arrow between MA and FO). We use this model to investigate whether strong factorial invariance holds by testing whether the assumptions of this model hold.\n\n\n\nThe data for this exercise are included in the file named Family.dat; note it only contains the summary statistics, that is, it contains the means, standard deviations, and correlation matrices for each group (men first, then women), that were printed in the original paper. Have a look at these.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can open the data either in Mplus, or with a program like notepad. This is what you see:\n161.779 138.382 86.229 86.392 85.046\n32.936 22.749 13.390 13.679 14.382\n1\n.740 1\n.265 .422 1\n.305 .401 .791 1\n.315 .351 .662 .587 1\n155.547 137.971 82.764 85.494 81.003\n31.168 20.094 11.229 11.743 13.220\n1\n.658 1\n.288 .398 1\n.171 .295 .480 1\n.264 .305 .554 .422 1\n\n\n\n\n\n\nTypically when you have data, you will have the raw data. In that case you will have the observed variables and a grouping variable in one file. See example 5.14 in the Mplus Users Guide for how to specify the DATA and VARIABLE commands in that case.\nHere we only have the summary data. To specify the DATA and VARIABLE commands in this case, use:\nDATA:   NGROUPS ARE 2;\n        TYPE IS MEANS STD CORR;\n        FILE IS Family.dat;\n        NOBSERVATIONS ARE 103 103;\n\nVARIABLE:   NAMES ARE S I F M FM;\nWe will begin with using the automatic option in Mplus that allows us to run all three models that are needed to investigate measurement invariance. This can be done by adding:\nANALYSIS:   MODEL = CONFIGURAL METRIC SCALAR;\nwhere CONFIGURAL is the model without any constraints across the groups; METRIC is the model we refer to as weak factorial invariance, that is, equal factor loadings across groups; and SCALAR is what we refer to as strong factorial invariance, that is, equal factor loadings and intercepts across groups, and freely estimated latent means in group 2 (and subsequent groups, if there are any).\nUse the code above, and add:\n\nTITLE command\nMODEL command, in which you just specify the general factor model (so no need to specify separate models for separate groups!)\nOUTPUT command\n\nRun the model and check the output. Describe what you see.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the top menu in Mplus you can change the format of the output file by going to Mplus and choosing HTML output, and then run the model. This will result in output with links that makes it easier to navigate through it. At the beginning of the output, you get to see:\nOUTPUT SECTIONS\n\nInput Instructions \nInput Warnings And Errors \nSummary Of Analysis \nSample Statistics \nModel Fit Information \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nModel Results \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nTechnical 1 Output \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nTechnical 9 Output \nHence, we see that for each of the three models we get information about model fit, we get the parameter estimates, and the additional output (here, we asked for TECH1). We also get TECH9 which contains the warnings for the three models.\n\n\n\nWhile this automatic option is of course very convenient in practice, we will now focus in this exercise on how to specify and run these three models ourselves. The point of this is that we see how we can overrule defaults in Mplus, and we consider the models one by one (and check the TECH1 output), and consider alternative ways of scaling these models.\n\n\n\n\n\nIf we specify the model for configural invariance:\n\nhow many sample statistics are there?\nhow many free parameters are there?\nhow many df are there?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSample statistics. We have 5 observed variables in each group. Hence, we have 5*6/2 = 15 unique elements in the covariance matrix S for each group, plus 5 observed means, so 20 sample statistics per group. That makes 40 sample statistics in total.\nFree parameter. In each group we estimate:\n\n3 factor loadings (there are 5 factor loadings, but 2 are used for scaling)\n2 factor variances\n1 factor covariance\n5 residual variances\n5 intercepts\n\nThat makes 16 parameters per group; hence, 32 free parameters in total.\nDegrees of freedom. The degrees of freedom are therefore: \\(df = 40 - 32 = 8\\).\n\n\n\n\n\n\nSpecify the two-factor model for configural invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   MA BY S@1 I;\n            FO BY F@1 M FM;\n            [S I F M FM];\n            [MA@0 FO@0];\nwhere the first MODEL: command is the general model specification, and the second part MODEL g2; is overruling the multiple group factor analysis defaults through:\n\nfreeing the factor loadings (so they are not identical to the factor loadings in g1), and using @1 to ensure the factors are scaled\nfreeing the intercepts in the second group (so they are not identical to the intercepts in g1)\nfixing the latent means to zero (to ensure identification)\n\nAlternatively, one could also say:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   MA BY I;\n            FO BY M FM;\n            [S I F M FM];\n            [MA@0 FO@0];\nHere, we are doing the same thing, but not overruling the default for the factor loadings of the first indicator of each latent variable (hence the initial scaling remains in tact).\nIn addition to this MODEL command, we specify the OUTPUT command as:\nOUTPUT: TECH1 MOD(4);\n\n\n\n\n\n\nRun this model, and check whether the TECH1 output matches your answer under Question 4 regarding where the free parameters are. Also check the warning(s); is there a reason for concern?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe get this warning:\nTHE MODEL ESTIMATION TERMINATED NORMALLY\n\nWARNING:  THE RESIDUAL COVARIANCE MATRIX (THETA) IN GROUP G1 IS NOT\nPOSITIVE DEFINITE.  THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL\nVARIANCE FOR AN OBSERVED VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE\nBETWEEN TWO OBSERVED VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO\nOBSERVED VARIABLES.  CHECK THE RESULTS SECTION FOR MORE INFORMATION.\nPROBLEM INVOLVING VARIABLE I.\nThis implies that the residual covariance matrix contains a combination of numbers (i.e., parameter estimates) that are not possible in a covariance matrix. We can start with checking the relevant parameter estimates in the first group:\nResidual Variances\n  S                528.470    130.512      4.049      0.000\n  I                -39.883    109.198     -0.365      0.715\n  F                 21.613     10.983      1.968      0.049\n  M                 53.509     11.710      4.570      0.000\n  FM               103.074     16.168      6.375      0.000\nIt shows that the residual variance for the indicator I (intimacy) is negative; this is not possible (as variances are by definition zero or larger). This is referred to as a Heywood case, and is typically interpreted as meaning that the model is too complicated for the data (for instance because the model is really wrong, or because the sample size is too small). I is an indicator of MA, which only has one other indicator (i.e., S); this is often a difficult situation in terms of estimation.\nOne action we could take is setting this residual variance to zero (note the parameter is not significantly different from zero). That would mean this variable is a perfect indicator of the latent variable MA, as there would be no measurement error at all; this would in turn mean we only need this indicator, and there is no need for the second indicator to measure the latent variable.\nBut for now, we will just leave the variable in, and consider the model fit before moving on to testing weak factorial invariance.\n\n\n\n\n\n\nFor now, we ignore this warning. What is the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nChi-Square Test of Model Fit\n\n          Value                              6.025\n          Degrees of Freedom                     8    \n          P-Value                           0.6444\nThe chi-square test indicates the model fits well (note btw that the degrees of freedom are indeed 8). We see this chi-square is simply the sum of the chi-squares that are obtained for each group, as presented in the output:\nChi-Square Contribution From Each Group\n\n          G1                                 4.688\n          G2                                 1.337\nThe other fit measures also indicate the model fits very well:\nRMSEA (Root Mean Square Error Of Approximation)\n\n          Estimate                           0.000\n          90 Percent C.I.                    0.000  0.095\n          Probability RMSEA &lt;= .05           0.786\n\nCFI/TLI\n\n          CFI                                1.000\n          TLI                                1.000\n\nSRMR (Standardized Root Mean Square Residual)\n\n          Value                              0.019\n\n\n\n\n\n\n\n\n\nNext, specify the model for weak factorial invariance. How many df would this model have? Run this model and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the model for weak factorial invariance, we set the factor loadings invariant across groups, while not constraining the mean structure. In practice, this implies we no longer have to overrule the defaults for the factor loadings, but we still need to overrule the defaults for the intercepts and latent means. Hence, the model specification becomes:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   [S I F M FM];\n            [MA@0 FO@0];\nWhile in the previous model we were estimating 3 factor loadings in each group (so 6 factor loadings in total), we now estimate 3 factor loadings for both groups. Hence, this model has 3 free parameters less, and thus 3 df more than the model for configural invariance; the df should thus be 8+3=11. This also becomes clear when looking at the TECH1 output of this model (see the numbers that identify the free parameters in the matrix LAMBDA).\nWe see this in the chi-square test:\nChi-Square Test of Model Fit\n\n          Value                              8.735\n          Degrees of Freedom                    11\n          P-Value                           0.6463\nWe see indeed the number of df is 11.\n\n\n\n\n\n\nDo a chi-square difference test to determine whether the assumption of weak factorial invariance (i.e., equal factor loadings across groups) holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\(\\Delta \\chi^2 = 8.735 - 6.025 = 2.710\\)\n\\(\\Delta df = 11 - 8 = 3\\)\nHence, the chi-square difference is 2.710 with df=3. The p-value for this is 0.4385 (for an online chi-square calculator, see for instance: https://www.fourmilab.ch/rpkp/experiments/analysis/chiCalc.html).\nThis means that our H0 (i.e., weak factorial invariance) is not rejected. Put differently, the constraints for weak factorial invariance can be imposed.\n\n\n\n\n\n\n\n\n\nNext, specify the model for strong factorial invariance. Again, indicate how many df this model will have, run the model, and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nStrong factorial invariance is the default multiple group factor model that Mplus runs. Hence, it does not require us to overrule any of its defaults. Compared to the previous model, this means that it will constrain all five intercepts to be identical across the two groups, but at the same time, it will freely estimate the two latent means in the second group. Hence, the difference in df is 5-2=3; the new model with have 3 df more than the one we had before.\nThe MODEL command for this model is very simple; we only need:\nMODEL:      MA BY S I;\n            FO BY F M FM; \nThe chi-square of this model is:\nChi-Square Test of Model Fit\n\n        Value                             15.647\n        Degrees of Freedom                    14\n        P-Value                           0.3354\nWe see that indeed the df are 3 more than before (\\(11 + 3 = 14\\)).\n\n\n\n\n\n\nDo a chi-square difference test to determine whether the assumption of strong factorial invariance (i.e., equal intercepts; only latent mean differences) holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe compare the current model fit to that of the previous model (i.e., the one for weak factorial invariance), to determine whether the additional constraints are tenable.\nHence we have:\n\\(\\Delta \\chi^2 = 15.647 - 8.735 = 6.912\\)\n\\(\\Delta df = 14 - 11 = 3\\)\nA chi-square difference test of 6.912 with 3 df has a p-value of 0.0748. Hence, again, the H0 is not rejected, which now means we can assume that strong factorial invariance holds.\n\n\n\n\n\n\nCheck the TECH1 output for the latter model. How do you see the constraints that were imposed?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can see the intercepts and factor loadings are constrained across the two groups, because the same numbers are used to show which ones are estimated freely:\n         NU\n            S             I             F             M             FM\n           ________      ________      ________      ________      ________\n                1             2             3             4             5\n\n\n         LAMBDA\n           MA            FO\n            ________      ________\n S                  0             0\n I                  6             0\n F                  0             0\n M                  0             7\n FM                 0             8\n\n\n\n\n\n\n\nAbove, we have used the usual way of scaling:\n\nfirst factor loading of each latent variable fixed to 1 (in each group)\nall latent means fixed to 0 (in each group), combined with estimating the intercepts for the observed variables freely (in each group)\n\nIn this case, the step from configural to weak factorial invariance now consists of only adding more constraints, which makes it easy to see these two models are nested (i.e., the model for weak factorial invariance is nested under the model for configural invariance).\nHowever, it is less obvious that the model for strong factorial invariance is nested under the model for weak factorial invariance, because it includes constraining parameters (i.e., the intercepts have to be equal across groups), but also requires freeing parameters (i.e., the latent means in the second group are freed).\nTo ensure that these models are nested, we use an alternative way of specifying these models, based on a different way of scaling. The key issue here is that these alternative model specification are simply reparameterizations of the the same models; they are equivalent models, as we can see because they lead to the exact same model fit.\n\n\nInstead of scaling with the latent means fixed to zero and the intercepts all estimated freely, scale the latent variable in the model for configural invariance through setting the intercept for the first indicator to zero, while allowing the latent mean to be estimated freely. Compare the model fit to the one obtained above for the configural invariance model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     MA BY S@1 I;\n              FO BY F@1 M FM;\n              [S@0 I F@0 M FM];\nWhen running the model like this, it does not converge within the default number of iterations. We get this message:\nNO CONVERGENCE.  NUMBER OF ITERATIONS EXCEEDED.\nand there is no model fit, standard errors, or p-values. This can mean the model is too complicated. It can also mean you need to specify (better) starting values. As a first step, we can just increase the number of iterations, by adding:\nANALYSIS:   ITERATIONS ARE 20000;\nIn this case, this solves it, that is, the model now converges. When considering the model fit, we see it is exactly the same as that of the model discussed in Question 7.\nChi-Square Test of Model Fit\n\n          Value                              6.025\n          Degrees of Freedom                     8    \n          P-Value                           0.6444\nBecause the chi-square is exactly the same (and the df), this implies these models are statistically equivalent; they are identical, just parameterized differently. You cannot distinguish between them on statistical grounds.\nHence, this shows that this alternative way of scaling the latent variables gives a model that is equivalent.\n\n\n\n\n\n\nNext, use this alternative way of scaling and specify the model for weak factorial invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     [S@0 I F@0 M FM];\nThat is, we no longer overrule the defaults for the factor loadings. Note that for this model to converge, we do not need to increase the number of iterations.\nWhen considering the model fit, we see it is exactly the same as that of the model discussed in Question 8:\nChi-Square Test of Model Fit\n\n          Value                              8.735\n          Degrees of Freedom                    11\n          P-Value                           0.6463\nThis means that the current model is statistically equivalent to the model we had before to impose weak factorial invariance.\n\n\n\n\n\n\nAnd now, the Moment Suprême: We will specify the model for strong factorial invariance using this alternative way of scaling. The key issue to notice here is that in going from weak factorial invariance to strong factorial invariance, we will now only add constraints, which makes it very clear that the latter model must be nested under the former.\nRemember that before, we were adding constraints (i.e., fixing the intercepts to be identical across the groups), but also were freeing parameters (i.e., allowing the latent means in the second group to be estimated freely); this makes it difficult to see that the model for strong factorial invariance is nested under that of weak factorial invariance.\nBut with this alternative way of scaling, which leads to statistically equivalant models (i.e., models with the exact fit, and which are thus indistinguishable), we now only add constraints on parameters when going from weak to strong factorial invariance, such that it is very obvious that (and how) they are nested.\nSpecify the model for strong factorial invariance using this alternative way of scaling.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     [S@0 F@0];\nThis model leads to the exactly same model fit as that of the model discussed in Question 10:\nChi-Square Test of Model Fit\n\n          Value                             15.647\n          Degrees of Freedom                    14\n          P-Value                           0.3354\nThis means that the current model is statistically equivalent to the model we had before to impose strong factorial invariance. This also means that we can now be certain that the model for strong factorial invariance is nested under the model for weak factorial invariance; this means we can do a chi-square difference test to compare them (as we already did above).\n\n\n\n\n\n\nWhile this alternative way of specifying the series of models is useful to seeing their nestedness, the first way of specifying the models also has advantages. One of these advantages is that it requires fewer defaults to be overruled. But more importantly, it allows us to easily determine in the strong factorial invariance model whether there are latent mean differences between the groups. Report and interpret these.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the first approach, the model for strong factorial invariance is based on constraining the factor loadings and intercepts across the groups, and freeing the latent means in the second group, while the means in the first group are fixed to zero.\nThat is, for G1 we get:\nMeans\n    MA                 0.000      0.000    999.000    999.000\n    FO                 0.000      0.000    999.000    999.000\nand for G2 we get:\nMeans\n    MA                -0.415      3.118     -0.133      0.894\n    FO                -3.140      1.655     -1.898      0.058\nThis implies that the significance test of the latter can be used to determine whether there are latent mean differences between the second and the first group. Here we get a p-value of 0.894 for MA, and a p-value of 0.058 for FO; hence for both we do not find evidence that they differ from zero, which means that for both we do not find evidence that the two groups differ.\n\n\n\n\n\n\n\nAs both the test for weak and for strong factorial invariance were non-significant, we can conclude that strong factorial invariance holds. This means we can compare individuals from these groups, and we can compare the means of these groups. It also means that the constructs “Marital Adjustment” and “Family of Origin” are measured in the same way in these two groups, and that we can specify a structural model for these latent variables in the two groups to investigate how they are related.\n\n\nSpecify the model as initially intended, with FO as a predictor of MA at the latent level, while assuming strong factorial invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model is now specified as:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n            MA ON FO;\n\n\n\n\n\n\nRun this model, and compare the model fit to that of the model for strong factorial invariance that we had before. What do you conclude?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThese models have the exact same model fit (same chi-square and df). This means these models are statistically equivalent. Hence, it does not matter whether you estimate the covariance between the two latent variables, or a regression coefficient.\n\n\n\n\n\n\nWhen comparing the TECH1 output of these two models, what difference do you spot?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the two-factor model we have for G1:\n          BETA\n              MA            FO\n              ________      ________\n MA                 0             0\n FO                 0             0\n\n\n           PSI\n              MA            FO\n              ________      ________\n MA                14\n FO                15            16\nthat is, no structural parameters, and a covariance is Psi; in contrast in the regression model we have for G1:\n               BETA\n                  MA            FO\n                  ________      ________\n     MA                 0            14\n     FO                 0             0\n\n\n               PSI\n                  MA            FO\n                  ________      ________\n     MA                15\n     FO                 0            16\nshowing there is a structural parameter in Beta (going to MA, coming from FO), and there is no covariance estimated in Psi. The same is true for G2.\n\n\n\n\n\n\nAs a final step, we want to investigate whether the regression coefficient is different in the two groups or not. How can you investigate this?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the model above, the regression parameter was not constrained across the groups. We can now specify a model in which we constrain the parameter to be invariant across the two groups; that model will be nested under the previous model, and we can thus do a chi-square difference test to see whether the constraint holds.\nTo constrain the parameter across the groups, we only have to give it a label (i.e., a name). Here we will give it the label c (you could als give it a longer name, such as coeff). The model is now specified as:\n        MODEL:      MA BY S I;\n                    FO BY F M FM; \n                    MA ON FO (c);\nTo see that this leads to having the same regression coefficient in both groups, we can check the TECH1 output. For G1 we have (only showing part of it):\n           ALPHA\n              MA            FO\n              ________      ________\n                    0             0\n\n\n           BETA\n               MA            FO\n              ________      ________\n MA                 0            14\n FO                 0             0\n\n\n          PSI\n             MA            FO\n              ________      ________\n MA                15\n FO                 0            16\nand for G2:\n         ALPHA\n             MA            FO\n             ________      ________\n                  22            23\n\n\n          BETA\n              MA            FO\n              ________      ________\n MA                 0            14\n FO                 0             0\n\n\n           PSI\n              MA            FO\n              ________      ________\n MA                24\n FO                 0            25\nIt shows that the structural parameter in both cases is the same parameter (number 14).\nThe model fit is:\nChi-Square Test of Model Fit\n\n          Value                             16.315\n          Degrees of Freedom                    15\n          P-Value                           0.3614\nshowing it has 1 df more than the model we had before (because we estimate 1 parameter less). Doing a chi-square difference test we get:\n\\(\\Delta \\chi^2 = 16.315 - 15.647 = 0.688\\) with \\(df-1\\), which gives a p-value of 0.4137, which means the test is not significant. Hence, H0 does not have to be rejected, and we can therefore assume that the regression coefficient is identical across the two groups.\n\n\n\n\n\n\n\nTo summarize what we did in this exercise:\n\nwe were interested in investigating a full SEM model (with both a measurement model and a structural model), in two groups\nbefore we could investigate the structural part of the model (i.e., the latent regression), we had to determine whether there was measurement invariance across the groups\nto this end we ran a series of three models: configural invariance, weak factorial invariance and strong factorial invariance; these models are increasingly more restrictive, and we compared each subsequent model with the preceding one (using a chi-square different test) to see whether the additional constraints were tenable\nsince neither of the two chi-square difference test reached significance, we can conclude that strong factorial invariance holds; this means we are measuring the same constructs in both groups, and we can compare their latent means\nwe also considered an alternative way to scale the models (based on setting one of the intercepts per factor to zero, rather than the latent means), which more clearly shows that the model for strong factorial invariance is a special case of the model for weak factorial invariance\nthe first way of scaling has the advantage that we can immediately see whether the means of the two groups on the latent variables differ or not; here we found no significant difference\nsince the latent variables are measured in the same way in both groups, we continue with our actual research question, which concerns the latent regression model; regressing the latent variables on each other resulted in a model that is equivalent to the model for strong factorial invariance\nsubsequently, we constrained the regression coefficient across the two groups to see whether the effect of family of origin (FO) has the same effect on marital adjustment (MA) in the two groups; again, by doing a chi-square difference test we could determine whether or not this constraint was tenable; since the test was not significant, we may assume that the two regression slopes are the same across the groups\nnote that in the end, we still have the same warning as for the first model about a Heywood case (negative variance) in the first group; we should present such results in a paper; we could constrain this variance to zero (and we could do the same thing in the other group, because it is not significantly different from zero there either), which would make this indicator and the latent variable it measures identical; put differently, this implies that we can measure marital adjustment with this one variable, and we do not need the other one for it"
  },
  {
    "objectID": "day1_exercises.html#measurement-invariance",
    "href": "day1_exercises.html#measurement-invariance",
    "title": "Exercises",
    "section": "",
    "text": "Measurement invariance is important if we want to compare individuals from different groups, or the means of different groups. Measurement invariance implies that two individuals from different groups who have the same latent score, have the same expected observed scores. It also means that if there are observed mean differences between two groups, these can only stem from latent mean differences.\nWhen measurement invariance does not hold, we call the test (i.e., measurement instrument) biased. We may then look for the source of the bias, and try to account for this in our analyses.\nHere we will show how to specify a sequence of models to test whether measurement invariance holds. These steps include:\n\nconfigural invariance; this implies the same model in each group without any constraints across the groups\nweak factorial invariance; this implies the factor loadings are constrained across the groups to be the same\nstrong factorial invariance; this implies the factor loadings and the intercepts are constrained to be the same across the groups, while the latent means in the second (and subsequent) group(s) are allowed to be estimated freely.\n\nWe start with drawing the model as a path diagram. The data come from Sabatelli and Bartle-Haring (2003). They obtained measures from 103 married couples regarding their marital adjustment and their family of origin. Here we analyze these data using a multiple group approach, although the individuals in the two groups are not independent of each other, and there are other approaches that would be more appropriate for this (such as described in the original paper, where the cases are couples, and the data of each couple consists of variables measured in the hubsand and other variables are measured in the wives).\nThe variables included are:\n\nSatisfaction (S): higher levels imply fewer complaints\nIntimacy (I): higher scores imply more self-disclosures, experiences of empathy and affection, and feelings of emotional closeness toward the marital partner\nFather (F): higher scores imply a better relationship between the participant and his/her father\nMother (M): higher scores imply a better relationship between the participant and his/her mother\nFather-mother (FM): higher scores a better relationship between the parents of the participant\n\nThe idea is that the first two variables measure Marital Adjustment (MA) and the latter three variables measure the quality of relationships in the Family of Origin (FO). Furthermore, it is assumed that FO is a predictor of MA.\n\n\nDraw the path diagram for this structural equation model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMeasurement part of the model: S and I are indicators of MA; F, M, and FM are indicators of FO. Structural part of the model: MA is regressed on FO.\n\n\n\n\nBefore doing the actual model that includes the structural relation between the latent variables, we start with only the measurement model; this means that we specify a two-factor model in which the latent variables are allowed to covary (i.e., a two-headed arrow between MA and FO). We use this model to investigate whether strong factorial invariance holds by testing whether the assumptions of this model hold.\n\n\n\nThe data for this exercise are included in the file named Family.dat; note it only contains the summary statistics, that is, it contains the means, standard deviations, and correlation matrices for each group (men first, then women), that were printed in the original paper. Have a look at these.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can open the data either in Mplus, or with a program like notepad. This is what you see:\n161.779 138.382 86.229 86.392 85.046\n32.936 22.749 13.390 13.679 14.382\n1\n.740 1\n.265 .422 1\n.305 .401 .791 1\n.315 .351 .662 .587 1\n155.547 137.971 82.764 85.494 81.003\n31.168 20.094 11.229 11.743 13.220\n1\n.658 1\n.288 .398 1\n.171 .295 .480 1\n.264 .305 .554 .422 1\n\n\n\n\n\n\nTypically when you have data, you will have the raw data. In that case you will have the observed variables and a grouping variable in one file. See example 5.14 in the Mplus Users Guide for how to specify the DATA and VARIABLE commands in that case.\nHere we only have the summary data. To specify the DATA and VARIABLE commands in this case, use:\nDATA:   NGROUPS ARE 2;\n        TYPE IS MEANS STD CORR;\n        FILE IS Family.dat;\n        NOBSERVATIONS ARE 103 103;\n\nVARIABLE:   NAMES ARE S I F M FM;\nWe will begin with using the automatic option in Mplus that allows us to run all three models that are needed to investigate measurement invariance. This can be done by adding:\nANALYSIS:   MODEL = CONFIGURAL METRIC SCALAR;\nwhere CONFIGURAL is the model without any constraints across the groups; METRIC is the model we refer to as weak factorial invariance, that is, equal factor loadings across groups; and SCALAR is what we refer to as strong factorial invariance, that is, equal factor loadings and intercepts across groups, and freely estimated latent means in group 2 (and subsequent groups, if there are any).\nUse the code above, and add:\n\nTITLE command\nMODEL command, in which you just specify the general factor model (so no need to specify separate models for separate groups!)\nOUTPUT command\n\nRun the model and check the output. Describe what you see.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the top menu in Mplus you can change the format of the output file by going to Mplus and choosing HTML output, and then run the model. This will result in output with links that makes it easier to navigate through it. At the beginning of the output, you get to see:\nOUTPUT SECTIONS\n\nInput Instructions \nInput Warnings And Errors \nSummary Of Analysis \nSample Statistics \nModel Fit Information \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nModel Results \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nTechnical 1 Output \n- For The Configural Model \n- For The Metric Model \n- For The Scalar Model \nTechnical 9 Output \nHence, we see that for each of the three models we get information about model fit, we get the parameter estimates, and the additional output (here, we asked for TECH1). We also get TECH9 which contains the warnings for the three models.\n\n\n\nWhile this automatic option is of course very convenient in practice, we will now focus in this exercise on how to specify and run these three models ourselves. The point of this is that we see how we can overrule defaults in Mplus, and we consider the models one by one (and check the TECH1 output), and consider alternative ways of scaling these models.\n\n\n\n\n\nIf we specify the model for configural invariance:\n\nhow many sample statistics are there?\nhow many free parameters are there?\nhow many df are there?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSample statistics. We have 5 observed variables in each group. Hence, we have 5*6/2 = 15 unique elements in the covariance matrix S for each group, plus 5 observed means, so 20 sample statistics per group. That makes 40 sample statistics in total.\nFree parameter. In each group we estimate:\n\n3 factor loadings (there are 5 factor loadings, but 2 are used for scaling)\n2 factor variances\n1 factor covariance\n5 residual variances\n5 intercepts\n\nThat makes 16 parameters per group; hence, 32 free parameters in total.\nDegrees of freedom. The degrees of freedom are therefore: \\(df = 40 - 32 = 8\\).\n\n\n\n\n\n\nSpecify the two-factor model for configural invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   MA BY S@1 I;\n            FO BY F@1 M FM;\n            [S I F M FM];\n            [MA@0 FO@0];\nwhere the first MODEL: command is the general model specification, and the second part MODEL g2; is overruling the multiple group factor analysis defaults through:\n\nfreeing the factor loadings (so they are not identical to the factor loadings in g1), and using @1 to ensure the factors are scaled\nfreeing the intercepts in the second group (so they are not identical to the intercepts in g1)\nfixing the latent means to zero (to ensure identification)\n\nAlternatively, one could also say:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   MA BY I;\n            FO BY M FM;\n            [S I F M FM];\n            [MA@0 FO@0];\nHere, we are doing the same thing, but not overruling the default for the factor loadings of the first indicator of each latent variable (hence the initial scaling remains in tact).\nIn addition to this MODEL command, we specify the OUTPUT command as:\nOUTPUT: TECH1 MOD(4);\n\n\n\n\n\n\nRun this model, and check whether the TECH1 output matches your answer under Question 4 regarding where the free parameters are. Also check the warning(s); is there a reason for concern?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe get this warning:\nTHE MODEL ESTIMATION TERMINATED NORMALLY\n\nWARNING:  THE RESIDUAL COVARIANCE MATRIX (THETA) IN GROUP G1 IS NOT\nPOSITIVE DEFINITE.  THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL\nVARIANCE FOR AN OBSERVED VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE\nBETWEEN TWO OBSERVED VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO\nOBSERVED VARIABLES.  CHECK THE RESULTS SECTION FOR MORE INFORMATION.\nPROBLEM INVOLVING VARIABLE I.\nThis implies that the residual covariance matrix contains a combination of numbers (i.e., parameter estimates) that are not possible in a covariance matrix. We can start with checking the relevant parameter estimates in the first group:\nResidual Variances\n  S                528.470    130.512      4.049      0.000\n  I                -39.883    109.198     -0.365      0.715\n  F                 21.613     10.983      1.968      0.049\n  M                 53.509     11.710      4.570      0.000\n  FM               103.074     16.168      6.375      0.000\nIt shows that the residual variance for the indicator I (intimacy) is negative; this is not possible (as variances are by definition zero or larger). This is referred to as a Heywood case, and is typically interpreted as meaning that the model is too complicated for the data (for instance because the model is really wrong, or because the sample size is too small). I is an indicator of MA, which only has one other indicator (i.e., S); this is often a difficult situation in terms of estimation.\nOne action we could take is setting this residual variance to zero (note the parameter is not significantly different from zero). That would mean this variable is a perfect indicator of the latent variable MA, as there would be no measurement error at all; this would in turn mean we only need this indicator, and there is no need for the second indicator to measure the latent variable.\nBut for now, we will just leave the variable in, and consider the model fit before moving on to testing weak factorial invariance.\n\n\n\n\n\n\nFor now, we ignore this warning. What is the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nChi-Square Test of Model Fit\n\n          Value                              6.025\n          Degrees of Freedom                     8    \n          P-Value                           0.6444\nThe chi-square test indicates the model fits well (note btw that the degrees of freedom are indeed 8). We see this chi-square is simply the sum of the chi-squares that are obtained for each group, as presented in the output:\nChi-Square Contribution From Each Group\n\n          G1                                 4.688\n          G2                                 1.337\nThe other fit measures also indicate the model fits very well:\nRMSEA (Root Mean Square Error Of Approximation)\n\n          Estimate                           0.000\n          90 Percent C.I.                    0.000  0.095\n          Probability RMSEA &lt;= .05           0.786\n\nCFI/TLI\n\n          CFI                                1.000\n          TLI                                1.000\n\nSRMR (Standardized Root Mean Square Residual)\n\n          Value                              0.019\n\n\n\n\n\n\n\n\n\nNext, specify the model for weak factorial invariance. How many df would this model have? Run this model and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the model for weak factorial invariance, we set the factor loadings invariant across groups, while not constraining the mean structure. In practice, this implies we no longer have to overrule the defaults for the factor loadings, but we still need to overrule the defaults for the intercepts and latent means. Hence, the model specification becomes:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n\nMODEL g2:   [S I F M FM];\n            [MA@0 FO@0];\nWhile in the previous model we were estimating 3 factor loadings in each group (so 6 factor loadings in total), we now estimate 3 factor loadings for both groups. Hence, this model has 3 free parameters less, and thus 3 df more than the model for configural invariance; the df should thus be 8+3=11. This also becomes clear when looking at the TECH1 output of this model (see the numbers that identify the free parameters in the matrix LAMBDA).\nWe see this in the chi-square test:\nChi-Square Test of Model Fit\n\n          Value                              8.735\n          Degrees of Freedom                    11\n          P-Value                           0.6463\nWe see indeed the number of df is 11.\n\n\n\n\n\n\nDo a chi-square difference test to determine whether the assumption of weak factorial invariance (i.e., equal factor loadings across groups) holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\(\\Delta \\chi^2 = 8.735 - 6.025 = 2.710\\)\n\\(\\Delta df = 11 - 8 = 3\\)\nHence, the chi-square difference is 2.710 with df=3. The p-value for this is 0.4385 (for an online chi-square calculator, see for instance: https://www.fourmilab.ch/rpkp/experiments/analysis/chiCalc.html).\nThis means that our H0 (i.e., weak factorial invariance) is not rejected. Put differently, the constraints for weak factorial invariance can be imposed.\n\n\n\n\n\n\n\n\n\nNext, specify the model for strong factorial invariance. Again, indicate how many df this model will have, run the model, and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nStrong factorial invariance is the default multiple group factor model that Mplus runs. Hence, it does not require us to overrule any of its defaults. Compared to the previous model, this means that it will constrain all five intercepts to be identical across the two groups, but at the same time, it will freely estimate the two latent means in the second group. Hence, the difference in df is 5-2=3; the new model with have 3 df more than the one we had before.\nThe MODEL command for this model is very simple; we only need:\nMODEL:      MA BY S I;\n            FO BY F M FM; \nThe chi-square of this model is:\nChi-Square Test of Model Fit\n\n        Value                             15.647\n        Degrees of Freedom                    14\n        P-Value                           0.3354\nWe see that indeed the df are 3 more than before (\\(11 + 3 = 14\\)).\n\n\n\n\n\n\nDo a chi-square difference test to determine whether the assumption of strong factorial invariance (i.e., equal intercepts; only latent mean differences) holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe compare the current model fit to that of the previous model (i.e., the one for weak factorial invariance), to determine whether the additional constraints are tenable.\nHence we have:\n\\(\\Delta \\chi^2 = 15.647 - 8.735 = 6.912\\)\n\\(\\Delta df = 14 - 11 = 3\\)\nA chi-square difference test of 6.912 with 3 df has a p-value of 0.0748. Hence, again, the H0 is not rejected, which now means we can assume that strong factorial invariance holds.\n\n\n\n\n\n\nCheck the TECH1 output for the latter model. How do you see the constraints that were imposed?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can see the intercepts and factor loadings are constrained across the two groups, because the same numbers are used to show which ones are estimated freely:\n         NU\n            S             I             F             M             FM\n           ________      ________      ________      ________      ________\n                1             2             3             4             5\n\n\n         LAMBDA\n           MA            FO\n            ________      ________\n S                  0             0\n I                  6             0\n F                  0             0\n M                  0             7\n FM                 0             8\n\n\n\n\n\n\n\nAbove, we have used the usual way of scaling:\n\nfirst factor loading of each latent variable fixed to 1 (in each group)\nall latent means fixed to 0 (in each group), combined with estimating the intercepts for the observed variables freely (in each group)\n\nIn this case, the step from configural to weak factorial invariance now consists of only adding more constraints, which makes it easy to see these two models are nested (i.e., the model for weak factorial invariance is nested under the model for configural invariance).\nHowever, it is less obvious that the model for strong factorial invariance is nested under the model for weak factorial invariance, because it includes constraining parameters (i.e., the intercepts have to be equal across groups), but also requires freeing parameters (i.e., the latent means in the second group are freed).\nTo ensure that these models are nested, we use an alternative way of specifying these models, based on a different way of scaling. The key issue here is that these alternative model specification are simply reparameterizations of the the same models; they are equivalent models, as we can see because they lead to the exact same model fit.\n\n\nInstead of scaling with the latent means fixed to zero and the intercepts all estimated freely, scale the latent variable in the model for configural invariance through setting the intercept for the first indicator to zero, while allowing the latent mean to be estimated freely. Compare the model fit to the one obtained above for the configural invariance model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     MA BY S@1 I;\n              FO BY F@1 M FM;\n              [S@0 I F@0 M FM];\nWhen running the model like this, it does not converge within the default number of iterations. We get this message:\nNO CONVERGENCE.  NUMBER OF ITERATIONS EXCEEDED.\nand there is no model fit, standard errors, or p-values. This can mean the model is too complicated. It can also mean you need to specify (better) starting values. As a first step, we can just increase the number of iterations, by adding:\nANALYSIS:   ITERATIONS ARE 20000;\nIn this case, this solves it, that is, the model now converges. When considering the model fit, we see it is exactly the same as that of the model discussed in Question 7.\nChi-Square Test of Model Fit\n\n          Value                              6.025\n          Degrees of Freedom                     8    \n          P-Value                           0.6444\nBecause the chi-square is exactly the same (and the df), this implies these models are statistically equivalent; they are identical, just parameterized differently. You cannot distinguish between them on statistical grounds.\nHence, this shows that this alternative way of scaling the latent variables gives a model that is equivalent.\n\n\n\n\n\n\nNext, use this alternative way of scaling and specify the model for weak factorial invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     [S@0 I F@0 M FM];\nThat is, we no longer overrule the defaults for the factor loadings. Note that for this model to converge, we do not need to increase the number of iterations.\nWhen considering the model fit, we see it is exactly the same as that of the model discussed in Question 8:\nChi-Square Test of Model Fit\n\n          Value                              8.735\n          Degrees of Freedom                    11\n          P-Value                           0.6463\nThis means that the current model is statistically equivalent to the model we had before to impose weak factorial invariance.\n\n\n\n\n\n\nAnd now, the Moment Suprême: We will specify the model for strong factorial invariance using this alternative way of scaling. The key issue to notice here is that in going from weak factorial invariance to strong factorial invariance, we will now only add constraints, which makes it very clear that the latter model must be nested under the former.\nRemember that before, we were adding constraints (i.e., fixing the intercepts to be identical across the groups), but also were freeing parameters (i.e., allowing the latent means in the second group to be estimated freely); this makes it difficult to see that the model for strong factorial invariance is nested under that of weak factorial invariance.\nBut with this alternative way of scaling, which leads to statistically equivalant models (i.e., models with the exact fit, and which are thus indistinguishable), we now only add constraints on parameters when going from weak to strong factorial invariance, such that it is very obvious that (and how) they are nested.\nSpecify the model for strong factorial invariance using this alternative way of scaling.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe MODEL command can be specified as:\nMODEL:        MA BY S I;\n              FO BY F M FM;\n\nMODEL g1:     [S@0 F@0];\n              [MA FO];\n\nMODEL g2:     [S@0 F@0];\nThis model leads to the exactly same model fit as that of the model discussed in Question 10:\nChi-Square Test of Model Fit\n\n          Value                             15.647\n          Degrees of Freedom                    14\n          P-Value                           0.3354\nThis means that the current model is statistically equivalent to the model we had before to impose strong factorial invariance. This also means that we can now be certain that the model for strong factorial invariance is nested under the model for weak factorial invariance; this means we can do a chi-square difference test to compare them (as we already did above).\n\n\n\n\n\n\nWhile this alternative way of specifying the series of models is useful to seeing their nestedness, the first way of specifying the models also has advantages. One of these advantages is that it requires fewer defaults to be overruled. But more importantly, it allows us to easily determine in the strong factorial invariance model whether there are latent mean differences between the groups. Report and interpret these.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the first approach, the model for strong factorial invariance is based on constraining the factor loadings and intercepts across the groups, and freeing the latent means in the second group, while the means in the first group are fixed to zero.\nThat is, for G1 we get:\nMeans\n    MA                 0.000      0.000    999.000    999.000\n    FO                 0.000      0.000    999.000    999.000\nand for G2 we get:\nMeans\n    MA                -0.415      3.118     -0.133      0.894\n    FO                -3.140      1.655     -1.898      0.058\nThis implies that the significance test of the latter can be used to determine whether there are latent mean differences between the second and the first group. Here we get a p-value of 0.894 for MA, and a p-value of 0.058 for FO; hence for both we do not find evidence that they differ from zero, which means that for both we do not find evidence that the two groups differ.\n\n\n\n\n\n\n\nAs both the test for weak and for strong factorial invariance were non-significant, we can conclude that strong factorial invariance holds. This means we can compare individuals from these groups, and we can compare the means of these groups. It also means that the constructs “Marital Adjustment” and “Family of Origin” are measured in the same way in these two groups, and that we can specify a structural model for these latent variables in the two groups to investigate how they are related.\n\n\nSpecify the model as initially intended, with FO as a predictor of MA at the latent level, while assuming strong factorial invariance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model is now specified as:\nMODEL:      MA BY S I;\n            FO BY F M FM; \n            MA ON FO;\n\n\n\n\n\n\nRun this model, and compare the model fit to that of the model for strong factorial invariance that we had before. What do you conclude?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThese models have the exact same model fit (same chi-square and df). This means these models are statistically equivalent. Hence, it does not matter whether you estimate the covariance between the two latent variables, or a regression coefficient.\n\n\n\n\n\n\nWhen comparing the TECH1 output of these two models, what difference do you spot?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the two-factor model we have for G1:\n          BETA\n              MA            FO\n              ________      ________\n MA                 0             0\n FO                 0             0\n\n\n           PSI\n              MA            FO\n              ________      ________\n MA                14\n FO                15            16\nthat is, no structural parameters, and a covariance is Psi; in contrast in the regression model we have for G1:\n               BETA\n                  MA            FO\n                  ________      ________\n     MA                 0            14\n     FO                 0             0\n\n\n               PSI\n                  MA            FO\n                  ________      ________\n     MA                15\n     FO                 0            16\nshowing there is a structural parameter in Beta (going to MA, coming from FO), and there is no covariance estimated in Psi. The same is true for G2.\n\n\n\n\n\n\nAs a final step, we want to investigate whether the regression coefficient is different in the two groups or not. How can you investigate this?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the model above, the regression parameter was not constrained across the groups. We can now specify a model in which we constrain the parameter to be invariant across the two groups; that model will be nested under the previous model, and we can thus do a chi-square difference test to see whether the constraint holds.\nTo constrain the parameter across the groups, we only have to give it a label (i.e., a name). Here we will give it the label c (you could als give it a longer name, such as coeff). The model is now specified as:\n        MODEL:      MA BY S I;\n                    FO BY F M FM; \n                    MA ON FO (c);\nTo see that this leads to having the same regression coefficient in both groups, we can check the TECH1 output. For G1 we have (only showing part of it):\n           ALPHA\n              MA            FO\n              ________      ________\n                    0             0\n\n\n           BETA\n               MA            FO\n              ________      ________\n MA                 0            14\n FO                 0             0\n\n\n          PSI\n             MA            FO\n              ________      ________\n MA                15\n FO                 0            16\nand for G2:\n         ALPHA\n             MA            FO\n             ________      ________\n                  22            23\n\n\n          BETA\n              MA            FO\n              ________      ________\n MA                 0            14\n FO                 0             0\n\n\n           PSI\n              MA            FO\n              ________      ________\n MA                24\n FO                 0            25\nIt shows that the structural parameter in both cases is the same parameter (number 14).\nThe model fit is:\nChi-Square Test of Model Fit\n\n          Value                             16.315\n          Degrees of Freedom                    15\n          P-Value                           0.3614\nshowing it has 1 df more than the model we had before (because we estimate 1 parameter less). Doing a chi-square difference test we get:\n\\(\\Delta \\chi^2 = 16.315 - 15.647 = 0.688\\) with \\(df-1\\), which gives a p-value of 0.4137, which means the test is not significant. Hence, H0 does not have to be rejected, and we can therefore assume that the regression coefficient is identical across the two groups.\n\n\n\n\n\n\n\nTo summarize what we did in this exercise:\n\nwe were interested in investigating a full SEM model (with both a measurement model and a structural model), in two groups\nbefore we could investigate the structural part of the model (i.e., the latent regression), we had to determine whether there was measurement invariance across the groups\nto this end we ran a series of three models: configural invariance, weak factorial invariance and strong factorial invariance; these models are increasingly more restrictive, and we compared each subsequent model with the preceding one (using a chi-square different test) to see whether the additional constraints were tenable\nsince neither of the two chi-square difference test reached significance, we can conclude that strong factorial invariance holds; this means we are measuring the same constructs in both groups, and we can compare their latent means\nwe also considered an alternative way to scale the models (based on setting one of the intercepts per factor to zero, rather than the latent means), which more clearly shows that the model for strong factorial invariance is a special case of the model for weak factorial invariance\nthe first way of scaling has the advantage that we can immediately see whether the means of the two groups on the latent variables differ or not; here we found no significant difference\nsince the latent variables are measured in the same way in both groups, we continue with our actual research question, which concerns the latent regression model; regressing the latent variables on each other resulted in a model that is equivalent to the model for strong factorial invariance\nsubsequently, we constrained the regression coefficient across the two groups to see whether the effect of family of origin (FO) has the same effect on marital adjustment (MA) in the two groups; again, by doing a chi-square difference test we could determine whether or not this constraint was tenable; since the test was not significant, we may assume that the two regression slopes are the same across the groups\nnote that in the end, we still have the same warning as for the first model about a Heywood case (negative variance) in the first group; we should present such results in a paper; we could constrain this variance to zero (and we could do the same thing in the other group, because it is not significantly different from zero there either), which would make this indicator and the latent variable it measures identical; put differently, this implies that we can measure marital adjustment with this one variable, and we do not need the other one for it"
  },
  {
    "objectID": "day1_exercises.html#path-analysis",
    "href": "day1_exercises.html#path-analysis",
    "title": "Exercises",
    "section": "Path analysis",
    "text": "Path analysis\nIn this exercise, we consider a path model in which observed variables are regressed on each other. The data come from the paper Hale et al. (2005). We collected the means, standard deviations, and correlation matrix from that paper for the group of older boys (n=275) in the file BoysDep.dat. We have the following four variables (in this order):\n\nperceived parental rejection (PPR)\nadolescent depression (AD)\nadolescent aggression (AA)\nadolescent withdrawal (AW)\n\nThe model that the researchers proposed, is presented below: Their question is whether perceived parental rejection (meaning the adolescent feels rejected by the parents), leads adolescents to feel sad (as operationalized with adolescent withdrawal), or mad (as operationalized with adolescent aggression), and to what extent these effects are mediated through adolescent depression.\n\n\n\nThe path model proposed by Hale et al. (2005)\n\n\n\nQuestion 1\nDetermine: a) how many sample statistics there are; b) how many free parameters there are: and c) how many degrees of freedom this model has.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are four observed variables, so \\(\\frac{4 \\times 5}{2} = 10\\) unique elements in the covariance matrix S, and 4 observed means; that makes 14 sample statistics in total.\nThe number of free parameters in this model are: 1 variance of the exogenous variable (PPR), 3 residual variance of the endogenous variables (AD, AA and AW), 5 structural parameters (i.e., regression coefficients), 1 mean for the exogenous variable (PPR), and 3 intercepts for the endogenous variables (AD, AA, and AW). That makes 13 free parameters in total.\nThe number of degrees of freedom should therefor equal \\(14 - 13 = 1\\).\n\n\n\n\n\nQuestion 2\nTo specify the above model, make use of this code for the DATA command:\nDATA:       TYPE IS MEANS STDEVIATIONS CORRELATION;\n            FILE = BoysDep.dat;  \n            NOBSERVATIONS = 275;\nNote that when we have summary data, we have to tell Mplus how many observations there are, because it is not possible to know this in any other way.\nAlso, make use of this code for the MODEL command:\nMODEL:      AD ON PPR;\n            AA ON AD PPR;\n            AW ON AD PPR;        \nFinish the code and run the model. Consider the model fit results: Do they make sense to you?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBelow are the two most notable parts of the model fit output.\nMODEL FIT INFORMATION\n\nNumber of Free Parameters                       12\n\n...\n\nChi-Square Test of Model Fit\n\n          Value                              0.000\n          Degrees of Freedom                     0\n          P-Value                           0.0000\nIt indicates that there are 12, rather than 13, free parameters, and that there are 0, rather than 1, degree of freedom. At first sight, this makes no sense: 12+0=12, but this should equal the number of sample statistics, which we determined is 14.\n\n\n\n\n\nQuestion 3\nThere are actually two things going on at once here. Check the TECH1 output to see whether you can figure out what the two issues are.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nConsidering the first three matrices in TECH1:\nTECHNICAL 1 OUTPUT\n\n     PARAMETER SPECIFICATION\n\n           NU\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n                  0             0             0             0\n\n           LAMBDA\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n AD                 0             0             0             0\n AA                 0             0             0             0\n AW                 0             0             0             0\n PPR                0             0             0             0\n\n\n           THETA\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n AD                 0\n AA                 0             0\n AW                 0             0             0\n PPR                0             0             0             0\nThese three matrices are associated with the measurement equation and contain no free parameters for a path model.\nConsider the second set of three model matrices:\n           ALPHA\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n                  1             2             3             0\n\n\n           BETA\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n AD                 0             0             0             4\n AA                 5             0             0             6\n AW                 7             0             0             8\n PPR                0             0             0             0\n\n\n           PSI\n              AD            AA            AW            PPR\n              ________      ________      ________      ________\n AD                 9\n AA                 0            10\n AW                 0            11            12\n PPR                0             0             0             0\nHere we see where the free parameters are (adding up to 12, which was the number indicated in the Mplus output). There are three things to notice here:\n\nthe order of the variables has been changed by Mplus, and the exogenous variable PPR is placed at the end in these matrices; this may be somewhat inconvenient when looking at these matrices, but is not a problem\nthe mean and the variance for this exogenous variable are not counted as free parameters; this is because they are exactly the same as the observed mean and variance, which in turn are not counted as sample statistics (hence, the free parameters + df add up to 12 rather than 14); while this does not affect model fit here, we can decide to overrule this, asking for the means and/or variance of PPR, which changes its status to endogenous\nthere is a covariance between the residuals of AW and AA (the off-diagonal element, parameter 11 in the Psi matrix); apparently, this is a default that Mplus imposes for path models, that the variables at the end (i.e., the endogenous variables that are only dependent variables, and do not predict anything themselves) have correlated residuals; if we don’t want that, we have to actively set this covariance to zero\n\nRegarding the latter point, we may also look at the parameter estimate for this covariance:\n         AW       WITH\n            AA                 1.173      1.358      0.864      0.388\nThis covariance is not significantly different from zero; hence, we can decide that it can be omitted from the model (which is the same as fixing it to zero).\n\n\n\n\n\nQuestion 4\nSpecify a model that overrules the defaults we ran into in the previous question. Discuss the model fit. Check the TECH1 output and notice the differences with what you saw before.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe use the following MODEL command:\nMODEL:      AD ON PPR;\n            AA ON AD PPR;\n            AW ON AD PPR;\n            AA WITH AW@0;\n            PPR; \nThe fit information we get with this code is:\nMODEL FIT INFORMATION\n\nNumber of Free Parameters                       13\n\n  ...\n\nChi-Square Test of Model Fit\n\n          Value                              0.750\n          Degrees of Freedom                     1\n          P-Value                           0.3865\nSo now we see there are 13 free parameters in this model and there is 1 df; this is what we determined in the beginning (and \\(13 + 1 = 14\\), so it nicely adds up to the total number of sample statistics that we counted to begin with).\nWhen checking the TECH1 output, what we notice is:\n\nthe free parameters are counting up to 13\nthe mean and variance of the exogenous variable PPR are now both counted as free parameters\nthe covariance between the residuals of AA and AW is no longer estimated (not a free parameter)\n\n\n\n\n\n\nQuestion 5\nWe are actually interested not so much in overall model fit here (the model has only 1 df, so it is very unlikely that will not fit well), but rather in its parameter estimates, and even more so, in the mediated and direct effects.\nTo get information about the indirect (i.e., mediated) effects, we have to add these lines to the code:\n        MODEL INDIRECT:\n                    AA IND PPR;\n                    AW IND PPR;      \nRun the model with this code added, and report on the indirect effects.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNote that the model itself has not changed (you can also tell by the fact that the model fit and parameter estimates are the same as before); we just have additional output.\nThe nonstandardized additional output starts with:\nTOTAL, TOTAL INDIRECT, SPECIFIC INDIRECT, AND DIRECT EFFECTS\n\n                                                    Two-Tailed\n                    Estimate       S.E.  Est./S.E.    P-Value\n\nEffects from PPR to AA\n\n  Total                0.538      0.247      2.174      0.030\n  Total indirect       0.221      0.085      2.608      0.009\n\n  Specific indirect 1\n    AA\n    AD\n    PPR                0.221      0.085      2.608      0.009\n\n  Direct\n    AA\n    PPR                0.317      0.240      1.320      0.187\nIt reports all there is to know about the effect of PPR on AA:\n\nthe direct effect is not significant (\\(p = .187\\))\nthe indirect effect through AD is significant and positive (\\(p = .009\\)), meaning that higher perceived parental rejection leads to higher aggression\nthe total indirect effect is the same, as there is only one indirect effect (there can be multiple indirect through different series of mediators in more complicated models)\nthe total effect is the total indirect effect (i.e., all indirect effects) plus the direct effect\n\nBecause the direct effect is not significant, we could decide to take this out of the model (which is the same as setting it to zero).\nFor the second outcome variable we get:\nEffects from PPR to AW\n\n  Total                0.035      0.070      0.498      0.619\n  Total indirect       0.042      0.019      2.249      0.025\n\n  Specific indirect 1\n    AW\n    AD\n    PPR                0.042      0.019      2.249      0.025\n\n  Direct\n    AW\n    PPR               -0.007      0.070     -0.103      0.918\nPretty much the same picture: The direct effect is non-significant and could thus be fixed to zero. The indirect effect is significantly different from zero, and positive, meaning more perceived parental rejection is followed by more adolescent withdrawal.\nWe can also look at the standardized effects, but let’s first fix the non-significant direct effects to zero.\n\n\n\n\n\nQuestion 6\nFix the non-significant direct effects to zero, and run the model again. Consider the standardized indirect effects in this model: What can you conclude with regard to the researchers’ question: Does perceived rejection make adolescents sad or mad?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe standardized indirect effect of PPR on AA is:\n          Specific indirect 1\n            AA\n            AD\n            PPR                0.056      0.021      2.680      0.007\nThe standardized indirect effect of PPR on AW is:\n          Specific indirect 1\n            AW\n            AD\n            PPR                0.036      0.016      2.281      0.023\nWe see the effect of PPR on AA (aggression) is larger than that on AW (withdrawal). Hence, we could say that perceived parental rejection makes adolescents more mad than sad, although it also makes them sad. Note however that these effects are both quite small.\n\n\n\n\n\nQuestion 7\nConsider the parameter estimates from the non-standardized solution and write down the regression equations for the three dependent variables in the model; fill in the actual parameter estimates for the intercepts and slopes (i.e., regression coefficients).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFor adolescent depression we have:\n\\[AD_i = 22.096 + 0.609*PPR_i + \\zeta_{ADi}\\]\nFor adolescent aggression we have:\n\\[AA_i = 16.739 + 0.379*AD_i + \\zeta_{AAi}\\] \\[     = 16.739 + 0.379*(22.096 + 0.609*PPR_i + \\zeta_{ADi})+ \\zeta_{AAi}\\]\nFor adolescent withdrawal we have:\n\\[AW_i = 6.842 + 0.0.069*AD_i + \\zeta_{AWi}\\] \\[= 6.842 + 0.069*(22.096 + 0.609*PPR_i + \\zeta_{ADi})+ \\zeta_{AWi}\\]\n\n\n\n\n\nConclusion\nWhen doing a path analysis with only observed variables, there are several defaults that are operating. It can be helpful to check the TECH1 output to see what and where they are (rather than trying to memorize all of them).\nSome aspects regarding observed exogenous variables to keep in mind:\n\nobserved exogenous variables are observed variables that do not have any one-headed arrows pointing towards them; this means that they are not predicted by anything\nMplus treats such variables differently than other variables; specifically: a) their observed variances, covariances and means are not counted as sample statistics; and b) their estimated variances, covariances and means are not counted as free parameters; note these two cancel each other out (in terms of sample statistics - free parameters = degrees of freedom)\nWhen there are no missing data, the observed means, variances and covariances for observed exogenous variables are identical to their estimated means, variances and covariances\nWhen there are missing data, Mplus will use case-wise deletion for cases that have missings on the observed exogenous variables; this may be undesirable, and can be avoided by changing the status of these variables in Mplus to endogenous by asking for their means and/or variances (then Mplus will keep all cases and use ML to deal with the missing observations)\nAnother scenario in which we need to be concerned about observed exogenous variables being treated differently, is when we want to compare such a model to a model in which one or more of these variables are not exogenous; the AIC and BIC of these two models will not be comparable; you can tell by looking at the loglikelihood value for H1 (i.e., for the saturated model), just above the Information Criteria in the output; if these are not the same, the AIC and BIC are not comparable!\n\nSome issues regarding additional defaults to keep in mind:\n\nIn a path model with observed variables only, you have exogenous variables and endogenous variables; the latter can be further distinguished into mediators (i.e., they are dependent variables, but also predictors of other variables), and outcome variables (i.e., they have only arrows pointing towards them, not out of them)\nThe exogenous variables in such models are by default allowed to covary (i.e., there is a two-headed arrow between them); typically, that is fine as we do not have a specific theory about how the predictors are related to each other; however, if you do not want them to be correlated, you can set their covariance to zero with the WITH statement (note this will also change their status from exogenous to endogenous)\nThe residuals of mediators in such models are uncorrelated, unless you specify they should covary (using the WITH statement)\nThe residuals of outcome variables in such models are by default allowed to be correlated (or: to covary); in terms of a path diagram this implies Mplus automatically adds a two-headed arrow between these residuals\nYou can use the TECH1 output to trace these defaults\n\nSome issues regarding indirect effects to keep in mind:\n\nIn this exercise we let Mplus compute the indirect (i.e., mediated) effects by simply multiplying the parameter estimates; the p-value that is reported for this, is known as the Sobel test; however, it is also known that this test is not correct\nA better approach to determine whether the indirect effect differs from zero or not, is through using bootstrapping and checking the 95% confidence interval for the indirect effect; this can be easily done in Mplus, but requires you to have the raw data (here we only have the summary data, which makes it impossible); in that case you may add to your code:\n\nANALYSIS: BOOTSTRAP IS 1000;\n\nOUTPUT:   CINTERVAL;"
  },
  {
    "objectID": "day1_introduction.html",
    "href": "day1_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "These exercises are for day 1 of S23. In the first exercise we investigate measurement invariance, while in the second exercise the focus is on path analysis. You can choose which of these you want to focus on, and start with that.\nIn both exercises we will focus on: a) determining the number of degrees of freedom (df) by counting the number of sample statistics (i.e., unique pieces of information in our data) and the number of free parameters; and b) checking the TECH1 output to see where the free parameters are in the diverse underlying model matrices.\nYou can navigate through these excises by using the left-hand menu. Answers are included below each exercise in a drop down option. The data and Mplus input files can found in the SURFdrive folder."
  },
  {
    "objectID": "day2_exercises.html",
    "href": "day2_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "The file PTSD.dat contains data on burn survivors, specifically (in this order):\n\ngender (gender),\npercentage total body surface burned (tvlo),\nSVL at wave 1 (2 weeks after burn injury; W1),\nSVL at wave 2 (4 weeks after burn injury; W2),\nSVL at wave 3 (2 months after burn injury; W3),\nSVL at wave 4 (4 months after burn injury; W4),\nSVL at wave 5 (6 months after burn injury; W5),\nSVL at wave 6 (9 months after burn injury; W6),\nSVL at wave 7 (12 months after burn injury; W7),\nSVL at wave 8 (18 months after burn injury; W8), and\nBPAS at wave 9 (24 months after burn injury; pain).\n\n\n\nSpecify a latent growth curve model. Consider different specifications discussed in the lecture, and try to find the best specification. Use only the time measurements, not including additional predictor variables. Think about which metric of time to use and the shape of the function (linear or quadratic). Base your decision of the best model on plots (!), model fit indices, model comparison tools, and interpretation of the model parameters.\nIf you have reason to believe that another type of LGCM fits the data better, feel free to specific and estimate that model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDeciding on the metric of time Based on these descriptions, I’ve chosen for the following specification of time in the LGM:\ni s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;\nIn this specification I set the first time point to 0.5 months after burn injury (approximation of 2 weeks after burn injury), the second time point to 1 month after burn injury (approximation of 4 weeks after burn injury), etc.\nPlots You can enable the plot functionality of Mplus by specifying\nPLOT:\n  TYPE = PLOT3;\n  SERIES = W1 W2 W3 W4 W5 W6 W7 W8 (s);\nThe TYPE = PLOT3; function ensures that all kinds of different types of plots are available in Mplus (see the Mplus User Guide for an overview of the different types of plots). The SERIES = ...; function tells Mplus to draw a line through the named variables in that order, for each individual.\nDeciding on linear vs. linear and quadratic slope Some example syntaxes for running models with different trajectory shapes are available in SURFdrive. These include:\n\nA LGCM with only a linear slope.\nA LGCM with an added quadratic slope.\nA LGCM with an added quadratic slope but no quadratic slope factor variance.\n\nFor the model with a quadratic slope, it was necessary to fix the variance of Q at 0 to ensure convergence. For both models, only CFI and TLI indicate adequate fit.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nParameters\nAIC\nBIC\nRMSEA\nCFI\nTLI\nSRMR\n\n\n\n\nexercise1a.out\n13\n14051\n14096\n.14\n.93\n.94\n.08\n\n\nexercise1a_Q.out\n-\n-\n-\n-\n-\n-\n-\n\n\nexercise1a_Q0.out\n14\n14037\n14085\n.13\n.94\n.94\n.08\n\n\n\nModel comparison tools To see which model fit the data better, we can do a \\(\\Delta \\chi^{2}\\) (i.e., Chi-square difference) test (e.g., using the function chisq_sb() from the tidySEM package in R, or using on online \\(\\chi^{2} calculator\\)): \\(\\Delta \\chi^{2} = 16.14\\), \\(\\Delta df = 1\\), \\(p &lt; .001\\). Furthermore, both AIC and BIC are lower in the model with a quadratic slope. Thus, model misfit is significantly lower when the quadratic slope is added although the fit indices still do not indicate adequate fit. We can use the plots, RES option in Mplus, or modification indices to see what the source of the misfit is.\nModel parameters The mean of the quadratic slope factor is significant (q = 0.02, \\(p &lt; .001\\)), indicating that, on average, the growth curve does follow a quadratic curve (see exercise1a_Q0.out).\n\n\n\n\n\n\nUsing the best fitting LGM model found above, regress the growth parameters on TVLO and regress pain on the growth components. Then investigate if there are gender differences in the regression of the growth parameters on TVLO and in the regression of pain on the growth parameters?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRephrasing the question, we are asked to investigate if gender moderates the predictive relationship of TVLO on the growth components, as well as the relationship between the growth components and Pain. As such, we can do a multigroup analysis by gender, resulting in the addition of the following syntax to the VARIABLE: command:\nGROUPING = gender (1 = male 2 = female);\nSince we needed to fix the quadratic slope variance to 0, we cannot estimate any regressions on the quadratic slope or use the quadratic slope as a predictor of some outcome. We therefore focus on the intercept and linear slope.\nThe file exercise1B.inp on SURFdrive contains the Mplus syntax on how to specify this model, including the MODEL TEST command to test between-group (i.e., between-gender) differences in the effect of TVLO on the growth components, and the growth components on pain. This is only an illustrative example for how to approach this analysis; your specific execution may differ (e.g., you could specify 2 models, and with across group constraints and one without, and then use the \\(\\Delta \\chi^{2}\\) test to see if the improvement of model fit is significant). Note that in this example, the Wald \\(\\chi^2\\) p-value is not significant. That means that there are no significant gender differences in the effect of the growth trajectory on pain.\nNote that the Wald test is an overall test of all comparisons that we specify in MODEL TEST. Thus, if you want a separate test for the regression of TVLO on the growth parameters, you need to re-run the analysis but with a different MODEL TEST argument.\nConclusion: There are no gender differences in the regression of growth parameters on TVLO and in the regression of Pain on the growth parameters."
  },
  {
    "objectID": "day2_exercises.html#burn-survivors",
    "href": "day2_exercises.html#burn-survivors",
    "title": "Exercises",
    "section": "",
    "text": "The file PTSD.dat contains data on burn survivors, specifically (in this order):\n\ngender (gender),\npercentage total body surface burned (tvlo),\nSVL at wave 1 (2 weeks after burn injury; W1),\nSVL at wave 2 (4 weeks after burn injury; W2),\nSVL at wave 3 (2 months after burn injury; W3),\nSVL at wave 4 (4 months after burn injury; W4),\nSVL at wave 5 (6 months after burn injury; W5),\nSVL at wave 6 (9 months after burn injury; W6),\nSVL at wave 7 (12 months after burn injury; W7),\nSVL at wave 8 (18 months after burn injury; W8), and\nBPAS at wave 9 (24 months after burn injury; pain).\n\n\n\nSpecify a latent growth curve model. Consider different specifications discussed in the lecture, and try to find the best specification. Use only the time measurements, not including additional predictor variables. Think about which metric of time to use and the shape of the function (linear or quadratic). Base your decision of the best model on plots (!), model fit indices, model comparison tools, and interpretation of the model parameters.\nIf you have reason to believe that another type of LGCM fits the data better, feel free to specific and estimate that model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDeciding on the metric of time Based on these descriptions, I’ve chosen for the following specification of time in the LGM:\ni s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;\nIn this specification I set the first time point to 0.5 months after burn injury (approximation of 2 weeks after burn injury), the second time point to 1 month after burn injury (approximation of 4 weeks after burn injury), etc.\nPlots You can enable the plot functionality of Mplus by specifying\nPLOT:\n  TYPE = PLOT3;\n  SERIES = W1 W2 W3 W4 W5 W6 W7 W8 (s);\nThe TYPE = PLOT3; function ensures that all kinds of different types of plots are available in Mplus (see the Mplus User Guide for an overview of the different types of plots). The SERIES = ...; function tells Mplus to draw a line through the named variables in that order, for each individual.\nDeciding on linear vs. linear and quadratic slope Some example syntaxes for running models with different trajectory shapes are available in SURFdrive. These include:\n\nA LGCM with only a linear slope.\nA LGCM with an added quadratic slope.\nA LGCM with an added quadratic slope but no quadratic slope factor variance.\n\nFor the model with a quadratic slope, it was necessary to fix the variance of Q at 0 to ensure convergence. For both models, only CFI and TLI indicate adequate fit.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nParameters\nAIC\nBIC\nRMSEA\nCFI\nTLI\nSRMR\n\n\n\n\nexercise1a.out\n13\n14051\n14096\n.14\n.93\n.94\n.08\n\n\nexercise1a_Q.out\n-\n-\n-\n-\n-\n-\n-\n\n\nexercise1a_Q0.out\n14\n14037\n14085\n.13\n.94\n.94\n.08\n\n\n\nModel comparison tools To see which model fit the data better, we can do a \\(\\Delta \\chi^{2}\\) (i.e., Chi-square difference) test (e.g., using the function chisq_sb() from the tidySEM package in R, or using on online \\(\\chi^{2} calculator\\)): \\(\\Delta \\chi^{2} = 16.14\\), \\(\\Delta df = 1\\), \\(p &lt; .001\\). Furthermore, both AIC and BIC are lower in the model with a quadratic slope. Thus, model misfit is significantly lower when the quadratic slope is added although the fit indices still do not indicate adequate fit. We can use the plots, RES option in Mplus, or modification indices to see what the source of the misfit is.\nModel parameters The mean of the quadratic slope factor is significant (q = 0.02, \\(p &lt; .001\\)), indicating that, on average, the growth curve does follow a quadratic curve (see exercise1a_Q0.out).\n\n\n\n\n\n\nUsing the best fitting LGM model found above, regress the growth parameters on TVLO and regress pain on the growth components. Then investigate if there are gender differences in the regression of the growth parameters on TVLO and in the regression of pain on the growth parameters?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRephrasing the question, we are asked to investigate if gender moderates the predictive relationship of TVLO on the growth components, as well as the relationship between the growth components and Pain. As such, we can do a multigroup analysis by gender, resulting in the addition of the following syntax to the VARIABLE: command:\nGROUPING = gender (1 = male 2 = female);\nSince we needed to fix the quadratic slope variance to 0, we cannot estimate any regressions on the quadratic slope or use the quadratic slope as a predictor of some outcome. We therefore focus on the intercept and linear slope.\nThe file exercise1B.inp on SURFdrive contains the Mplus syntax on how to specify this model, including the MODEL TEST command to test between-group (i.e., between-gender) differences in the effect of TVLO on the growth components, and the growth components on pain. This is only an illustrative example for how to approach this analysis; your specific execution may differ (e.g., you could specify 2 models, and with across group constraints and one without, and then use the \\(\\Delta \\chi^{2}\\) test to see if the improvement of model fit is significant). Note that in this example, the Wald \\(\\chi^2\\) p-value is not significant. That means that there are no significant gender differences in the effect of the growth trajectory on pain.\nNote that the Wald test is an overall test of all comparisons that we specify in MODEL TEST. Thus, if you want a separate test for the regression of TVLO on the growth parameters, you need to re-run the analysis but with a different MODEL TEST argument.\nConclusion: There are no gender differences in the regression of growth parameters on TVLO and in the regression of Pain on the growth parameters."
  },
  {
    "objectID": "day2_exercises.html#alcohol-use",
    "href": "day2_exercises.html#alcohol-use",
    "title": "Exercises",
    "section": "Alcohol use",
    "text": "Alcohol use\nThe figure below depicts the basic LGCM for the alcohol use data from @duncan_introduction_2006, example 8_1.\n\n\n\nLatent growth curve model for alcohol use.\n\n\nThe data are in the file DDS8_1.dat, with variables ALC1YR1 ALC1YR2 ALC1YR3 ALCPROB5 AGE1 and GENDER1 (in that order). Missing values are coded as -99. The variable ALCPROB5 is categorical, it indicates alcohol problems in year 5 of the study (0 = no, 1 = yes).\n\nExercise 2A\nSet up the LGCM as depicted in the figure above in Mplus using the | notation (rather than specifying a CFA by using the BY statement). Inspect the output carefully with special attention for a) the pattern of missing values, b) the model fit, and c) the interpretation of the parameter estimates. How well does the model predict alcohol use of the years?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input and output file (exercise2A.inp and exercise2A.out) can be found on SURFdrive. The table under PROPORTION OF DATA PRESENT in the output file shows that the majority of the cases is complete, but that there is a small amount of attrition (panel dropout). You can also inspect the coverage matrix to inspect how much information you have for different parts of the model. Regarding model fit, the model fits well overall with the chi-square test of model fit \\(\\chi^{2}(1) = 2.781\\), \\(p = 0.095\\), and the CFI and TLI above their recommended cutoff points. However, the RMSEA implies some some degree of misfit at \\(0.062\\). The intercept and slope means indicate a relatively high starting point (3.68, \\(SE = .081\\)) and a growth of 0.92 (\\(SE = .053\\)) per year. The intercept and slope factors show considerable variance, indicating that the starting points and rates of growth differ considerably across individuals. Interestingly, the explained variance \\(R^{2}\\) is high for years 1 and 3, but lower for year 2.\n\n\n\n\n\nExercise 2B\nWe will now explore how different predictor variables affect the model fit. Include gender and age in the model as predictors of the intercept and slope. Interpret the fit of the model and the output. Feel free to estimate several models, including or excluding certain covariates. Make a model fit table by hand in a spreadsheet, reporting on the fit indices you deem to be appropriate. Which model do you consider to be best?\n\n\n\n\n\n\nConfirmatory versus exploratory research\n\n\n\nWhen you conduct confirmatory research, and are testing theoretical hypotheses, you should not add and omit paths based on exploratory analyses and model fit. It is fine to add and remove paths in exploratory research. Model fit indices, like AIC and BIC, are suitable for selecting well-fitting models in exploratory research. p-values are not designed for variable selection, and using them for that purpose may lead to sub-optimal models.\nIt is good scientific practice to clearly separate confirmatory and exploratory research. When you conduct exploratory research, you should not perform inference on the resulting parameters based on p-values (because inference generalizes your findings to the population, and exploratory findings tend to be tailored toward this specific sample). You should also not present exploratory results as if they were testing a post-hoc theory (also referred to as “Hypothesizing After the Results are Known”, or HARKing). This is a questionable research practice and can lead to false-positive (spurious) findings.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe files exercise2B_M1.inp, exercise2B_M2.inp, and exercise2B_M3.inp, on SURFdrive contain various models in which we predict the growth components using AGE1 and GENDER1. The model fit remains excellent. After removing non-significant paths from exercise2B_M1.inp (order based on magnitude of standardized effect size), gender and age only predict the starting point but not the slope. However, after having removed the effect of gender and age on the slope, the model suddenly fits very badly (exercise2B_M2.inp). Careful inspection of the output shows that the covariance between intercept and slope has disappeared from the model (it is now the covariance between a latent variable and a residual, Mplus automatically puts these at zero). Mplus automatically constrains these to zero. If we add the statement I WITH S to the model, we obtain a good fit with significant effects of both gender and age on the intercept (exercise2B_M3.inp). This illustrates the importance of checking the output carefully to find out if Mplus is actually doing what you think it does!\n\n\n\n\n\nExercise 2C\nInclude alcohol problems in year 5 in the model. Let the intercept and slope factors predict alcohol problems in year 5. Declare the variable as categorical in the variable section (CATEGORICAL = ALCPROB5). Inspect if the effect of age and gender on alcohol problems year 5 is completely mediated by the growth factors, or if there are additional direct paths from age and gender on the alcohol problems.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model fit is still good. Note that after adding a categorical dependent variable to the model, Mplus switches to a robust estimator (MLR, and the exact type of regression the Mplus uses now is a logit regression). Both intercept and slope predict alcohol problems (see exercise2c_M1.inp on SURFdrive). Age also predicts alcohol problems directly (see exercise2c_M2.inp on SURFdrive). Since age predicts alcohol problems both directly and via the intercept, a mediation analysis is in order. This shows that the indirect effect of age via the intercept on alcohol problems is still significant when the direct effect is added to the model."
  },
  {
    "objectID": "day2_exercises.html#level-and-shape-parameterization",
    "href": "day2_exercises.html#level-and-shape-parameterization",
    "title": "Exercises",
    "section": "Level and shape parameterization",
    "text": "Level and shape parameterization\nThe file GPA.dat holds the following variables (in that order):\n\ngrade point average (GPA) data with GPA scores of 200 students in 6 consecutive semesters (gpa1, …, gpa6),\nhigh school GPA highpa,\ngender sex, and\nadmitted to university of choice (missing if not applied for university, student).\n\nIn this exercise you will use the GPA data to set up a level and shape model (i.e., a LGCM with estimated time scores).\n\nExercise 3A\nUse a parameterization with GPA1@0 and GPA6@1. The loadings for the other time points should be freely estimated. This can be done with, for example, the syntax GPA2* as shown in the handout. Interpret the factor loadings and estimate for S.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus model syntax for this LGCM can be found in exercise3A.inp on SURFdrive. The factor loadings indicate the proportion of change for a 1 unit change in time (here, a 1 unit change of time is specified as the change between the first and the last time points). The predicted change in the outcome for a 1 unit change in time is the mean of the slope, \\(\\alpha_{S} = 0.55\\). Therefore, when looking at the factor loadings, 24% of the total change occurs between GPA1 and GPA2.. The intercept at GPA1 = 2.575. So the estimated score at GPA2 is \\(GPA1 = 2.575 + 0.239*0.549 = 2.706\\). The estimated score at GPA3 is \\(GPA3 = 2.575 + 0.450*0.549 = 2.822\\), etc.\n\n\n\n\n\nExercise 3B\nNow use a parameterization with GPA1@0 and GPA2@1. The other GPA’s should be freely estimated. Interpret the factor loadings and estimate for S.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus model syntax for this parametrization of the LGCM with freely estimated time scores can be found in exercise3B.inp. The mean of the slope factor \\(\\alpha_{S}\\) now indicates the difference between GPA1 and GPA2. The estimated factor loadings indicate the distance in units from the starting point, where 1 unit is S. In other words, every distance compares to the increase between GPA1 and GPA2.\n\n\n\nWhich parameterization do you like best?\n\n\nExercise 3C\nDraw the development of GPA over time, using the parametrization of your choice) based on your own calculations (by hand). Compare this to the estimated means plot that you can get with the plot command:\nPLOT: \n  SERIES = GPA1-GPA6 (s); \n  TYPE = PLOT3;\nDon’t forget that you need to rescale that plot, since S is linear while the location of the estimated points is based on the factor loadings.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe estimated means plot for the parametrization (0 1 * * * *) is shown below, and can be generated by clicking the plots button, and selecting “Estimated means”.\n\n\n\nEstimated means\n\n\n\n\n\n\n\nExercise 3D\nUse sex as a predictor of the intercept and slope and interpret the result (with 0 = boys, 1 = girls).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus model syntax for the LGCM with time scores (0 * * * * 1) and gender predicting the growth components can be found in exercise3D.inp. Sex is a significant predictor of the intercept and a significant predictor of development, with girls having a higher initial level (\\(b = .079\\), \\(SE = .037\\)), and a greater development over time (\\(b = .136\\), \\(SE = .054\\)). Who run the world?"
  },
  {
    "objectID": "day2_exercises.html#latent-growth-curve-model-on-gpa-data",
    "href": "day2_exercises.html#latent-growth-curve-model-on-gpa-data",
    "title": "Exercises",
    "section": "Latent growth curve model on GPA data",
    "text": "Latent growth curve model on GPA data\n\nExercise 4A\nContinuing with the data used for the previous exercise, set up a latent growth model for GPA for the 6 consecutive occasions and run this model. Obtain the following parameters:\n\nAIC, BIC, \\(\\chi^{2}\\), RMSEA, CFI, and TLI;\nThe mean of the intercept factor \\(\\alpha_{I}\\) and slope factor \\(\\alpha_{S}\\);\nThe variance of the intercept facor \\(\\psi_{I}\\) and slope factor \\(\\psi_{S}\\).\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus model syntax for this can be found in exercise4A.inp.\n\n\n\n\n\nExercise 4B\nThen, set up a latent growth curve model for 3 years where each year is a latent variable measured by the GPA of two consecutive semesters.\nThe factor loadings for GPA2, GPA4 and GPA6 ought to be constrained to be equal with a label (a) behind the loading in the syntax. As such, the scores relate in the same way to the year score over time. The GPA intercepts are constrained at 0.\nIf you get the error message below, can you find out what the problem is?\n    WARNING:  THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE DEFINITE. THIS \n    COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION \n    GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE \n    THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. \nA rough way to deal with this problem may be to fix the problematic parameter to a particular value (e.g., .001), try this and rerun the model. Now examine the same parameters as for exercise 4a, and compare the two. Are there major differences?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus model syntax for this can be found in exercise4B_M2.inp. Note that, without year3@.001 (see exercise4B_M1.inp), this code gives an error message: The variance of the latent variable year3 is estimated negatively which is problematic since variances should always be positive. A simple way to deal with the problem of the latent variance of year3 is to fix it to a very small value (.001) for instance, as it would also be illogical to fix a variance to 0. To do this, simply add this to your input file under model: year3@.001;\nIf you inspect the output carefully (and provided you have requested standardized estimates) you will notice that the latent variables year2 and year3 have a correlation of 1. So the negative variance is the result of a multicolinearity problem. It is apparently better to analyze these data using only the observed variables gpa1-gpa6. Creating latent variables per year does not work well. In line with this interpretation, the fit and results of the simple latent growth model look better than the 2nd order latent growth curve model."
  },
  {
    "objectID": "day2_introduction.html",
    "href": "day2_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "These exercises are for day 1 of S23. In this computer lab session you can practice with specifying latent growth models in Mplus and interpreting the output. All of the input files for the exercises are provided with the course materials on SURFdrive."
  },
  {
    "objectID": "day3_exercises.html",
    "href": "day3_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "The goal of this exercise is to find subpopulations with different alcohol use trajectories. To this end, we start with an exploratory latent class growth analysis, and work towards a growth mixture model.\n\n\nFirst, we perform an exploratory latent class growth analysis (LCGA) as initial exploratory option. Set up LCGA models models for 1, 2, 3, and 4 classes for the data in DDS8_1.dat. Specify the model using the | notation, and constrain the variances of the intercept and slope factors to be equal to 0. Furthermore, request TECH11, and TECH14 to help evaluate model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMplus model syntax for the LCGA models for 1, 2, 3, and 4 classes are in exercise1A_1C.inp, exercise1A_2C.inp, exercise1A_3C.inp, exercise1A_4C.inp, respectively.\n\n\n\n\n\n\nThese models use random starting values. Several independent random starts are made, to ensure that the model converges on the proper solution. The default is 20 random sets of starting values, of which 4 are run to completion. Inspect the output, and look carefully if the model estimation has converged, especially for the larger number of classes. Look for warning and error messages, make sure you understand what they are telling you.\nThe STARTS option is used to specify the number of initial random starting values and final stage optimizations. Now, increase the number of starts to ensure proper convergence. Once you are confident that the model has converged to the proper solution, compare the different models using the available fit information (e.g., BIC, LMR-LRT, BLRT, entropy, min. N in classes, etc.). Which model do you prefer, and why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can inspect the convergence of the model by checking that the best final state loglikelihood value has been replicated using different starting values. See the output section RANDOM STARTS RESULTS RANKED FROM THE BEST TO THE WORST LOGLIKELIHOOD VALUES. Increasing the number of random starts can be done by specifying STARTS = 50 10; in the ANALYSIS command, where the first number specifies the initial number of random starts, and the second number specifies the number of initial starts that will be converged to the final stage.\nBased on the fit indices of the fitted LCGA models, I would select a 3-class model. The fit indices and (LMR-LRT tests essentially indicate that you can keep adding classes and improve the model, which makes it difficult to decide. However, if we look at the counts in each class, we see that from 4 classes onward, the smallest class has less than 10% of cases assigned to it. The minimum posterior classification probability and entropy are best for the 3-class model, which means that this model can reasonably accurately assign individuals to classes.\n\n\n\n\n\n\nSet up the same models as analyzed in the previous exercise, but now allow the means and variances of the intercept and slope factors to be freely estimated in each class (i.e., a growth mixture model). You do this by mentioning the intercept and slope explicitly in the class-specific part of the syntax. This is a more complex model, and we might therefore expect that we will need fewer classes for a good description of the data. This analysis will also take more computing time, so add PROCESSORS = 4 to the analysis section. Make a table of the fit indices, look at BIC, the LMR-LRT (TECH11), and the bootstrapped LRT value (TECH14).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMplus model syntax for the GMM models for 1, 2, 3, and 4 classes are in exercise1C_1C.inp, exercise1C_2C.inp, exercise1C_3C.inp, exercise1C_4C.inp, respectively. The BLRT for the GMM with 3 classes warns that OF THE 10 BOOTSTRAP DRAWS, 7 DRAWS HAD BOTH A SMALLER LRT VALUE THAN THE OBSERVED LRT VALUE AND NOT A REPLICATED BEST LOGLIKELIHOOD VALUE FOR THE 3-CLASS MODEL. You can increase the number of random starts for the BLRT using LRTSTARTS = 0 0 40 10; in the ANALYSIS command. Also note the convergence problems for the GMM with 4 classes. This indicates that a model with 4 classes is likely to be too complex for the data. Furthermore, since the GMM with only a single class is equivalent to a “simple” LGCM, we focus on the GMM with 2 and 3 classes in the next exercises.\n\n\n\n\n\n\nPlotting the model-predicted trajectories makes it easier to interpret the model. Moreover, visualizing the raw data provides yet another way to evaluate the fit of your mixture model to the data. With this in mind, plot the GMM models with 2 and 3 classes you created in exercise 1c, and interpret what you see. First, plot only the predicted trajectories. Then, plot raw data as well. Explain the benefit of plotting the raw data in your own words.\n::: {.callout-caution collapse=“true”} #### Answer Plotting the raw data helps us understand how representative the average trajectory for each class captures the individual trajectories of individuals in that class. It helps us see how separable the classes are visually, instead of just relying on statistics like entropy. To get plots, make sure you include:\nPLOT:\n    TYPE = PLOT3;\n    SERIES = ALC1YR1(1) ALC1YR2(2) ALC1YR3(3);\nwhen running the model. Then press the “plot” button and select “Estimated mean and observed individual values” and “Estimated means and estimated individual values”. Below you can find these plots for the GMM with 2 classes.\n\n\n\nEstimated means and individual values.\n\n\n\n\n\nEstimated means and estimated invidivual trajectories\n\n\nAdmittedly, this plot looks chaotic. Primarily because the individual values are not colored according to the class to which they are assigned. Alternatively, you could get the estimated means and (individual) values per class in a seperate window as well. However, MplusAutomation has some useful plotting functions that I recommend you to explore, for example plotGrowthMixtures(), in which you can color the lines according to their class membership.\n\n\n\nCovariates are often added to mixture models, to predict 1) class membership 2) to explain variation in the growth parameters within the classes, or 3) as a distal outcome. Whenever covariates are however added to the model, they change the latent class solution. Sometimes, this is fine, as the covariates can help to improve the classification. In other cases, you would use a 3-step approach, which Mplus has automated:\n\nFit an unconditional LCA (without covariates).\nA “most likely class variable” is created using the posterior distribution of step 1.\nThis most likely class variable is then regressed on (a) covariate.\n\nThere are a few options for how to do 3-step analysis. They all rely on adding to the VARIABLE command. For more info, see https://www.statmodel.com/download/webnotes/webnote15.pdf.\n\n\n\nYou can add the following options to the VARIABLE command:\n\nAUXILIARY = x(R)\nThis is actually a 1-step method for predicting latent class memberships using Pseudo-Class draws.\nAUXILIARY = x(R3step);\nA 3-step procedure, where covariates predict the latent class.\nAUXILIARY = y(e)\nA 1-step method, where the latent class predicts a continuous distal outcome.\nAUXILIARY = y(de3step);\nA 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and equal variances.\nAUXILIARY = y(du3step);\nA 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and variances.\nAUXILIARY = Y(dcon);\nProcedure for continuous distal outcomes as suggested by Lanza et al (2013).\nAUXILIARY = Y(dcon);\nProcedure for categorical distal outcomes as suggested by Lanza et al (2013).\nAUXILIARY = y(BCH);\nImproved and currently best 3-step procedure with continuous covariates as distal outcomes.\n\nPick your final model from 1c, and add both age and gender as auxiliary variables in the model. Try to think what 3-step model you want, and if you are not sure, run different models, so you can evaluate how the different procedures make a difference. What is the effect of both age and gender?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nI’m providing an example using the 3-step procedure in exercise1E.inp. The results of adding these covariate to the model as predictors of the latent class can be found under the heading TESTS OF CATEGORICAL LATENT VARIABLE MULTINOMIAL LOGISTIC REGRESSIONS USING THE 3-STEP PROCEDURE. It can be seen, from the overall test and the pairwise comparisons, that the third group is significantly older, and has a significantly lower proportion of girls than the other two classes."
  },
  {
    "objectID": "day3_exercises.html#latent-growth-mixture-modeling",
    "href": "day3_exercises.html#latent-growth-mixture-modeling",
    "title": "Exercises",
    "section": "",
    "text": "The goal of this exercise is to find subpopulations with different alcohol use trajectories. To this end, we start with an exploratory latent class growth analysis, and work towards a growth mixture model.\n\n\nFirst, we perform an exploratory latent class growth analysis (LCGA) as initial exploratory option. Set up LCGA models models for 1, 2, 3, and 4 classes for the data in DDS8_1.dat. Specify the model using the | notation, and constrain the variances of the intercept and slope factors to be equal to 0. Furthermore, request TECH11, and TECH14 to help evaluate model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMplus model syntax for the LCGA models for 1, 2, 3, and 4 classes are in exercise1A_1C.inp, exercise1A_2C.inp, exercise1A_3C.inp, exercise1A_4C.inp, respectively.\n\n\n\n\n\n\nThese models use random starting values. Several independent random starts are made, to ensure that the model converges on the proper solution. The default is 20 random sets of starting values, of which 4 are run to completion. Inspect the output, and look carefully if the model estimation has converged, especially for the larger number of classes. Look for warning and error messages, make sure you understand what they are telling you.\nThe STARTS option is used to specify the number of initial random starting values and final stage optimizations. Now, increase the number of starts to ensure proper convergence. Once you are confident that the model has converged to the proper solution, compare the different models using the available fit information (e.g., BIC, LMR-LRT, BLRT, entropy, min. N in classes, etc.). Which model do you prefer, and why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can inspect the convergence of the model by checking that the best final state loglikelihood value has been replicated using different starting values. See the output section RANDOM STARTS RESULTS RANKED FROM THE BEST TO THE WORST LOGLIKELIHOOD VALUES. Increasing the number of random starts can be done by specifying STARTS = 50 10; in the ANALYSIS command, where the first number specifies the initial number of random starts, and the second number specifies the number of initial starts that will be converged to the final stage.\nBased on the fit indices of the fitted LCGA models, I would select a 3-class model. The fit indices and (LMR-LRT tests essentially indicate that you can keep adding classes and improve the model, which makes it difficult to decide. However, if we look at the counts in each class, we see that from 4 classes onward, the smallest class has less than 10% of cases assigned to it. The minimum posterior classification probability and entropy are best for the 3-class model, which means that this model can reasonably accurately assign individuals to classes.\n\n\n\n\n\n\nSet up the same models as analyzed in the previous exercise, but now allow the means and variances of the intercept and slope factors to be freely estimated in each class (i.e., a growth mixture model). You do this by mentioning the intercept and slope explicitly in the class-specific part of the syntax. This is a more complex model, and we might therefore expect that we will need fewer classes for a good description of the data. This analysis will also take more computing time, so add PROCESSORS = 4 to the analysis section. Make a table of the fit indices, look at BIC, the LMR-LRT (TECH11), and the bootstrapped LRT value (TECH14).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMplus model syntax for the GMM models for 1, 2, 3, and 4 classes are in exercise1C_1C.inp, exercise1C_2C.inp, exercise1C_3C.inp, exercise1C_4C.inp, respectively. The BLRT for the GMM with 3 classes warns that OF THE 10 BOOTSTRAP DRAWS, 7 DRAWS HAD BOTH A SMALLER LRT VALUE THAN THE OBSERVED LRT VALUE AND NOT A REPLICATED BEST LOGLIKELIHOOD VALUE FOR THE 3-CLASS MODEL. You can increase the number of random starts for the BLRT using LRTSTARTS = 0 0 40 10; in the ANALYSIS command. Also note the convergence problems for the GMM with 4 classes. This indicates that a model with 4 classes is likely to be too complex for the data. Furthermore, since the GMM with only a single class is equivalent to a “simple” LGCM, we focus on the GMM with 2 and 3 classes in the next exercises.\n\n\n\n\n\n\nPlotting the model-predicted trajectories makes it easier to interpret the model. Moreover, visualizing the raw data provides yet another way to evaluate the fit of your mixture model to the data. With this in mind, plot the GMM models with 2 and 3 classes you created in exercise 1c, and interpret what you see. First, plot only the predicted trajectories. Then, plot raw data as well. Explain the benefit of plotting the raw data in your own words.\n::: {.callout-caution collapse=“true”} #### Answer Plotting the raw data helps us understand how representative the average trajectory for each class captures the individual trajectories of individuals in that class. It helps us see how separable the classes are visually, instead of just relying on statistics like entropy. To get plots, make sure you include:\nPLOT:\n    TYPE = PLOT3;\n    SERIES = ALC1YR1(1) ALC1YR2(2) ALC1YR3(3);\nwhen running the model. Then press the “plot” button and select “Estimated mean and observed individual values” and “Estimated means and estimated individual values”. Below you can find these plots for the GMM with 2 classes.\n\n\n\nEstimated means and individual values.\n\n\n\n\n\nEstimated means and estimated invidivual trajectories\n\n\nAdmittedly, this plot looks chaotic. Primarily because the individual values are not colored according to the class to which they are assigned. Alternatively, you could get the estimated means and (individual) values per class in a seperate window as well. However, MplusAutomation has some useful plotting functions that I recommend you to explore, for example plotGrowthMixtures(), in which you can color the lines according to their class membership.\n\n\n\nCovariates are often added to mixture models, to predict 1) class membership 2) to explain variation in the growth parameters within the classes, or 3) as a distal outcome. Whenever covariates are however added to the model, they change the latent class solution. Sometimes, this is fine, as the covariates can help to improve the classification. In other cases, you would use a 3-step approach, which Mplus has automated:\n\nFit an unconditional LCA (without covariates).\nA “most likely class variable” is created using the posterior distribution of step 1.\nThis most likely class variable is then regressed on (a) covariate.\n\nThere are a few options for how to do 3-step analysis. They all rely on adding to the VARIABLE command. For more info, see https://www.statmodel.com/download/webnotes/webnote15.pdf.\n\n\n\nYou can add the following options to the VARIABLE command:\n\nAUXILIARY = x(R)\nThis is actually a 1-step method for predicting latent class memberships using Pseudo-Class draws.\nAUXILIARY = x(R3step);\nA 3-step procedure, where covariates predict the latent class.\nAUXILIARY = y(e)\nA 1-step method, where the latent class predicts a continuous distal outcome.\nAUXILIARY = y(de3step);\nA 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and equal variances.\nAUXILIARY = y(du3step);\nA 3-step procedure, where latent class predicts continuous covariates (distal outcome) with unequal means and variances.\nAUXILIARY = Y(dcon);\nProcedure for continuous distal outcomes as suggested by Lanza et al (2013).\nAUXILIARY = Y(dcon);\nProcedure for categorical distal outcomes as suggested by Lanza et al (2013).\nAUXILIARY = y(BCH);\nImproved and currently best 3-step procedure with continuous covariates as distal outcomes.\n\nPick your final model from 1c, and add both age and gender as auxiliary variables in the model. Try to think what 3-step model you want, and if you are not sure, run different models, so you can evaluate how the different procedures make a difference. What is the effect of both age and gender?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nI’m providing an example using the 3-step procedure in exercise1E.inp. The results of adding these covariate to the model as predictors of the latent class can be found under the heading TESTS OF CATEGORICAL LATENT VARIABLE MULTINOMIAL LOGISTIC REGRESSIONS USING THE 3-STEP PROCEDURE. It can be seen, from the overall test and the pairwise comparisons, that the third group is significantly older, and has a significantly lower proportion of girls than the other two classes."
  },
  {
    "objectID": "day3_exercises.html#latent-transition-analysis-lta",
    "href": "day3_exercises.html#latent-transition-analysis-lta",
    "title": "Exercises",
    "section": "Latent transition analysis (LTA)",
    "text": "Latent transition analysis (LTA)\nIn this exercise we will explore the development of dating status over time using a latent transition analysis. Use the data in DatingSex.dat, which holds data on five dating indicators measured at two occasions (u11, …, u15, u21, …, u25), as well as the variable gender. The u-variables represent five yes/no items measured at two time points (first digit represents time point, second digit represents the item).\n\nExercise 2A\nSet up a model with two latent class variables for the two time points. Exclude the variable gender for now (i.e., explore the LTA without covariates first), and assume there are 2 latent classes. Restrict the thresholds (and hence response probabilities) across the two time points by first repeating the thresholds for each latent class (2), in both model c1 and model c2. To be sure Mplus does what you want, include equality constraints on the five thresholds of %c1#1% and %c2#1%, and similarly for %c1#2% and %c2#2%. Note that these constraints can be interpreted as imposing measurement invariance over time. Although we don’t test the assumption of measurement invariance in these exercises, it is definitely something you would want to check in practice.\nAfter running the analysis, inspect the proportions of yes/no answers for each of the indicators in the latent classes (look at probability scale in Mplus output).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe Mplus syntax should is given in exercise2A.inp. The parameters in probability scale can be found in under the heading RESULTS IN PROBABILITY SCALE in the output file. For example, we find that the probability of falling into category 1 (i.e., answering yes/no) is 0.434 (\\(SE = .024\\)) if you are in class 1 at the first time point, and 0.566 (\\(SE = .024\\)) for falling into category 2 (i.e., answering yes/no). Because of the imposed constraints, the probabilities also apply to time point 2, see Latent Class C2#1.\n\n\n\n\n\nExercise 2B\nExamine the proportions of participants in each class, based on the estimated model. Note that for each latent variable, the total proportions add up to 1. Next, examine the latent transition probabilities based on the estimated model. What do these probabilities signify?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou can find proportions of participants in each class under the heading FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE BASED ON ESTIMATED POSTERIOR PROBABILITIES. These probabilities represent the proportion of the total sample that is assigned to each class. Note that an individual can have a non-zero probability of being assigned to both classes. E.g., there might be a 70% probability that the person belongs to class 1, and a 30% probability that the person belongs to class 2. The proportions here are a sum across those probabilities for all participants. Thus, this person would contribute for 30% to the proportion of the sample in class 2.\nYou can find the latent transition probabilities based on the estimated model under the heading TECHNICAL 15 OUTPUT. These probabilities represent the probability that an individual assigned to one class at time one, will be assigned to another class at time 2. So for example, we see that people in class 1 at time 1 also tend to be in class 1 at time 2 (.76 probability).\n\n\n\n\n\nExercise 2C\nIf there is time, you can conduct additional analyses. Include gender as a control variable on the observed variables.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou could include gender as a control variable on the observed variables, by adding it to the USEVARIABLES, and including the following lines:\nu11-u15 ON gender; u21-u25 ON gender;\nSee exercise2C.inp. Alternatively, you could regress class membership on gender, to see whether men are more likely to be in a particular class than women, or vice versa. This is only allowed when you’re NOT using probability parametrization. So, you would have to remove this line:\nPARAMETERIZATION = PROBABILITY;\nAnd add this line:\nc1 c2 ON gender;\n\n\n\n\n\nExercise 2D\nWe are going to extend the LTA to a Mover-Stayer LTA. This model assumes that there is a subpopulation of “stayers” that stay in the same class, and a subpopulation of “movers” that is free to transition to a different class over time. Answer the below questions:\n\nContinuing with the 2 classes at both time points. Then, for movers, there is no restriction on the 2 by 2 transition matrix. However, what does the transition matrix for the stayers look like in terms of probabilities? Furthermore, what does the transition matrix for stayers look like in terms of thresholds?\nAdd a Movers-Stayers class (i.e., an additional latent categorical factor with 2 classes, namely a movers class and a stayers class) to the LTA specified in the previous exercise. Make sure that for the movers class the transition matrix has no restrictions, and that the stayers class has the restrictions as discussed above.\nRun the Movers-Stayers class and look in the output. Which proportion of people is categorized as movers/stayers?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBy definition, for stayers who are in category 1 at time point 1, there is a probability of 1 for being in category 1 at time point 2 as well, and a probability of 0 for transitioning to category 2. For stayers who are in category 2 at time point 1, there is a probability of 0 for being in category 1 at time point 2, but a probability of 1 for being in category 2. Translating this to thresholds, a large negative threshold represents a very high probability of being into that category, whereas a large positive threshold represents a low probability. So stayers who are in category 1 at time point 1 should have a large negative threshold for category 1 at time point 2, and a large positive threshold for category 2, etc.\nMplus model syntax for the mover-stayer model can be found in exercise2D.inp. Looking at TECHNICAL 15 OUTPUT, we can clearly see that we have specified a movers and a stayers class:\nP(C2=1|CM=1,C1=1)=0.271\nP(C2=2|CM=1,C1=1)=0.729\n\nP(C2=1|CM=1,C1=2)=0.542\nP(C2=2|CM=1,C1=2)=0.458\n\nP(C2=1|CM=2,C1=1)=1.000\nP(C2=2|CM=2,C1=1)=0.000\n\nP(C2=1|CM=2,C1=2)=0.000\nP(C2=2|CM=2,C1=2)=1.000\nLooking at the information under FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE BASED ON THEIR MOST LIKELY LATENT CLASS PATTERN, we see that 66.8% is classified as a mover, and 33.2% as a stayer.\n\n\n\n\nExercise 2E\nWe have not investigated whether 2 classes is the right number for this dataset. Investigate how many classes at each time point you would choose.\nThink about:\n\nWhether you think there should be an equal number of classes at both time points (this is mostly a theoretical decision).\nHow to build the model. Should you start by comparing unconstrained or constrained models?\nHow to decide what solution you prefer."
  },
  {
    "objectID": "day3_introduction.html",
    "href": "day3_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "The exercises in this lab session are designed, in the first place, for use of Mplus exclusively. However, for those interested, we have the option to run the latent growth mixture models in batch, using the R-package MplusAutomation. This package allows you to automate part of your workflow (like making plots and tables), and provides functions for plots that are more aesthetically pleasing, as well as more insightful. The exercises using MplusAutomation can be found with the course materials on SURFdrive."
  },
  {
    "objectID": "day4_exercises.html",
    "href": "day4_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "The researchers are interested in fitting a quasi-simplex model to these data, that is, a simplex model at the latent level, thus accounting for measurement error in the observations. This model is graphically represented in slide 19.\n\n\nProvide the names of the variances (i.e., indicate in which model matrix, and which position in this matrix they have) in the quasi-simplex graph in the slides. What is the difference between the \\(e\\)’s and the \\(\\zeta\\)’s?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\(e\\)’s are residuals at the measurement level and can be found in the \\(\\theta\\)-matrix. They only influence the observation at a single occasion in time. \\(\\zeta\\)’s are residuals of the simplex process and can be found in the \\(\\psi\\)-matrix. Their effect is carried forward to future observation through the autoregressive relationships. This difference allows Mplus to estimate both types of ``errors’’.\n\n\n\n\n\n\nHow would you specify the model in Mplus?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Exercise B.inp.\n\n\n\n\n\n\nDetermine the number of degrees of freedom for this model (indicate how you obtained this number). Is it possible to estimate this model?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are \\(\\frac{4 \\times 5}{2} = 10\\) unique elements in \\(S\\).\nFree parameters:\n\n4 residual variances at measurement level\n1 factor variance\n3 residual factor variances\n3 regression parameters\n11 parameters in total.\n\nTherefore, we have \\(10 - 11 = -1\\) df. It is not possible to estimate this model because we are trying to estimate more parameters than we have information in the data.\n\n\n\n\n\n\nTo make sure a quasi-simplex model is identified, often the variances of the measurement errors are constrained to be equal over time. How can you do this in Mplus? How many df does this model have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Exercise E.inp for how to constrain the measurement error variances over time. With constrained measurement error variances, we estimate 3 parameters less. So, we estimate \\(11 - 3 = 8\\) and therefore have \\(10 - 8 = 2\\) df.\n\n\n\n\n\n\nRun the model and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe find the below fit indices:\n\n\\(\\chi^{2}\\) = 13.29 with df = 2, \\(p = .0013\\),\nRMSEA = .057,\nCFI = .994, and\nTLI = .981.\n\nExcept for \\(\\chi^{2}\\) test of model fit, the model seems to fit the data well. Note, however, that the sample size is very large and therefore the \\(\\chi^{2}\\) is likely to be significant, even for minor problems with model fit.\n\n\n\n\n\n\nThe quasi-simplex model you just ran, led to the following warning:\nWARNING: THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE DEFINITE. THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. PROBLEM INVOLVING VARIABLE ETA4.\nWhat is the problem?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn your output, look at the reported (estimated) residual variances. We find that the residual variance of ETA4 is estimated to be negative. This is a Heywood case and it is causing the warning to appear. Note however, that it is significant, so ``just” fixing it to 0 as a solution is probably not warranted here.\n\n\n\n\n\n\nAs indicated in the description of the data, the third and fourth measurement were obtained at the same measurement wave (with only 40 minutes in between). Hence, the researchers proposed the following model instead of the regular quasi-simplex model. Explain why this model makes more sense for these data than the regular quasi-simplex model. Tip: check the description of the study at the beginning of this exercise.\n\n\n\nAdjusted quasi-simplex model.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAt each occasion there is a latent variable which represents Life Satisfaction. At the first two occasions there was only a single indicator of this latent variable, but at the third occasion there were two indicators.\n\n\n\n\n\n\nHow many df does this model have? Note that we keep the constraint on the variances of the measurement errors.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are \\(\\frac{4*5}{2} = 10\\) unique elements in S. We freely estimate:\n\n1 constrained residual variances at measurement level\n1 factor variance\n2 residual factor variances\n2 regression parameters\n1 factor loading\n7 parameters in total.\n\nTherefore, we have \\(10 - 7 = 3\\) df.\n\n\n\n\n\n\nAre these two models nested? If so, how? If not, why not, and how could we compare them?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, they are nested: this model is a special case of the previous model, as it is based on having ETA3 and ETA4 from the previous model now being a single latent variable. That is, we can constrain the residual variance of ETA4 to zero to get the alternative model. This gives us 1 df for the difference.\n\n\n\n\n\n\nSpecify this model in Mplus and run it. Report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Excercise J.inp for the model specification in Mplus. Apart from the \\(\\chi^{2}\\)-test of model fit, the model fits well:\n\n\\(\\chi^{2} (3) = 27.37\\), with \\(p &lt; .001\\),\nRMSEA = 0.069,\nCFI = 0.987,\nTLI = 0.973, and\nSRMR = 0.039.\n\n\n\n\n\n\n\nCompare the two models to each other. What can you conclude?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nComparing both models using the \\(\\Delta \\chi^{2}\\)-test gives us \\(27.37 – 13.29 = 14.0\\) with 1 df such that \\(p &lt; .001\\). This implies that imposing the restriction is not tenable. You can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool\nComparing the models using information criteria gives us AIC = 29593 and BIC = 29637 for the first model, and AIC = 29605 and BIC = 29643 for the second. In conclusion, all measures indicate the first model is better. However, the current model makes more theoretical sense, and the negative variance estimate in the first model is a problem. For these 2 reasons, we should prefer the current model.\n\n\n\n\n\n\nCan you improve the second model in any way? Indicate which parameter you would add to your model, and what this parameter represents in substantive terms.\n::: {.callout-caution collapse=“true”} #### Answer You can get the modification indices by adding MOD to the OUTPUT command. Here, the suggested BY statements make no sense (later life satisfaction as an indicator of previous life satisfaction). With regards to the ON statement, only the suggested effect of ETA3 ON ETA1 makes sense as we then predict forwards in time. The WITH statement suggests adding a covariance between the residuals of y3 and y4. If we add this covariance and look at the standardized results, we get a correlation. This correlation actually quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). r if(knitr::is_html_output()){\"\\\\details\"}\n\n\n\nRun a model in which you include the Y3 WITH Y4 parameter. Where will this relationship end up in the model? Does it lead to a significant improvement? How would you interpret this additional parameter?\n::: {.callout-caution collapse=“true”} #### Answer See Exercise M.inp for the Mplus specification of this model. The Y3 WITH Y4 parameter is an additional covariance between the residuals of y3 and y4 (so not between y3 and y4 themselves). Model fit is quite good (except for the \\(\\chi^{2}\\)-test of model fit):\n\n\\(\\chi^{2} (2) = 7.077\\), \\(p = .0291\\),\nRMSEA = 0.038,\nCFI = 0.997,\nTLI = 0.992, and\nSRMR = 0.011.\n\nTo compare this model to the previous model, we can do a the \\(\\Delta \\chi^{2}\\)-test: \\(27.37 – 7.08 = 20.29\\), with 1 df such that \\(p &lt; .001\\), which implies that adding the covariance between the residuals leads to a significant improvement in model fit. This additional parameter implies that y3 and y4 have more in common with each other than what would be expected based on their common dependence on ETA3. Note that in the standardized results, the WITH statement can be interpreted as a correlation, and it is quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). r if(knitr::is_html_output()){\"\\\\details\"}"
  },
  {
    "objectID": "day4_exercises.html#quasi-simplex-model",
    "href": "day4_exercises.html#quasi-simplex-model",
    "title": "Exercises",
    "section": "",
    "text": "The researchers are interested in fitting a quasi-simplex model to these data, that is, a simplex model at the latent level, thus accounting for measurement error in the observations. This model is graphically represented in slide 19.\n\n\nProvide the names of the variances (i.e., indicate in which model matrix, and which position in this matrix they have) in the quasi-simplex graph in the slides. What is the difference between the \\(e\\)’s and the \\(\\zeta\\)’s?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\(e\\)’s are residuals at the measurement level and can be found in the \\(\\theta\\)-matrix. They only influence the observation at a single occasion in time. \\(\\zeta\\)’s are residuals of the simplex process and can be found in the \\(\\psi\\)-matrix. Their effect is carried forward to future observation through the autoregressive relationships. This difference allows Mplus to estimate both types of ``errors’’.\n\n\n\n\n\n\nHow would you specify the model in Mplus?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Exercise B.inp.\n\n\n\n\n\n\nDetermine the number of degrees of freedom for this model (indicate how you obtained this number). Is it possible to estimate this model?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are \\(\\frac{4 \\times 5}{2} = 10\\) unique elements in \\(S\\).\nFree parameters:\n\n4 residual variances at measurement level\n1 factor variance\n3 residual factor variances\n3 regression parameters\n11 parameters in total.\n\nTherefore, we have \\(10 - 11 = -1\\) df. It is not possible to estimate this model because we are trying to estimate more parameters than we have information in the data.\n\n\n\n\n\n\nTo make sure a quasi-simplex model is identified, often the variances of the measurement errors are constrained to be equal over time. How can you do this in Mplus? How many df does this model have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Exercise E.inp for how to constrain the measurement error variances over time. With constrained measurement error variances, we estimate 3 parameters less. So, we estimate \\(11 - 3 = 8\\) and therefore have \\(10 - 8 = 2\\) df.\n\n\n\n\n\n\nRun the model and report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe find the below fit indices:\n\n\\(\\chi^{2}\\) = 13.29 with df = 2, \\(p = .0013\\),\nRMSEA = .057,\nCFI = .994, and\nTLI = .981.\n\nExcept for \\(\\chi^{2}\\) test of model fit, the model seems to fit the data well. Note, however, that the sample size is very large and therefore the \\(\\chi^{2}\\) is likely to be significant, even for minor problems with model fit.\n\n\n\n\n\n\nThe quasi-simplex model you just ran, led to the following warning:\nWARNING: THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE DEFINITE. THIS COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. PROBLEM INVOLVING VARIABLE ETA4.\nWhat is the problem?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn your output, look at the reported (estimated) residual variances. We find that the residual variance of ETA4 is estimated to be negative. This is a Heywood case and it is causing the warning to appear. Note however, that it is significant, so ``just” fixing it to 0 as a solution is probably not warranted here.\n\n\n\n\n\n\nAs indicated in the description of the data, the third and fourth measurement were obtained at the same measurement wave (with only 40 minutes in between). Hence, the researchers proposed the following model instead of the regular quasi-simplex model. Explain why this model makes more sense for these data than the regular quasi-simplex model. Tip: check the description of the study at the beginning of this exercise.\n\n\n\nAdjusted quasi-simplex model.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAt each occasion there is a latent variable which represents Life Satisfaction. At the first two occasions there was only a single indicator of this latent variable, but at the third occasion there were two indicators.\n\n\n\n\n\n\nHow many df does this model have? Note that we keep the constraint on the variances of the measurement errors.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are \\(\\frac{4*5}{2} = 10\\) unique elements in S. We freely estimate:\n\n1 constrained residual variances at measurement level\n1 factor variance\n2 residual factor variances\n2 regression parameters\n1 factor loading\n7 parameters in total.\n\nTherefore, we have \\(10 - 7 = 3\\) df.\n\n\n\n\n\n\nAre these two models nested? If so, how? If not, why not, and how could we compare them?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYes, they are nested: this model is a special case of the previous model, as it is based on having ETA3 and ETA4 from the previous model now being a single latent variable. That is, we can constrain the residual variance of ETA4 to zero to get the alternative model. This gives us 1 df for the difference.\n\n\n\n\n\n\nSpecify this model in Mplus and run it. Report on the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Mplus input file Excercise J.inp for the model specification in Mplus. Apart from the \\(\\chi^{2}\\)-test of model fit, the model fits well:\n\n\\(\\chi^{2} (3) = 27.37\\), with \\(p &lt; .001\\),\nRMSEA = 0.069,\nCFI = 0.987,\nTLI = 0.973, and\nSRMR = 0.039.\n\n\n\n\n\n\n\nCompare the two models to each other. What can you conclude?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nComparing both models using the \\(\\Delta \\chi^{2}\\)-test gives us \\(27.37 – 13.29 = 14.0\\) with 1 df such that \\(p &lt; .001\\). This implies that imposing the restriction is not tenable. You can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool\nComparing the models using information criteria gives us AIC = 29593 and BIC = 29637 for the first model, and AIC = 29605 and BIC = 29643 for the second. In conclusion, all measures indicate the first model is better. However, the current model makes more theoretical sense, and the negative variance estimate in the first model is a problem. For these 2 reasons, we should prefer the current model.\n\n\n\n\n\n\nCan you improve the second model in any way? Indicate which parameter you would add to your model, and what this parameter represents in substantive terms.\n::: {.callout-caution collapse=“true”} #### Answer You can get the modification indices by adding MOD to the OUTPUT command. Here, the suggested BY statements make no sense (later life satisfaction as an indicator of previous life satisfaction). With regards to the ON statement, only the suggested effect of ETA3 ON ETA1 makes sense as we then predict forwards in time. The WITH statement suggests adding a covariance between the residuals of y3 and y4. If we add this covariance and look at the standardized results, we get a correlation. This correlation actually quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). r if(knitr::is_html_output()){\"\\\\details\"}\n\n\n\nRun a model in which you include the Y3 WITH Y4 parameter. Where will this relationship end up in the model? Does it lead to a significant improvement? How would you interpret this additional parameter?\n::: {.callout-caution collapse=“true”} #### Answer See Exercise M.inp for the Mplus specification of this model. The Y3 WITH Y4 parameter is an additional covariance between the residuals of y3 and y4 (so not between y3 and y4 themselves). Model fit is quite good (except for the \\(\\chi^{2}\\)-test of model fit):\n\n\\(\\chi^{2} (2) = 7.077\\), \\(p = .0291\\),\nRMSEA = 0.038,\nCFI = 0.997,\nTLI = 0.992, and\nSRMR = 0.011.\n\nTo compare this model to the previous model, we can do a the \\(\\Delta \\chi^{2}\\)-test: \\(27.37 – 7.08 = 20.29\\), with 1 df such that \\(p &lt; .001\\), which implies that adding the covariance between the residuals leads to a significant improvement in model fit. This additional parameter implies that y3 and y4 have more in common with each other than what would be expected based on their common dependence on ETA3. Note that in the standardized results, the WITH statement can be interpreted as a correlation, and it is quite high: \\(.522\\) (SE = .044), \\(p &lt; .001\\). r if(knitr::is_html_output()){\"\\\\details\"}"
  },
  {
    "objectID": "day4_exercises.html#clpm-ri-clpm",
    "href": "day4_exercises.html#clpm-ri-clpm",
    "title": "Exercises",
    "section": "CLPM & RI-CLPM",
    "text": "CLPM & RI-CLPM\nFor the cross-lagged panel model (CLPM) and the random intercept cross-lagged panel model (RI-CLPM) we are going to analyze data that were reported in Davies et al. (2016). The summary data (means, standard deviations and correlation matrix) are included in Davies.dat, and contains the means, standard deviations, and the correlation matrix. The number of observations is 232. There are 5 waves of data, taken when the child was 7, 8, 13, 14, and 15 years old. The order of the variables is:\n\nChild gender\nParental education\nInterparental hostility (waves 1-5): composite score based on observational data and questionnaires, reflecting the degree of hostility between the parents\nInterparental dysphoria (waves 1-5): based on composite score based on observational data and questionnaires, reflecting the degree of dysphoria\nChild/adolescent insecurity in the relationship with the parents (waves 1-5)\nPsychological problems (waves 1-5): based on the subscales anxious/depressed, withdrawal, aggressive behaviors, and delinquency scales of the Child Behavior Checklist (CBCL), filled out by both parents.\n\nHere we will focus on Interparental dysphoria and Psychological problems of the child. The DATA and VARIABLE commands should be:\nDATA: \n  TYPE = MEANS STDEVIATIONS CORRELATION;\n  FILE = Davies.dat;\n  NOBSERVATIONS = 232;\n\nVARIABLE: \n  NAMES = ChildGen ParentEd\n  Hos1 Hos2 Hos3 Hos4 Hos5 Dys1 Dys2 Dys3 Dys4 Dys5\n  Ins1 Ins2 Ins3 Ins4 Ins5 PsPr1 PsPr2 PsPr3 PsPr4 PsPr5;\n  USEVARIABLES = Dys1-Dys5 PsPr1-PsPr5;\n\nExercise A\nHow many sample statistics are there for this data set (focusing on the 5 measures of dysphoria and the 5 measures of psychological problems?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are 10 observed variables such that there are \\(\\frac{10*11}{2} = 55\\) unique elements in the observed covariance matrix S, and 10 observed means in M. Therefore, there are 65 sample statistics in total.\n\n\n\n\n\nExercise B\nWe begin with an RI-CLPM (see slide 53). For now, do not impose any constraints on the parameters across time. Draw the model, and indicate which parameters will be estimated freely. How many parameters will be estimated in total? So how many df are there?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the RI-CLPM we estimate:\n\n2 variances for the random intercepts,\n1 covariance between the random intercepts,\n2 variances for the within-person centered variables at wave 1,\n1 covariance between the within-person centered variables at wave 1,\n8 residual variances (for the dynamic errors of both variables at wave 2-5),\n4 covariances between the residuals (for the dynamics errors at waves 2-5),\n16 lagged parameters (4 for each interval), and\n10 means.\n\nIn total, we estimate 44 parameters such that we have \\(65 - 44 = 21\\) df.\n\n\n\n\n\nExercise C\nRun the model. Check whether the number of df is correct. Also look at the TECH1 output, to see if you understand where the free parameters are. What is the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for this model is in RICLPM.inp. The model means are estimated in the \\(\\nu\\)-matrix, no parameters are estimated in the \\(\\theta\\)-matrix (measurement error variances), \\(\\lambda\\)-matrix (factor loadings), or \\(\\alpha\\)-matrix (means/intercepts of the latent variables). The variances and covariance of the random intercepts, the within-person centered variables at wave 1, and the dynamic errors at subsequent waves are all estimated in the \\(\\psi\\)-matrix. The lagged regression coefficients are estimated in \\(\\beta\\).\nApart from the \\(\\chi^{2}\\)-test of model, all fit indices indicate at least acceptable fit.\n\n\\(\\chi^{2} (21) = 41.451\\), \\(p = .005\\),\nRMSEA = 0.065,\nCFI = 0.979,\nTLI = 0.956, and\nSRMR = 0.029.\n\n\n\n\n\n\nExercise D\nInclude the significant standardized parameter estimates for the covariances (i.e., the WITH statements) and the lagged regression parameters (i.e., the ON statements) in the figure below. Indicate which part of the model is considered the between-person part, and which part is the within-person part.\n\n\n\nThe bivariate random-intercept cross-lagged panel model with 5 repeated measures (waves).\n\n\n\n\nExercise E\nOmit the random intercepts. How many parameters and df does this model have? What is the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for this model is CLPMasRICLPM.inp. The model has three parameters less (and thus 3 df more) than the previous model: 2 variances and the covariance for the random intercepts.\nThe model fit indices show that this model does not fit well:\n\n\\(\\chi^{2} (24) = 73.374\\), \\(p &lt; .001\\),\nRMSEA = 0.094,\nCFI = 0.950,\nTLI = 0.907, and\nSRMR = 0.061.\n\n\n\n\n\n\nExercise F\nSpecify the CLPM and run this model. Compare it to the previous two models. How are these models related?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for this model is in CLPM.inp. This model is statistically identical to the previous model; these are different parameterizations of the same model. The model fit is therefore also exactly the same. Hence, this model is a special case of the RI-CLPM.\nComparing the two models using a chi-square difference test gives: \\(\\Delta \\chi^{2} = 73.37 - 41.45 = 31.92\\) with \\(24 – 21 = 3\\) df, \\(p &lt; .001\\). Hence, the random intercepts should not be omitted; put differently, there are stable, trait-like difference between families in the two variables (parental dysphoria and psychological problems).\nHowever, when constraints are placed on the bound of the parameter space (which is the case here, fixing a variance to 0 is its absolute minimum value), we should actually use the chi-bar-square test (\\(\\bar{\\chi}^{2}\\)-test; Stoel et al. 2006). The traditional \\(\\Delta \\chi^{2}\\)-test does not take into account that variances can only be positive and is therefore conservative. This means that if it is significant, we are certain that the correct test (i.e., the \\(\\bar{\\chi}^{2}\\) test) would also be significant. On the other hand, when the usual chi‐square test is not significant, we do not know anything about the result of the correct test (it can be significant or not significant).\nIf you are working in R with the lavaan-package, you can find more information about the \\(\\bar{\\chi}^{2}\\)-test at jeroendmulder.github.io/RI-CLPM/lavaan.html#(bar{chi}^{2})-test. For Mplus users, there is a Shiny app by Rebecca Kuiper available as well.\n\n\n\n\n\nExercise G\nInclude the significant standardized parameter estimates for the covariances and the lagged regression parameters in the figure below.\n\n\n\nThe bivariate cross-lagged panel model with 5 repeated measures (waves).\n\n\n\n\nExercise H\nDiscuss how the model results differ.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nCross-lagged relationships In the RI-CLPM none of the cross-lagged parameters are significant. In contrast, in the CLPM there is a positive relationship from PsPr1 to Dys2. This implies that higher levels of children’s psychological problems at age 7 are followed by higher levels of interparental dysphoria at age 8. Moreover, from age 14 to 15 both cross-lagged parameters are significant and positive, indicating that psychological problems are followed by increases in interparental dysphoria, but also that increased interparental dysphoria is followed by an increase in psychological problems for the adolescent.\nAutoregressive parameters The autoregressive parameters in the RI-CLPM are lower, and have larger SE’s, such that fewer reach significance. This is expected as within-person stability is now captures in the random intercepts, rather than in the autoregressive effects in the CLPM.\nCorrelations In the CLPM only the residual correlation at wave 2 is significant; it is negative, indicating that external effects tend to have an opposite effect on these two processes; increases in Dysphoria are accompanied by decreases in psychological problems and vice versa. In the RI-CLPM, the within-person correlation at wave 1 is not significantly different from zero; however, at waves 2, 3 and 4 the correlations between the residuals is significant and negative. At wave 5 the residual variance is not significant.\nIn the RI-CLPM there is also the correlation between the random intercepts (i.e., the trait-like difference between families). This turns out to be a very substantial correlation of .63: Hence, in contrast to the results from the CLPM and the within-level results from the RI-CLPM, there is a strong positive relationship between trait-like levels of interparental dysphoria and trait-like levels of psychological problems."
  },
  {
    "objectID": "day4_introduction.html",
    "href": "day4_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "This computer lab session consist roughly of 2 parts: First we will focus on the quasi-simplex model, and second we will focus on the random intercept cross-lagged panel model. For the quasi-simplex model we are going to study the concept of life satisfaction. The covariance matrix is in the file Coenders.dat and comes from 1724 children and adolescents that participated in the National Survey of Child and Adolescent Well-Being (NSCAW) in Russia. They indicated how satisfied they were with their lives as a whole on a 10-point scale (1 = not at all satisfied, 10 = very satisfied). There were three waves (1993, 1994 and 1995). At the third wave, the question was asked twice (with 40 minutes in between). Hence, in total there are four measurements obtained at three waves. The data and variables commands for these data should read:\nDATA: \n  TYPE = COVARIANCE;\n  FILE = Coenders.dat;\n  NOBSERVATIONS = 1724;\n\nVARIABLE: \n  NAMES = Y1 Y2 Y3 Y4;\nAll of the input files for the exercises are provided with the course materials on SURFdrive."
  },
  {
    "objectID": "day5_exercises.html",
    "href": "day5_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "In Model 1 we first decompose each variable at each time point (occasion) in two parts:\n\na person-specific mean, which has the same value at each occasion but differs from person to person\na deviation from that mean for each person and occasion.\n\nHence, we decompose the variables into two latent variables: One with person-specific means, at the between level. One with deviations from these means unique to each occasion and person, at the within level. These deviations can be seen as simply the within-person centered scores for a person at each occasion.\nNext, we add two regression relationships:\n\nBetween level: the person means of Somber are regressed on the person means of Event\nWithin level: the person-mean centered variable Somber is regressed on the person-mean centered variable Event.\n\nNote that this is not a dynamic SEM model yet in terms of the Mplus specification, because there are no explicit lagged relationships in the model. But note that there is an implicit lagged relationship: Although the two variables are measured at the same occasion (as indicated by the subscript t), the variable Event refers to the interval between t-1 and t, while the variable Somber is referring to the specific time point t. Hence, the reported on events take place before the somber feelings.\nThis model can be represented as depicted below, with on the left this decomposition, and on the right the regression models specified at each level.\n\n\n\nTo run this model, use the input file model1.inp. In the ANALYSIS command you will find a number of commands that set up the Bayesian multilevel estimation procedure:\nANALYSIS:   TYPE = TWOLEVEL;\n            ESTIMATOR = BAYES; \n            PROC = 2;\n            BITER= (2000);\n            BSEED = 9556;\nMake sure the following commands for OUTPUT and PLOT are included:\nOUTPUT:     TECH1 STDYX;\nPLOT:       TYPE = PLOT3;\n            FACTORS = ALL;\nCheck out the model specification (i.e., the MODEL command). What do the commands on the within person level and on the between person level do?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVia ‘Somber ON Event’ at the within level, for each person in the model their somber within-person centered scores are regressed on their within-person centered event scores on the same measurement occasion. The regression coefficients and other model parameters – except for the means of somber and event - are the same for all persons.\nVia ‘Event’ we tell Mplus to make Event endogenous like Somber, such that means and variances are estimated for this variable as well - and Event is decomposed in a between person level and within-person level as well. That is, for both Somber and Event we now estimate the mean score over time for each individual inside the model. On the within level the deviations from these means (within-person centered scores) at each time point are modeled. At the between level the relationships among these means, that vary from individual to individual, are modeled.\nVia ‘Somber ON Event’ at the between level, it is specified that the person-specific means for Somber are regressed on the person-specific means for Event.\n\n\n\n\n\n\nWhile the model is running, write down the model in equations.\n\nStart with the decomposition, i.e., \\(E_{it}=\\) …\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S_{it} = \\mu_{S i} + S_{it}^{(w)}\\] \\[E_{it} = \\mu_{E i} + E_{it}^{(w)}\\]\n\n\n\n\nWrite down the within-level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S_{it}^{(w)} = b \\times E_{it}^{(w)} + \\zeta_{S it}\\] Parameters estimated at this level:\n\nFixed within-person slope b (same for each person)\nResidual within-person variance for S, the variance of \\(\\zeta_Sit\\)\nWithin-person variance of the (made endogenous) predictor \\(E^{(w)}_{it}\\)\n\n\n\n\n\nWrite down the between level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[\\mu_{S i} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\zeta_{Si} \\] Parameters estimated at this level:\n\nGrand intercept \\(\\gamma_{00}\\)\nBetween-person slope \\(\\gamma_{01}\\)\nBetween-person residual variance of \\(\\zeta_{Si}\\)\nMean of the between-person predictor \\(\\mu_{Ei}\\)\nVariance of the between-person predictor \\(\\mu_{Ei}\\)\n\n\n\n\n\n\n\nWhen the model is finished running, we first need to check the trace plots of the Bayesian estimation procedure to see if there are signs for non-convergence. Go to the icon with the two graphs, and click on this. Then, choose the option “Bayesian posterior parameter trace plots” and click “View”.\n\nBy clicking “OK” in the next window, the trace plot of parameter 1 appears. You can use the icons with the histograms and the left and right headed arrows to move backward and forward through the parameters (their names are in the headings of the plots).\n\nWrite down how these parameters relate to the ones you identified above (in questions c. and d.),\nAre there any problems with convergence based on these plots? Can you tell what parameter from question b each plot is about?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nParameter 1, %WITHIN%: SOMBER ON EVENT → within-person regression coefficient b\nParameter 2, %WITHIN%: SOMBER → within-person residual variance for somber\nParameter 3, %WITHIN%: EVENT → within-person variance on Event\nParameter 4, %BETWEEN%: [SOMBER] → between-person intercept on Somber (\\(\\gamma_{00}\\))\nParameter 5, %BETWEEN%: [EVENT] → between-person mean on Event\nParameter 6, %BETWEEN%: SOMBER ON EVENT → between-person regression coefficient (\\(\\gamma_{01}\\))\nParameter 7, %BETWEEN%: SOMBER → between-person residual variance of somber\nParameter 8, %BETWEEN%: EVENT → between-person variance on Event\n\nConvergence looks fine for the parameters.\n\n\n\n\n\n\nGo to the output, and consider the parameter estimates. Interpret the findings for the within-person and the between-person slopes (e.g., do they differ from zero, are they positive or negative, what about their size?).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin Level\n\n SOMBER     ON\n    EVENT             -0.203       0.010      0.000      -0.223      -0.184      *\n\n\nBetween Level\n\n SOMBER     ON\n    EVENT             -0.953       0.159      0.000      -1.266      -0.651      *\nBoth slopes are negative, implying that:\n\nWithin person: People’s increased (relative to their mean level) Event scoretends to be followed by a decreased (relative to their mean level) temporary somberness score. A 1 unit higher event score tends to be followed by a decrease of .20 units in their somber score.\nBetween person: People a relatively high (compared to other people) mean for event, tend to have a relatively low (compared to other people) mean for somberness. A 1 unit higher mean would imply about a .95 units lower mean for Somber.\n\nThe between-person slope is more than 4 times steeper: Note however that the between-person variance in Event is about 10 times smaller than the within-person variance in Event (0.278 vs. 2.844). Hence, in the next step we look at the standardized results.\n\n\n\n\n\n\nCheck the standardized results to compare the size of the slopes within and between.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSOMBER     ON\n    EVENT             -0.259       0.012      0.000      -0.284      -0.236      *\n\nSOMBER     ON\n    EVENT             -0.529       0.074      0.000      -0.656      -0.374      *\nThe standardized between slope is more than twice as steep than the within slope.\nIn terms of \\(R^{2}\\):\n\n6.7% of the momentary within-person variability in Somber is explained by within-person variability in Events.\n28.0% of the stable between-person variability in Somber is predicted by between-person differences in average Event."
  },
  {
    "objectID": "day5_exercises.html#random-intercept-model-with-implicit-lagged-effects-not-dsem",
    "href": "day5_exercises.html#random-intercept-model-with-implicit-lagged-effects-not-dsem",
    "title": "Exercises",
    "section": "",
    "text": "In Model 1 we first decompose each variable at each time point (occasion) in two parts:\n\na person-specific mean, which has the same value at each occasion but differs from person to person\na deviation from that mean for each person and occasion.\n\nHence, we decompose the variables into two latent variables: One with person-specific means, at the between level. One with deviations from these means unique to each occasion and person, at the within level. These deviations can be seen as simply the within-person centered scores for a person at each occasion.\nNext, we add two regression relationships:\n\nBetween level: the person means of Somber are regressed on the person means of Event\nWithin level: the person-mean centered variable Somber is regressed on the person-mean centered variable Event.\n\nNote that this is not a dynamic SEM model yet in terms of the Mplus specification, because there are no explicit lagged relationships in the model. But note that there is an implicit lagged relationship: Although the two variables are measured at the same occasion (as indicated by the subscript t), the variable Event refers to the interval between t-1 and t, while the variable Somber is referring to the specific time point t. Hence, the reported on events take place before the somber feelings.\nThis model can be represented as depicted below, with on the left this decomposition, and on the right the regression models specified at each level.\n\n\n\nTo run this model, use the input file model1.inp. In the ANALYSIS command you will find a number of commands that set up the Bayesian multilevel estimation procedure:\nANALYSIS:   TYPE = TWOLEVEL;\n            ESTIMATOR = BAYES; \n            PROC = 2;\n            BITER= (2000);\n            BSEED = 9556;\nMake sure the following commands for OUTPUT and PLOT are included:\nOUTPUT:     TECH1 STDYX;\nPLOT:       TYPE = PLOT3;\n            FACTORS = ALL;\nCheck out the model specification (i.e., the MODEL command). What do the commands on the within person level and on the between person level do?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nVia ‘Somber ON Event’ at the within level, for each person in the model their somber within-person centered scores are regressed on their within-person centered event scores on the same measurement occasion. The regression coefficients and other model parameters – except for the means of somber and event - are the same for all persons.\nVia ‘Event’ we tell Mplus to make Event endogenous like Somber, such that means and variances are estimated for this variable as well - and Event is decomposed in a between person level and within-person level as well. That is, for both Somber and Event we now estimate the mean score over time for each individual inside the model. On the within level the deviations from these means (within-person centered scores) at each time point are modeled. At the between level the relationships among these means, that vary from individual to individual, are modeled.\nVia ‘Somber ON Event’ at the between level, it is specified that the person-specific means for Somber are regressed on the person-specific means for Event.\n\n\n\n\n\n\nWhile the model is running, write down the model in equations.\n\nStart with the decomposition, i.e., \\(E_{it}=\\) …\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S_{it} = \\mu_{S i} + S_{it}^{(w)}\\] \\[E_{it} = \\mu_{E i} + E_{it}^{(w)}\\]\n\n\n\n\nWrite down the within-level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S_{it}^{(w)} = b \\times E_{it}^{(w)} + \\zeta_{S it}\\] Parameters estimated at this level:\n\nFixed within-person slope b (same for each person)\nResidual within-person variance for S, the variance of \\(\\zeta_Sit\\)\nWithin-person variance of the (made endogenous) predictor \\(E^{(w)}_{it}\\)\n\n\n\n\n\nWrite down the between level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[\\mu_{S i} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\zeta_{Si} \\] Parameters estimated at this level:\n\nGrand intercept \\(\\gamma_{00}\\)\nBetween-person slope \\(\\gamma_{01}\\)\nBetween-person residual variance of \\(\\zeta_{Si}\\)\nMean of the between-person predictor \\(\\mu_{Ei}\\)\nVariance of the between-person predictor \\(\\mu_{Ei}\\)\n\n\n\n\n\n\n\nWhen the model is finished running, we first need to check the trace plots of the Bayesian estimation procedure to see if there are signs for non-convergence. Go to the icon with the two graphs, and click on this. Then, choose the option “Bayesian posterior parameter trace plots” and click “View”.\n\nBy clicking “OK” in the next window, the trace plot of parameter 1 appears. You can use the icons with the histograms and the left and right headed arrows to move backward and forward through the parameters (their names are in the headings of the plots).\n\nWrite down how these parameters relate to the ones you identified above (in questions c. and d.),\nAre there any problems with convergence based on these plots? Can you tell what parameter from question b each plot is about?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nParameter 1, %WITHIN%: SOMBER ON EVENT → within-person regression coefficient b\nParameter 2, %WITHIN%: SOMBER → within-person residual variance for somber\nParameter 3, %WITHIN%: EVENT → within-person variance on Event\nParameter 4, %BETWEEN%: [SOMBER] → between-person intercept on Somber (\\(\\gamma_{00}\\))\nParameter 5, %BETWEEN%: [EVENT] → between-person mean on Event\nParameter 6, %BETWEEN%: SOMBER ON EVENT → between-person regression coefficient (\\(\\gamma_{01}\\))\nParameter 7, %BETWEEN%: SOMBER → between-person residual variance of somber\nParameter 8, %BETWEEN%: EVENT → between-person variance on Event\n\nConvergence looks fine for the parameters.\n\n\n\n\n\n\nGo to the output, and consider the parameter estimates. Interpret the findings for the within-person and the between-person slopes (e.g., do they differ from zero, are they positive or negative, what about their size?).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin Level\n\n SOMBER     ON\n    EVENT             -0.203       0.010      0.000      -0.223      -0.184      *\n\n\nBetween Level\n\n SOMBER     ON\n    EVENT             -0.953       0.159      0.000      -1.266      -0.651      *\nBoth slopes are negative, implying that:\n\nWithin person: People’s increased (relative to their mean level) Event scoretends to be followed by a decreased (relative to their mean level) temporary somberness score. A 1 unit higher event score tends to be followed by a decrease of .20 units in their somber score.\nBetween person: People a relatively high (compared to other people) mean for event, tend to have a relatively low (compared to other people) mean for somberness. A 1 unit higher mean would imply about a .95 units lower mean for Somber.\n\nThe between-person slope is more than 4 times steeper: Note however that the between-person variance in Event is about 10 times smaller than the within-person variance in Event (0.278 vs. 2.844). Hence, in the next step we look at the standardized results.\n\n\n\n\n\n\nCheck the standardized results to compare the size of the slopes within and between.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSOMBER     ON\n    EVENT             -0.259       0.012      0.000      -0.284      -0.236      *\n\nSOMBER     ON\n    EVENT             -0.529       0.074      0.000      -0.656      -0.374      *\nThe standardized between slope is more than twice as steep than the within slope.\nIn terms of \\(R^{2}\\):\n\n6.7% of the momentary within-person variability in Somber is explained by within-person variability in Events.\n28.0% of the stable between-person variability in Somber is predicted by between-person differences in average Event."
  },
  {
    "objectID": "day5_exercises.html#random-intercept-and-slopes-model-with-implicit-lagged-effects-not-dsem",
    "href": "day5_exercises.html#random-intercept-and-slopes-model-with-implicit-lagged-effects-not-dsem",
    "title": "Exercises",
    "section": "Random Intercept and Slopes Model with Implicit Lagged Effects (not DSEM)",
    "text": "Random Intercept and Slopes Model with Implicit Lagged Effects (not DSEM)\nIn Model 2, we extend Model 1 to allow for individual differences in the within-person slope. This implies that people may respond differently to a temporary increase in the variable Event; this can be interpreted as individual differences in reactivity. This random slope b1 becomes another latent variable at the between-person level, where we can use it as a predictor of the person-specific means of the variable Somber. We will also allow this slope variable to correlate with the means of Event.\nModel 2 can be represented as depicted below, with on the left the within-between decomposition, and on the right the regression models specified at each level. Note the black dot on the arrow to indicate a random slope at the within level.\n\n\nSpecify the Mplus Model\nWrite down the model command for this model. When your are done, check whether you specified it correctly by looking at the provided answers, and/or the input file model2.inp. Note that under command ‘ANALYSIS’ in the input file, we now need to specify type = TWOLEVEL RANDOM.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMODEL:  %WITHIN%\n              b1 | Somber ON Event;\n              Event;  \n              %BETWEEN%\n              Somber ON Event b1;\n                b1 WITH Event;\n\n\n\n\n\nModel Equations\nWhile the model is running, write down the model equations. The decomposition into within and between will be the same as for Model 1.\n\nWrite down the within level model. What parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + \\zeta_{S it}\\] The difference is that now the regression coefficient has a subject index i, because it now differs from person to person. The mean and variance of b1i are estimated at the between person level.\nParameters estimated at this level: - Residual within-person variance of \\(\\zeta_{Sit}\\) - Within-person variance of the predictor \\(E^{(w)}_{it}\\)\n\n\n\n\nWrite down the between level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[\\mu_{Si} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\gamma_{02} \\times b_{1i} + \\zeta_{Si}\\]\nParameters estimated at this level:\n\nGrand intercept \\(\\gamma_{00}\\)\nBetween-person slope \\(\\gamma_{01}\\)\nBetween-person slope \\(\\gamma_{02}\\)\nBetween-person residual variance of \\(\\zeta_{Si}\\)\nMean of the between-person predictor \\(\\mu_{Ei}\\)\nVariance of the between-person predictor \\(\\mu_{Ei}\\)\nMean of the between-person predictor \\(b_{1i}\\) (i.e., within-person slope)\nVariance of the between-person predictor \\(b_{1i}\\)\nCovariance of \\(b_{1i}\\) and \\(\\mu_{Ei}\\) (with statement in mplus code)\n\n\n\n\n\n\nConvergence\nCheck the trace plots of the posteriors for the parameters of the model. Can you link them to the free parameters you identified above? Are there signs of non-convergence?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAll looks good.\n\n\n\n\n\nInterpret the Results\n\nWhich parameter is the one we should focus on when interested in the average of the person-specific within-person slopes b1?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n\nMeans\n    B1                -0.206       0.014      0.000      -0.234      -0.179      *\nIt is the mean B1 reported at the between level.\n\n\n\n\nThere are two ON statements at the between level now. Report the results for these regressions, and indicate how to interpret these results.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n\nSOMBER     ON\n    B1                -1.966       1.079      0.020      -4.366      -0.095      *\n\n SOMBER     ON\n    EVENT             -0.839       0.176      0.000      -1.188      -0.490      *\nAs before: People with a relatively high (compared to other people) mean for event, tend to have a relatively low (compared to other people) mean for somberness.\nIn addition: People that have a relatively low mean for somber (compared to other people), tend to have a lower within-person slope b1.\n\n\n\n\nInterpreting the effect of b1 on Somber is challenging for most people. What may be helpful is to make a plot of the (bivariate) relationship between b_1i and the within-person mean on somber.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nGo to the plotting options and choose “Between-level scatterplots…”\n\nClick View. Then select “B1, mean” (the posterior means of each person’s B1 coefficient) as the X variable and “SOMBER (estimated cluster mean)” (each person’s mean for Somber) as the Y variable:\n\nClick OK. This produces the scatter plot.\n\n\n\n\nInterpret the relationship you see in the scatterplot.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe correlation is negative (about -0.503), indicating that a higher b1 (within-person slope) tends to go together with a lower person-mean on somber.\nNote that the individual differences in b1 run from -0.5 to about 0. Hence, the closer b_1i is to zero, the lower the person’s average score on somber.\nPut differently, people who tend to be less reactive to momentary changes in Events (b_1i closer to zero), are also characterized by a lower trait score on somber.\nNote that this plot is just presenting the bivariate relationship between the two random effects; in contrast, the regression coefficient in the output also is based on a regression model with multiple predictors (in this case, also the person mean on Event). Hence the scatter plot may be helpful, but is not a direct reflection of the regression coefficient (this is the same as in normal multiple linear regression analysis).\n\n\n\n\nLet us look at the person-specific slopes (the random effect b1) that were estimated.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo this end, go to the plot menu again and choose the option “Two-level cluster-specific observed and estimated values plots”. Click “View”, and click “OK” in the next window: Now you have a scatter plot of the data of a single individual, with the variable Event on the x-axis and Somber on the between-axis. The slope of the red line is the individual’s b1 (the individual specific regression coefficient for regressing Somber on Event).\nTo fix the axes (which makes it easier to compare the results across individuals, go to the plot menu at the top, choose “Axis properties” and then “Edit settings”:\n\nIn the next window, choose the “Axes Range” tab, click the “Fixed scale” option (at the top), and set the scale range for X from -4 to 4 (because Event was measured on a scale running from -3 to 3), and set the scale of Y from 0 to 8 (because it was measured on a scale from 0 to 7). Then click “OK”.\n\nNow, you can go through the plots of different individuals by clicking the person buttons on the top (with the left arrow to go back, and the right arrow to go forward). Because you fixed the axes, you can easily compare the slopes for different people. This illustrates that every person has his/her own slope."
  },
  {
    "objectID": "day5_exercises.html#dynamic-sem-including-random-autoregressive-effects.",
    "href": "day5_exercises.html#dynamic-sem-including-random-autoregressive-effects.",
    "title": "Exercises",
    "section": "Dynamic SEM: Including random autoregressive effects.",
    "text": "Dynamic SEM: Including random autoregressive effects.\nNext, we include a dynamic relationship in our model. First, create a lagged version of Somber, by using the LAGGED = in the VARIABLE command). In the next step, we’ll include the lagged variable as a predictor at the within level, allowing for a random slope - this produces a random autoregressive effect (each individual will get their own autoregressive effect). This model can be represented as:\n\n\nSpecify the Mplus Model\nWrite out the model command for this model. Check with the input file model3.inp if you specified it correctly.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMODEL:\n            %WITHIN%\n            s1 | Somber ON Event; ! random regression\n            s2 | Somber ON somber&1; ! random autoregression \n            \n            %BETWEEN%\n            Somber ON Event s1 s2;\nThe command &1 attached to a variable indicates this should be a lag 1 variable. The parameter label followed by | produces a random effect like before.\n\n\n\n\n\nModel Equations\nWhile the model is running, write down the model equations.\n\nWrite down the within level model. What parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + b_{2i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\]\nParameters estimated at this level:\n\nResidual within-person variance of \\(\\zeta_{Sit}\\)\nWithin-person variance of the predictor \\(E^{(w)}_{it}\\)\n\n\n\n\n\nWrite down the between level model. Which parameters are estimated at this level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[\\mu_{Si} = \\gamma_{00} + \\gamma_{01} \\times \\mu_{Ei} + \\gamma_{02} \\times b_{1i} + \\gamma_{03} \\times b_{2i} + \\zeta_{Si}\\]\nParameters estimated at this level:\n\nGrand intercept \\(\\gamma_{00}\\)\nBetween-person slope \\(\\gamma_{01}\\)\nBetween-person slope \\(\\gamma_{02}\\)\nBetween-person slope \\(\\gamma_{03}\\)\nBetween-person residual variance of \\(\\zeta_{Si}\\)\nMean of the between-person predictor \\(\\mu_{Ei}\\)\nVariance of the between-person predictor \\(\\mu_{Ei}\\)\nMean of the between-person predictor \\(b_{1i}\\) (i.e., within-person slope)\nVariance of the between-person predictor \\(b_{1i}\\)\nMean of the between-person predictor \\(b_{2}\\) (i.e., autoregressive slope)\nVariance of the between-person predictor \\(b_{2i}\\)\nCovariances between \\(b_{1i}\\), \\(b_{2i}\\), and \\(\\mu_{Ei}\\)\n\n\n\n\n\n\nConvergence & Interpret the Results\n\nAgain, check the trace plots. If they look okay, consider the parameter estimates. What can you say about the autoregressive effects?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMeans\n    B2                 0.340       0.022      0.000       0.300       0.383      *\n\nVariances\n    B2                 0.031       0.007      0.000       0.020       0.047      *\nThe average autoregressive effect is 0.34, with SD=0.18 (=sqrt(0.031)). On average, about .34 of the previous Somber score carries over to the next Somber score. The actual autoregressive effects will however differ from person to person.\nHence, on average across persons, about 12% (0.34^2=.12) of the within-person variability in somberness is predicted by the autoregressive effect. The exact numbers will however differ from person to person.\n\n\n\n\nTo obtain some idea of the individual differences in the autoregressive parameter, we will consider diverse plots. One plot that might be of interest is the histogram of the individual parameter values.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAgain, go to the plotting options, and now select the option: Between-level histogram (etc.)\n\nClick View. In the next window, select the random autoregressive parameter (B2):\n\nClick “OK”. This shows you the sample distribution of the autoregressive parameter. Note that the individual scores are based on the mean of an individual’s posterior distribution for this parameter.\n\n\n\n\nWhat is the highest and the lowest person-specific autoregressive effect?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe lowest is about 0.08 (so close to zero), the largest is about 0.7, so strong and positive. Most effects are around .2 to .45.\n\n\n\n\nConsider the level 2 effects where the within-person means of Somber are predicted by the within-person mean on Event, the random slope b1, and by the random slope b2. How would you interpret these results?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n SOMBER     ON\n    B1                -2.342       1.403      0.037      -5.405       0.153\n    B2                 0.181       0.626      0.377      -1.013       1.473\n SOMBER     ON\n    EVENT             -0.831       0.183      0.000      -1.194      -0.476      *\nHence, only the person mean on Event is a significant predictor. The effect is negative, so people with relatively high person-specific means for ‘pleasant Event’ (report higher pleasant Event scores on average compared to others), tend to have relatively low person-specific means for Somber.\nWhile the effect of b1 was significant in a previous model, it no longer is in this model."
  },
  {
    "objectID": "day5_exercises.html#dynamic-sem-including-random-autoregressive-and-cross-lagged-effects",
    "href": "day5_exercises.html#dynamic-sem-including-random-autoregressive-and-cross-lagged-effects",
    "title": "Exercises",
    "section": "Dynamic SEM: Including random autoregressive and cross-lagged effects",
    "text": "Dynamic SEM: Including random autoregressive and cross-lagged effects\nUntil now, we have treated Event as a predictor only. However, it is also possible that the experience of negative and positive Events is affected by a person’s momentary somberness. Moreover, there may be an autoregressive effect for Events. Hence, we are interested in the following model:\n\nThus, we have added two random slopes to the model: b3 and b4, the autoregressive and cross-lagged effect respectively. At the between level, we allow the now 6 random effects to be correlated, rather than that we predict one from the other as we did before. Note that while the figure does not include a relationship between S and E at t-1, these predictors are related in the model (as the model that is specified at time point t, equally applies to all other time points - so we could have added the same b1 arrow there); the current representation simply represents which model statements are needed.\n\nSpecify the Mplus Model\nHow do you specify this model? Check your specification with the model4.inp input file.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMODEL:\n            %WITHIN%\n            s1 | Somber ON Event; ! lagged random regression\n            s2 | Somber ON somber&1; ! random autoregression for somber\n            s3 | Event ON Event&1; ! random autoregression for Event \n            s4 | Event ON somber&1; ! lagged regression from Somber to Event\n            \n            %BETWEEN%\n            Somber Event s1 s2 s3 s4 WITH Event s1-s4;\n\n\n\n\n\nModel Equations\n\nWhile running the model, write down the regression equation for the within level.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\[S^{(w)}_{it}=b_{1i}\\times E^{(w)}_{it} + b_{2i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\]\n\\[E^{(w)}_{it}=b_{3i}\\times E^{(w)}_{it-1} + b_{4i}\\times S^{(w)}_{it-1} + \\zeta_{S it}\\]\n\n\n\n\nIn contrast to typical cross-lagged models that we covered in the lecture, we are not including a covariance between the residuals here. Why not?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe concurrent (lag 0) relationship is already accounted for by the (random) regression of \\(S_{it}\\) on \\(E_{it}\\). The residual of \\(S_{it}\\) is the part that cannot be predicted from \\(E_{it}\\) (and \\(S_{it-1}\\)); hence it would not make sense to correlate this residual with the residual of \\(E_{it}\\).\n\n\n\n\nHow many parameters are estimated at each level?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin: 2 residual variances\nNote that because Event is now not only a predictor, but also an outcome, we no longer estimate its variance, but instead its residual variance; the variance of Event is now a function of the residual variance, the regression coefficients, and the variances of the predictors.\nBetween:\n\n4 fixed slopes (mean slopes)\n2 fixed intercepts (grand means)\n6 variances of the 4 slopes and 2 intercepts (random effects)\n15 covariances between these random effects\n\n29 parameters in total.\n\n\n\n\n\nConvergence & Interpret the Results\nWhen the model is finished, check the trace plots for signs of non-convergence.\n\nLook at the estimated effects. What can you conclude about the autoregressive and cross-lagged coefficients?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMeans\n    B1               -0.169       0.014      0.000      -0.195      -0.142      *\n    B2                 0.342       0.022      0.000       0.298       0.382      *\n    B3                 0.118       0.020      0.000       0.078       0.159      *\n    B4               -0.126       0.024      0.000      -0.176      -0.081      *\nAll of the average coefficients differ from zero.\nThe average autoregressive coefficients, b2 and b3, are positive. So for on average, there is carryover from one moment to the next both for feelings of somberness and the experienced pleasantness of events.\nThe average Cross-lagged coefficients b1 and b4 are negative, implying: More positive Events tend to be followed by less somberness an occassion later, while increased somberness tends to by followed by less positively experienced events.\n\n\n\n\nTo compare the strengths of the cross-lagged effects, we need to consider the standardized parameters. Check the standardized output, and interpret the regression coefficients there.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nB1 | SOMBER ON\n    EVENT             -0.211       0.013      0.000      -0.237      -0.187      *\n\n B2 | SOMBER ON\n    SOMBER&1           0.341       0.014      0.000       0.312       0.370      *\n\n B3 | EVENT ON\n    EVENT&1            0.119       0.015      0.000       0.091       0.149      *\n\n B4 | EVENT ON\n    SOMBER&1          -0.105       0.015      0.000      -0.137      -0.077      *\nThe standardized autoregressive parameters should be (approximately) the same as the unstandardized ones. The reason for this is that the variances for \\(y_{t}\\) and \\(y_{t-1}\\) in a stationary model are the same by definition. Slight differences in the point estimates might occur due to the calculation procedure of the standardized effects.\nNote however that the standard errors are smaller for the standardized fixed effects. This is because the standardized fixed effect is a sample mean of the person-specific effects, and disregards sampling variability. Significance of fixed effects should hence be based on the unstandardized fixed effects. This also applies to the fixed cross-lagged effects. This is not an issue for the person-specific standardized effects.\nThe standardized average (fixed) effect from Event to Somber (-.211) is twice the size of the one from Somber to Event (-.105); so on average, the effect from Events on mood is stronger than the other way around. This however may be different from person to person.\n\n\n\n\nConsider the R-square output as well. How can you interpret this?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin-Level R-Square Averaged Across Clusters\n                                Posterior  One-Tailed         95% C.I.\n    Variable        Estimate       S.D.      P-Value   Lower 2.5%  Upper 2.5%\n    SOMBER          0.227       0.012      0.000       0.204       0.250\n    EVENT           0.057       0.008      0.000       0.043       0.073\nOn average, 23% of within-person variability in Somber can be accounted for by the lagged relationships; for Event this is 6%. These numbers may however differ from person to person.\n\n\n\n\nConsider the covariances and correlations between the random effects. For which of these correlations is there evidence that they deviate from zero?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are a few significant correlations:\nSOMBER   WITH\n    B1                -0.346       0.132      0.007      -0.585      -0.071      *\n    B3                 0.342       0.151      0.017       0.027       0.623      *\n\nB3       WITH\n    B4                 0.571       0.198      0.011       0.102       0.865      *\n\n SOMBER   WITH\n    EVENT             -0.523       0.083      0.000      -0.663      -0.346      *\nPeople with relatively high person-specific means for somber tend to have relatively low values for the effect of event on somber; and relatively high autoregressive effects for Event.\nPeople with relatively higher autoregressive effects for Event tend to have relatively high values for the cross-lagged effect of somber on event.\nPeople with relatively high person-specific means for somber tend to have relatively low person-specific means for event.\nTo interpret these effects further, we’ll look at some plots in the following exercise.\n\n\n\n\nFor each of these correlations, get a scatter plot and interpret the result (use the “Between-level scatterplots” option).\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSomber with b1: A higher mean level for Somber is related to lower b1 (effect of Event on Somber), which is negative on average; hence people with a lower level on somber, tend to have a b1 closer to zero, while individuals with a higher level on Somber tend to have a b1 that is more negative.\nSomber with b3: Individuals with relatively high person-specific means of Somber tend to have relatively high positive autoregressive effects in their Events.\nb3 with b4: People with relatively higher autoregressive effects for Event (b3) tend to have a relatively high b4 - Since the average b4 is negative, it means: higher autoregression for Event is a b4 closer to zero, while a lower autoregression for Event is associated with a stronger negative effect of Somber on Event.\nPeople with relatively high person-specific means for somber tend to have relatively low person-specific means for event."
  },
  {
    "objectID": "day5_exercises.html#dynamic-sem-adding-an-implicit-lag-2-effect-bonus",
    "href": "day5_exercises.html#dynamic-sem-adding-an-implicit-lag-2-effect-bonus",
    "title": "Exercises",
    "section": "Dynamic SEM: Adding an implicit lag 2 effect (bonus)",
    "text": "Dynamic SEM: Adding an implicit lag 2 effect (bonus)\nAs mentioned before, due to the time interval that the variable Event is referring to, you can think of this as a variable that is situated in time between two consecutive measurements of somber. Hence the lag 0 regression (b1) is in a way already a lagged relationship, and we have therefore not included the regression of Somber at occasion t on Event at occasion t-1, but only a “concurrent” relationship of Somber t on Event t (and hence no residual correlation between the residuals of somber t and event t). However, we could add the lagged effects to the model, which would than imply an implicit ‘lag 2’ effect. We then get the following model:\n\n\nAdditional parameters\nHow many additional parameters does this model have in comparison to the previous one?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe mean (fixed effect) of B5 and its variance (random effect) and the covariance between this random effect and the other 6 random effects; so 8 additional parameters.\n\n\n\n\n\nRun the Mplus Model & Interpret the Results\nRun this model, and interpret the results for the fixed effects of the lagged parameters.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMeans\n    B1                -0.162       0.014      0.000      -0.190      -0.135      *\n    B2                 0.324       0.022      0.000       0.279       0.367      *\n    B3                 0.116       0.021      0.000       0.076       0.156      *\n    B4                -0.131       0.025      0.000      -0.182      -0.083      *\n    B5                -0.056       0.013      0.000      -0.080      -0.029      *\nThey all differ significantly from zero. The autoregressive parameters (b2 and b3) are positive. The cross-lagged relationships are all negative. The new lagged effect (b5: delayed effect of Event on somber) is also negative; however, it is less strong than the other effect of Event on Somber (b1)."
  },
  {
    "objectID": "day5_exercises.html#dynamic-sem-adding-a-between-level-factor-structure-bonus",
    "href": "day5_exercises.html#dynamic-sem-adding-a-between-level-factor-structure-bonus",
    "title": "Exercises",
    "section": "Dynamic SEM: Adding a between level factor structure (bonus)",
    "text": "Dynamic SEM: Adding a between level factor structure (bonus)\nInstead of simply correlating the random effects at the between level, we may also consider modeling these variables more explicitly. For instance, we can specify a factor model to try to capture what these level 2 variables have in common. This can be represented like this:\n\nHow many parameters does this model have at each level?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin: 2 residual variances\nBetween:\n\n7 residual variances for the indicators\n6 factor loadings (one is fixed to 1 for scaling the latent variable)\n1 latent variance for eta (mean of zero)\n7 intercepts (means) for the indicators\n\n\n\n\n\nSpecify the Mplus Model\nTo specify the factor model at the between level, use:\n%BETWEEN%\neta BY somber@1 Event b1*1 b2 b3 b4 b5;\n(The b1*1 is required in the Mplus v8.1; it is probably not necessary any more in a future version.)\n\nWhile running the model, indicate how you would interpret the factor \\(\\eta\\).\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt is a latent variable which explains the shared variance among the random effects. Without further theory about what kind of latent variable would cause variation in all these random effects it is hard to give it a more meaningful label! Looking at the factor loadings may help interpret the factor here (akin to an EFA).\n\n\n\n\n\nConvergence & Interpret the Results\nIf the model converged, check the parameter estimates. Which factor loadings are significant, and what do they mean?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n\n ETA      BY\n    SOMBER             1.000       0.000      0.000       1.000       1.000\n    EVENT             -0.529       0.257      0.000      -1.365      -0.271      *\n\n ETA      BY\n    B1                -0.062       0.038      0.014      -0.158      -0.006      *\n    B2                -0.016       0.055      0.353      -0.140       0.084\n    B3                 0.095       0.058      0.020       0.005       0.249      *\n    B4                 0.078       0.063      0.069      -0.025       0.240\n    B5                -0.032       0.034      0.159      -0.111       0.031\nPeople with higher eta tend to have:\n\nHigher mean levels of somberness\nLower mean levels of unpleasant-pleasant Event\nMore negative effects of Event t on Somber t (b1) (more reactive to events)\nHigher carry-over in Event (b3) (more intertia in event)\n\nPerhaps the latent variable could be called something like ‘negative outlook’ or ‘neuroticism’. But it would be better to apply a model like this when one has a specific theory in mind!"
  },
  {
    "objectID": "day5_exercises.html#dynamic-sem-making-the-residual-variance-person-specific-bonus",
    "href": "day5_exercises.html#dynamic-sem-making-the-residual-variance-person-specific-bonus",
    "title": "Exercises",
    "section": "Dynamic SEM: Making the residual variance person-specific (bonus)",
    "text": "Dynamic SEM: Making the residual variance person-specific (bonus)\nIn this model, we allow the residual variances to be random. This is often not an option in multilevel software, but within the Bayesian approach of DSEM this is fairly doable. We do still assume normal distributions for the random effects, which is not 100% appropriate for variances as they should not be able to become negative. To avoid issues with this, we model logtransformed random variances instead. The model is depicted below - note that we have also kept the factor structure at the between level from exercise 6:\n\n\nSpecify the Mplus Model\nSpecify this model (or sneak a peak at our input file) and run it. While it is running, determine the number of parameters that are estimated in this model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin level: 0 parameters\nBetween level: - 9 fixed effects - 9 variances - 8 factor loadings - 1 factor variance\n27 parameters in total\n\n\n\n\n\nConvergence\nCheck the trace plots for signs of nonconvergence. Are there signs that indicate convergence may be slow?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSome of the trace plots show there is a lot of autocorrelation in the Bayesian samples (iterations) over time. This means the chains ‘mix’ slowly - the two chains are not covering each other all the time, and only move slowly along the y-axis.\nHowever, the chains do vary around the same constant (which would be the posterior mean estimate).\nEssentially, there is no evidence that the procedure is not converging, but that it is going relatively slowly. As a result, we’ll need more iterations than if we have lower autocorrelations.\nOne could decide to increase the number of iterations. This can be done by simply increasing the iteration number, or by use the thin option here. When using THIN=10; Mplus saves only every tenth sample of the MCMC chain, and it also means that 10 times as many iterations are used. Thinning reduces (visible) autocorrelation in the chains, and as a result you can more easily see if the chains are mixing well.\n\n\n\n\n\nInterpret the Results\n\nConsider the factor loading estimates: What do you conclude?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n\n ETA      BY\n    SOMBER             1.000       0.000      0.000       1.000       1.000\n    EVENT             -0.371       0.103      0.000      -0.595      -0.187      *\n\n ETA      BY\n    B1                -0.088       0.024      0.000      -0.143      -0.047      *\n    B2                 0.046       0.048      0.153      -0.039       0.147\n    B3                 0.060       0.040      0.051      -0.012       0.144\n    B4                -0.002       0.056      0.489      -0.115       0.105\n    B5                -0.028       0.013      0.014      -0.055      -0.004      *\n    LOGVS              1.412       0.403      0.000       0.856       2.448      *\n    LOGVE              0.057       0.107      0.282      -0.132       0.289\nB3 no longer loads significantly on \\(\\eta\\).\nPeople with relatively high scores on \\(\\eta\\), tend to have:\n\nrelatively high person-specific means for somberness\nrelatively low person-specific means for event\nmore negative effects of \\(Event_{t}\\) on \\(Somber_{t}\\) (b1)\nmore negative delayed effects of \\(Event_{t-1}\\) on \\(Somber_{t}\\) (b5)\nHave a larger (log) residual variance for somberness\n\n\n\n\n\nConsider the R-square in the standardized results: What do you conclude?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin: On average across persons, 24% of the within-person variance of momentary somberness and 5% of momentary Events is explained\nBetween: the factor eta accounts for a substantial proportion of between-person variability in average somberness (54%), direct reactivity (b1; 43%), and residual within-person variance in somberness (RVS; 45%).\nIt accounts for a smaller proportion of variance in the average pleasantness of Events (22%) and delayed reactivity (b5; 20%).\nThe other R-squares are closer to zero."
  },
  {
    "objectID": "day5_exercises.html#dsem-adding-a-level-2-between-level-predictor-bonus",
    "href": "day5_exercises.html#dsem-adding-a-level-2-between-level-predictor-bonus",
    "title": "Exercises",
    "section": "DSEM: Adding a level 2 (between level) predictor (bonus)",
    "text": "DSEM: Adding a level 2 (between level) predictor (bonus)\nFinally, we consider a between level observed predictor for the nine random effects. For instance, we may consider a personality trait like Neuroticism as a useful predictor of individual differences in person-specific average somberness, and person-specific average experienced unpleasantness-pleasantness of events. Furthermore, we can investigate whether it predicts individual differences in inertia (autoregression), reactivity (cross-lagged regressions), and residual variances.\n\n\nSpecify the Mplus Model\n\nSpecify the model and run it. While it is running indicate how many parameters this model has.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWithin level: 0 parameters\nBetween level:\n\n9 fixed effects\n9 variances\n9 regression coefficients\n1 mean for the between level predictor N\n1 variance for the between level predictor N\n\n29 parameters in total (….but see the next exercise)\n\n\n\n\nCheck the number of free parameters in the output (under model fit). Is this correct? If it is not correct, which parameter is added/deleted by default by Mplus?\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIt is 30 rather than 29.\nThe additional parameter that is estimates is the covariance between the residuals of the mean Somber and mean Events at the between level.\n\n\n\n\n\nInterpret the results\nInterpret the resulting parameter estimates - focus on the regression coefficients of the model that was estimated.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBetween Level\n\n B1         ON\n    NEUROTIC          -0.004       0.002      0.004      -0.008      -0.001      *\n\nLOGVS      ON\n    NEUROTIC           0.051       0.016      0.001       0.019       0.082      *\n\n SOMBER     ON\n    NEUROTIC           0.056       0.011      0.000       0.035       0.077      *\n\n EVENT      ON\n    NEUROTIC          -0.018       0.007      0.005      -0.032      -0.004      *\nPeople that score relatively high on Neuroticism tend to have relatively:\n\nhigh person-specific means for Somber\nlow person-specific means for Event (on average less pleasant momentary events)\nstronger reactivity to Event (i.e., a more negative b1)\nlarger residual variance for the variable Somber (more unexplained momentary fluctuations for Somberness)"
  },
  {
    "objectID": "day5_introduction.html",
    "href": "day5_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "In these exercises we focus on analyzing intensive longitudinal data (ILD) obtained with experience sampling (also referred to as ecological momentary assessments).\nWe will use data from Bringmann et al. (2013), stored in file Bringmann1.dat. It contains data from 129 persons, with each between 20 to 60 repeated measurements per variable. Throughout these exercises we will focus on two variables: Somber (to what degree are you feeling somber right now?), and Event (report on the most important event since the previous beep and indicate how unpleasant-pleasant is was).\n\n\n\n\nReferences\n\nBringmann, Laura F., Nathalie Vissers, Marieke Wichers, Nicole Geschwind, Peter Kuppens, Frenk Peeters, Denny Borsboom, and Francis Tuerlinckx. 2013. “A Network Approach to Psychopathology: New Insights into Clinical Longitudinal Data.” Edited by Gabriel Alejandro De Erausquin. PLoS ONE 8 (4): e60188. https://doi.org/10.1371/journal.pone.0060188."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced course on using Mplus",
    "section": "",
    "text": "This course material is part of the Advanced course on using Mplus, a five-day summer school course hosted by Utrecht University’s department of Methodology and Statistics. If you already know how to analyse your data in Mplus but want to learn more about what you are actually doing, and especially if you want to know more about advanced longitudinal analyses, this course is for you. The course consists of in-depth lectures on the fundamentals of SEM, Mplus, and advanced longitudinal models.\nUsing the menu on the left, you can navigate to the exercises of each day."
  }
]