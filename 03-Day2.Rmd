# Day 2: Latent Growth Models

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(MplusAutomation)
library(tidySEM)
show_answers <- TRUE
knitr::opts_chunk$set(warning = FALSE, message = FALSE, results = "hide", eval = show_answers, echo = show_answers)
options(digits = 2)
# f <- list.files(pattern = "(inp|out|log|dat|gh5)$")
# f <- f[!f %in% c("DatingSex.dat", "DDS8_1.dat", "PTSD.dat")]
# file.remove(f)
```

This computer lab session demonstrates to run latent growth models in batch, using the R-package `MplusAutomation`.
Note that, if you do not want to automate part of your workflow (like making plots and tables), you can also use Mplus exclusively.
All of the input files for the exercises described in this GitBook are provided with the course materials.

To get started with today's computer lab, first open the project file called `"S23_student.Rproj"`. It should load in the program "RStudio". The bottom right panel has several tabs, including one called "Files". Click on "Files" in this bottom right tab, and click the file "growth_exercises.R". 

## Exercise 1: burn survivors 
 
The file `“PTSD.dat”` contains data on burn survivors.
An incomplete, basic Mplus syntax can be found in the file 
`“PTSD - M0.inp”`.

Specifying that same syntax could be done in R, using `MplusAutomation`, as well. 
First, load the file `PTSD.dat` into the R environment. 
For convenience's sake, rename the columns of the data object to something a human would understand:

```{r read_dataptsd, echo = TRUE, eval = TRUE}
data <- read.table("PTSD.dat", na.strings = -999)
names(data) <- c("gender", "tvlo",
                 "W1", "W2", "W3", "W4", "W5", "W6", "W7", "W8",
                 "pain")
```

To specify a basic, *incomplete* syntax, use:

```{r, echo = TRUE, eval = TRUE}
basic <- mplusObject(
  TITLE = "exercise 1",
  MODEL = "",
  OUTPUT = "standardized;",
  PLOT = "SERIES = w1-w8 (s);
          TYPE = PLOT3;",
  rdata = data,
  usevariables =
    c("W1", "W2", "W3", "W4", "W5", "W6", "W7", "W8")
)
```

To evaluate this model, you can use:

```{r, echo = TRUE, eval = FALSE}
result <- mplusModeler(basic, modelout = "basic.inp", run = 1L)
```

The argument `run = 1L` creates the Mplus input file and data, evaluates the input file, thus creating an output file, and reads the results into R.

To summarize the results, you can use:

```{r, echo = TRUE, eval = FALSE}
# For one model
SummaryTable(result)
# For more models
SummaryTable(list(result1, result2))
```

### Exercise 1a

Specify a latent growth model. Consider different specifications discussed in the lecture, and try to find the best specification.

Use only the time measurements, not including additional 
predictor variables.  
Think about: 

* which metric of time to use (see the SPSS file for more information about the variables); 
* the shape of the function (linear or quadratic); 
and base your decision of the best model on:   
* model fit indices; 
* model comparison tools; 
* plots; 
* interpretation of the model parameters. 

<details>
  <summary><b>Click to show answers</b></summary>

**Deciding on the metric of time **

From the SPSS file variable descriptions:  

* SVL wave 1 (2 weeks after burn injury) 
* SVL wave 2 (4 weeks) 
* SVL wave 3 (2 months) 
* SVL wave 4 (4 months) 
* SVL wave 5 (6 months) 
* SVL wave 6 (9 months) 
* SVL wave 7 (12 months) 
* SVL wave 8 (18 months) 

Based on these descriptions, I’ve chosen for the following specification of time in the LGM: 

`"i s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"`
 
In this specification I set the first time point to 0.5 months after burn injury (approximation 
of 2 weeks after burn injury), the second time point to 1 month after burn injury 
(approximation of 4 weeks after burn injury), etc. 

**Deciding on Linear v.s. Linear + Quadratic slope** 

Some example syntaxes for running models with different trajectory shapes are shown below, along with a table of the resulting fit statistics. 

For the model with a quadratic slope, it was necessary to fix the variance of Q at 0 to ensure convergence (you can do this by 
adding q@0; to the syntax). For both models, only CFI and TLI indicate adequate fit. 

```{r}
# First, create a linear model from the basic one
linear <- basic
linear$MODEL <-
  "i s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_linear <- 
  mplusModeler(linear, modelout = "linear.inp", run = 1L)
# Then, a quadratic one
quad <- basic
quad$MODEL <-
  "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_quad <-
  mplusModeler(quad, modelout = "quad.inp", run = 1L)
# Then, a quadratic one with fixed variance
quad0 <- basic
quad0$MODEL <-
  "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;
   q@0;"
result_quad0 <-
  mplusModeler(quad0, modelout = "quad0.inp", run = 1L)
# Combine them both in a list:
results <- list(result_linear, result_quad, result_quad0)
# Compare the fit:
SummaryTable(results,
             keepCols = c("Filename", "Parameters",
                          "AIC", "BIC", "RMSEA_Estimate",
                          "CFI", "TLI", "SRMR"))
``` 

```{r, results = "asis", echo = FALSE}
# First, create a linear model from the basic one
invisible({
linear <- basic
linear$MODEL <- "i s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_linear <- mplusModeler(linear, modelout = "linear.inp", run = 1L)
# Then, a quadratic one
quad <- basic
quad$MODEL <- "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_quad <- mplusModeler(quad, modelout = "quad.inp", run = 1L)
# Then, a quadratic one with fixed variance
quad0 <- basic
quad0$MODEL <- "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;
               q@0;"
result_quad0 <- mplusModeler(quad0, modelout = "quad0.inp", run = 1L)
# Combine them both in a list:
results <- list(result_linear, result_quad, result_quad0)
})
kbl(SummaryTable(results, keepCols = c("Filename", "Parameters", "AIC", "BIC", "RMSEA_Estimate", "CFI", "TLI", "SRMR")), digits = 2)
```

Model comparison tools: To see which model fit the data better, we can do a Chi-square 
difference test, using the function `chisq_sb()` from the `tidySEM` package. It works directly on MplusAutomation's `SummaryTable`s:

```{r, echo = TRUE, eval = FALSE}
library(tidySEM)
chisq_sb(SummaryTable(list(result_linear, result_quad0), keepCols = c("Filename", "ChiSqM_Value", "ChiSqM_DF")))
```
```{r, results = "asis", echo = FALSE}
library(tidySEM)

kbl(chisq_sb(SummaryTable(list(result_linear, result_quad0), keepCols = c("Filename", "ChiSqM_Value", "ChiSqM_DF"))), digits = 2)
```

Note that the 
Furthermore, both AIC and BIC are lower in the 
model with a quadratic slope. Thus, model misfit is significantly lower when the quadratic 
slope is added.

**Plots**

To examine the plots, you must open Mplus and examine its native plots.

**Model parameters**

The added quadratic slope is significant (Q = 0.02, p < .001), indicating that, 
on average, the growth curve does follow a quadratic curve.

```{r, echo = TRUE, eval = FALSE}
tab <- table_results(result_quad0, columns = NULL)
tab[tab$paramheader == "Means", c("param", "est_sig", "pval")]
```
```{r, results = "asis", echo = FALSE}
tab <- table_results(result_quad0, columns = NULL)
kbl(tab[tab$paramheader == "Means", c("param", "est_sig", "pval")], digits = 2, row.names = FALSE)
```

`r if(knitr::is_html_output()){"\\details"}`

### Exercise 1b: Add covariates

Using the best fitting LGM model found above, regress the growth parameters on TVLO and regress Pain on the growth parameters (see examples from slides 195 and 199).
Are there gender differences in the regression of the 
growth parameters on TVLO and in the regression of Pain on the growth parameters?

<details>
  <summary><b>Click to show answers</b></summary>
  
To answer this question, we use multi-group analysis.
To do this with MplusAutomation, we add the 
following syntax to the VARIABLE argument: 

`VARIABLE = "GROUPING IS gender (1 = male 2 = female);"`

Since we needed to fix the quadratic slope variance to 0, we cannot estimate any 
regressions on the quadratic slope or use the quadratic slope as a predictor of some 
outcome. We therefore focus on the intercept and linear slope. 

Here is how we can specify the full syntax (starting with the quad0 model as base):

```{r}
# Assuming quad0 was the best, start with that
covs <- quad0
# Add to the existing model
covs$MODEL <- c(covs$MODEL,
                "
                i s on TVLO;
                pain on i s; 
                MODEL male:
                i on TVLO (m1);
                s on TVLO (m2);
                pain on i (m3);
                pain on s (m4);
                MODEL female:
                i on TVLO (f1);
                s on TVLO (f2);
                pain on i (f3);
                pain on s (f4);")
# Add new usevariables:
covs$usevariables <- c(covs$usevariables,
                       "tvlo", "gender", "pain")
covs$rdata
# Add grouping variable:
covs$VARIABLE <- "GROUPING IS gender (1 = male 2 = female);"
# Add parameter tests
covs$MODELTEST <- "m3 = f3; m4 = f4;"
                
result_covs <- mplusModeler(covs,
                            modelout = "covs.inp",
                            run = 1L)
# Obtain the model summaries; you need the Wald test for
# the parameter difference tests.
get_summaries(result_covs)
```
```{r, echo = FALSE, eval = TRUE, results='hide'}
invisible({
  linear <- basic
linear$MODEL <- "i s | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_linear <- mplusModeler(linear, modelout = "linear.inp", run = 1L)
# Then, a quadratic one
quad <- basic
quad$MODEL <- "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;"
result_quad <- mplusModeler(quad, modelout = "quad.inp", run = 1L)
# Then, a quadratic one with fixed variance
quad0 <- basic
quad0$MODEL <- "i s q | W1@0.5 W2@1 W3@2 W4@4 W5@6 W6@9 W7@12 W8@18;
               q@0;"
result_quad0 <- mplusModeler(quad0, modelout = "quad0.inp", run = 1L)
# Combine them both in a list:
results <- list(result_linear, result_quad, result_quad0)
  covs <- quad0
# Add to the existing model
covs$MODEL <- c(covs$MODEL,
                "
                i s on TVLO;
                pain on i s; 
                MODEL male:
                i on TVLO (m1);
                s on TVLO (m2);
                pain on i (m3);
                pain on s (m4);
                MODEL female:
                i on TVLO (f1);
                s on TVLO (f2);
                pain on i (f3);
                pain on s (f4);")
# Add new usevariables:
covs$usevariables <- c(covs$usevariables, "tvlo", "gender", "pain")
covs$rdata
# Add grouping variable:
covs$VARIABLE <- "GROUPING IS gender (1 = male 2 = female);"
# Add parameter tests
covs$MODELTEST <- "m3 = f3; m4 = f4;"
                
result_covs <- mplusModeler(covs, modelout = "covs.inp", run = 1L)
})
```
```{r, echo = FALSE, results='markup'}
get_summaries(result_covs)
```

This is only an illustrative example for how to approach this analysis; your specific execution may differ.

Note that in this example, the Wald $\chi^2$ p-value is not significant.
That means that there are no significant sex differences in the effect of the growth trajectory on pain.

Note that the Wald test is an overall test of **all** 
comparisons that we specify in `MODELTEST`.

Thus, if you want a separate test for the regression of TVLO on the growth parameters,
you need to re-run the analysis but with a different `MODELTEST` argument.

What is your conclusion about the other research question (regarding TVLO)?

Note that there are also other ways to test these hypotheses, aside from a Wald test.
Model comparisons would also be a feasible way; either using AIC/BIC, or using a Chi square / Likelihood ratio test to compare models with parameters free vs constrained.
For this, you could use the function `chisq_sb()` as before.
`r if(knitr::is_html_output()){"\\details"}`

#### Visualization

If you want to plot the model for these two groups, 
you can use the SEM graphing package `tidySEM`.
This flexible package produces fully customizable plots based on the R graphing package `ggplot2` for Mplus (and `lavaan`) models.
If you want to make publication quality graphs, [here is an online tutorial for graph customization](https://cjvanlissa.github.io/tidySEM/articles/Plotting_graphs.html).
The script below demonstrates how to plot a model using `tidySEM`. Assuming that we only want to visualize the regression part of the model, you could specify:

```{r demotidysem1, echo = TRUE, eval = TRUE}
library(tidySEM)
library(dplyr)
lo <- get_layout("",     "I",   "",
                 "TVLO", "",   "PAIN",
                 "",     "S",   "", rows = 3)
graph_sem(result_covs, layout = lo)
```

<!-- lo <- get_layout("PAIN",   "",   "",   "",   "",   "",   "",   "TVLO", -->
<!--                  "I",      "",   "",   "S",  "",   "",   "",   "Q", -->
<!--                  "W1",     "W2", "W3", "W4", "W5", "W6", "W7", "W8", rows = 3) -->
<!-- prepare_graph(result_covs, layout = lo) %>% -->
<!--   hide_var() %>% -->
<!--   plot() -->

#### Tabulating results

In addition to graphing, it is also possible to tabulate the results using `tidySEM`.
Here is a brief example:

```{r, echo = TRUE, eval = FALSE}
# Get all columns of results
tab <- table_results(result_covs, columns = NULL)
# Retain regression parameters
tab <- tab[tab$op == "~", ]
# Remove group name from the label
tab$label <- gsub("\\.(FE)?MALE", "", tab$label)
# Make a wide table with both groups next to each other
tab <- reshape(tab,
               timevar = "group",
               idvar = "label",
               direction = "wide")
# Retain only the standardized estimate, pvalue, and 95% CI
tab[, c(1, grep("(est_sig|pval|confint)_std", names(tab)))]
```

```{r 1b_make_table_hidden, eval = TRUE, echo = FALSE, results = "asis"}
# Get all columns of results
tab <- table_results(result_covs, columns = NULL)
# Retain regression parameters
tab <- tab[tab$op == "~", ]
# Remove group name from the label
tab$label <- gsub("\\.(FE)?MALE", "", tab$label)
# Make a wide table with both groups next to each other
tab <- reshape(tab, timevar = "group", idvar = "label", direction = "wide")
# Retain only columns with the standardized estimate, pvalue, and 95% CI
row.names(tab) <- NULL
kbl(tab[, c(1, grep("(est_sig|pval|confint)_std", names(tab)))], digits = 2)
```

## Exercise 2: Alcohol use 

The figure below depicts the basic Latent Growth model for the alcohol use data from Duncan, Duncan & Strycker example 8_1.

![Latent Growth model for alcohol](./Materials/Figure1_lgm_alcohol.png){width=400px}

The data are in the file `DDS8_1.dat`, with variables ALC1YR1 ALC1YR2 ALC1YR3 ALCPROB5 AGE1 and 
GENDER1. Missing values are coded as -99. The variable ALCPROB5 is categorical, it indicates alcohol problems in 
year 5 of the study (0=no, 1=yes).

First, load the file `DDS8_1.dat` into the R environment. For convenience's sake, rename the columns of the data object to something a human would understand:

```{r read_dataalc, echo = TRUE, eval = TRUE}
data <- read.table("DDS8_1.dat", na.strings = -99)
names(data) <- c("ALC1YR1", "ALC1YR2", "ALC1YR3",
                 "ALCPROB5", "AGE1", "GENDER1")
```

Now, examine the patterns of missing data. For this, you could use Mplus,
or in R, you can use the `mice` package:

```{r, eval = FALSE, echo = TRUE}
install.packages("mice")
library(mice)
md.pattern(data)
```
```{r, eval = TRUE, echo = FALSE, results='asis'}
library(mice)
md.pattern(data)
```

The missing data pattern shows that the majority of the cases is complete, there is a small amount of attrition over time (panel dropout).

### Exercise 2a

Set up the growth curve model as depicted in the Figure in Mplus.
As a starting point, use the `MplusAutomation` code below.

* Add the necessary syntax statements to finalize the syntax.
* Request sample statistics and standardized (STDYX) output. 
* Inspect the output carefully with special attention for 
    1. how well the model fits
    2. interpretation of the output; how well does the model predict alcohol use over the 
years?

```{r, echo = TRUE, eval = FALSE}
m0 <- mplusObject(
  TITLE = "LGA MODEL",
  MODEL = "",
  OUTPUT = "",
  rdata = data,
  usevariables = c("ALC1YR1", "ALC1YR2", "ALC1YR3"))
```

<details>
  <summary><b>Click to show answers</b></summary>

Here is an example of how to approach the problem:

```{r}
m0 <- mplusObject(
  TITLE = "LGA MODEL",
  MODEL = "i s | ALC1YR1@0 ALC1YR2@1 ALC1YR3@2;",
  OUTPUT = "SAMPSTAT standardized;",
  PLOT = "SERIES = ALC1YR1 ALC1YR2 ALC1YR3 (s);
	        TYPE = PLOT3;",
  rdata = data,
  usevariables = c("ALC1YR1", "ALC1YR2", "ALC1YR3"), 
  modelout = "m0.inp",
  run = 1L)

# Missing data patterns:
get_data_summary(m0)
# Fit
SummaryTable(m0, keepCols = c("Filename", "Parameters", "ChiSqM_Value", "ChiSqM_DF", 
"ChiSqM_PValue", "LL", "CFI", "TLI", "RMSEA_Estimate", "SRMR"))
# Parameters
tab <- tidySEM::table_results(m0, columns = NULL)
tab[tab$paramheader == "Means", c("label", "est_sig", "pval")]
```

The model fit should be very good, with non-significant chi-square, and good fit according to CFL/TLI. The intercept and slope means indicate 
a relatively high starting point (3.68) and a growth of 0.92 per year. The Intercept and Slope 
show considerable variance, indicating that the starting points and rates of growth differ 
considerably across individuals.

`r if(knitr::is_html_output()){"\\details"}`

### Exercise 2b

We will now *explore* how different predictor variables affect the model fit. 
Include gender and age in the model as predictors of the intercept and slope. Interpret the fit of the model 
and the output. 
Feel free to estimate several models, including or excluding certain covariates.
Either make a model fit table by hand in a spreadsheet, or use `SummaryTable()` to request the fit indices you deem to be appropriate.
Which model do you consider to be best?

#### Exploratory vs confirmatory research

Note that when you conduct *confirmatory* research, and are testing theoretical hypotheses, you should not add and omit paths based on exploratory analyses and model fit.

It is fine to add and remove paths in *exploratory* research. Model fit indices, like AIC and BIC, are suitable for selecting well-fitting models in exploratory research. P-values are not designed for variable selection, and using them for that purpose may lead to suboptimal models.

It is good scientific practice to clearly separate confirmatory and exploratory research. When you conduct exploratory research, you should not perform inference on the resulting parameters based on p-values (because inference generalizes your findings to the population, and exploratory findings tend to be tailored toward this specific sample).
You should also not present exploratory results as if they were testing a post-hoc theory ("Hypothesizing After the Results are Known", or HARKing, is a questionable research practice and can lead to false-positive (spurious) findings.

<details>
  <summary><b>Click to show answers</b></summary>

The answers to Exercise 1a demonstrate how to approach this.
Estimate multiple slightly different models, put them in a list, and run `SummaryTable()`.
Then use the AIC and BIC to identify the best-fitting model,
and assess how different the model fits are.
Also consider using RMSEA, CFI, TLI, and SRMR to make sure that your best-fitting
model has acceptable objective fit.

```{r}
# Create a vector with three "additional syntaxes"
# for my three different models
mod = c("i s ON GENDER1;",
        "i s ON AGE1;",
        "i s ON AGE1 GENDER1;",
        "i ON GENDER1;",
        "i ON AGE1;",
        "i ON AGE1 GENDER1;",
        "s ON GENDER1;",
        "s ON AGE1;",
        "s ON AGE1 GENDER1;",
        "i WITH s@0;",
        "!baseline")
# Create a list with the additional usevariables
# used in the three models above
vars = list("GENDER1",
            "AGE1",
            c("GENDER1", "AGE1"),
            "GENDER1",
            "AGE1",
            c("GENDER1", "AGE1"),
            "GENDER1",
            "AGE1",
            c("GENDER1", "AGE1"),
            NULL,
            NULL)
# Make a list of exploratory models by modifying m0
models <- lapply(1:length(mod), function(i){
  # append element i of mod
  m0$MODEL <- paste0(m0$MODEL, mod[i]) 
  # append element i of vars
  m0$usevariables <- c(m0$usevariables, vars[[i]])
  # Add unique filename
  m0$modelout = paste0("Model", i, ".inp") 
  # return the modified model
  m0 
})
# Run all models and store results in a list called results
results <- lapply(models, mplusModeler, run = 1L)
# Get summary table and store it in 'tab'
tab <- SummaryTable(results, 
                    keepCols = c("Parameters", "AIC", "BIC",
                                 "RMSEA_Estimate", "CFI",
                                 "TLI", "SRMR"),
                    sortBy = NULL)
# Order by BIC
tab <- tab[order(tab$BIC), ]
# Add model syntax to the table
tab <- cbind(Model = mod, tab)
tab
```
```{r 2b_make_table_hidden, echo = FALSE, results = "asis"}
row.names(tab) <- NULL
kbl(tab, digits = 2)
```

```{r}
# Plot the BICs and annotate with the syntax to see which is best
library(ggplot2)
qplot(x = 1:11, y = tab$BIC) +
  geom_line() +
  geom_text(label = tab$Model, size = 2)

```

It looks like, paradoxically, predicting I and S from either age or gender
has the best fit. However, note that there is only a small difference between
the smallest and the largest BIC: `r diff(range(tab$BIC))`.
I would either go for the simplest model (i WITH s@0), or go for the
best-fitting model (i s ON GENDER1).

Note that the covariance 
between intercept and slope disappears from the model when you add predictors, as 
this turns it into a covariance 
between a latent variable and a residual. Mplus automatically constrains these to zero.
If we add  the statement I WITH S to the model, we obtain a good fit with significant effects of both gender and age on the intercept. 
NOTE: This illustrates the importance of checking the output carefully to find out if Mplus is 
actually doing what you think it does! 

`r if(knitr::is_html_output()){"\\details"}`

### Exercise 2c

Include alcohol problems in year 5 in the model: let the intercept and slope factors predict alcohol problems year 5. Declare the variable as categorical in the variable section (CATEGORICAL = ALCPROB5). 
Inspect if the effect of age and gender on alcohol problems year 5 is completely mediated by the growth 
factors, or if there are additional direct paths from age and gender on the alcohol problems. 


<details>
  <summary><b>Click to show answers</b></summary>
  
The model fit is still good. Note that after adding a categorical dependent variable to the
model, Mplus switches to a robust estimator (MLR). Both intercept and slope predict alcohol problems. Age also predicts alcohol problems directly. Since age 
predicts alcohol problems both directly and via the intercept, a mediation analysis is in 
order. This shows that the indirect effect of age via the intercept on alcohol problems is still 
significant when the direct effect is added to the model.

To test whether there is full mediation or not, we may want to test whether the direct
effects are equal to zero or not.

If the analysis had not included a categorical dependent variable,
then we would have been able to compute the difference test using the `tidySEM`
function `chisq_sb(SummaryTable(keepCols = NULL))`.

However, in the presence of a categorical dependent variable, we must use Mplus'
option `difftest`.

Again, we can start from m0:

```{r}
# Specify model with only indirect effects
m2c_indirect <- m0
m2c_indirect$usevariables <- c(
  m2c_indirect$usevariables,
  "AGE1", "GENDER1", "ALCPROB5")
m2c_indirect$VARIABLE <- "CATEGORICAL = ALCPROB5;"
m2c_indirect$MODEL <- paste0(
  m0$MODEL,
  "i on AGE1 GENDER1;
  i WITH s;
  ALCPROB5 on i s;
  ALCPROB5 on AGE1 GENDER1;")
m2c_indirect$SAVEDATA <- "difftest is mediation.dat;"
m2c_indirect$modelout <- "m2c_indirect.inp"
# Run all models and store results in a list called results
result_ind <- mplusModeler(m2c_indirect, run = 1L)

# Specify model with direct effects too
m2c_direct <- m2c_indirect
# Constrain direct effects to 0 using gsub (replace)
m2c_direct$MODEL <- gsub("ALCPROB5 on AGE1 GENDER1;",
                         "ALCPROB5 on AGE1 GENDER1@0;",
                         m2c_direct$MODEL,
                         fixed = TRUE)
m2c_direct$ANALYSIS <- "difftest = mediation.dat;" 
m2c_direct$modelout <- "m2c_direct.inp"
# Run the direct model, which includes the difference test
result_dir <- mplusModeler(m2c_direct, run = 1L)
# Look at the model summaries
get_summaries(result_dir)
```
```{r 2c_make_table_hidden, echo = FALSE, results='markup'}
get_summaries(result_dir)
# kable_styling(knitr::kable(get_summaries(result_dir), digits = 2, format = "html"), latex_options = c("striped", "scale_down"))
```

Note that the ChiSqDiffTest_PValue is non-significant, which means we can
prefer the simpler (no direct effects) model. There is full mediation.

Let's use a graph to examine the unconstrained model too:

```{r}
lo <- get_layout("AGE1",    "", "",
                 "",        "I",  "ALCPROB5",
                 "GENDER1", "", "", rows = 3)
graph_sem(result_ind, layout = lo)
```

`r if(knitr::is_html_output()){"\\details"}`

## Exercise 3: Level and Shape Parameterization 

The file GPA.dat holds the GPA data (GPA = grade point average) with GPA scores of 200 students in 6 consecutive 
semesters. There are also time-invariant covariates: high school GPA and gender; and the outcome variable: 
admitted to university of choice (missing if not applied for university). Use the GPA data to set up a level and shape 
model.

First, load the data and name the variables:

```{r read_datagpa, echo = TRUE, eval = TRUE}
data <- read.table("GPA.dat")
names(data) <- c("STUDENT", "SEX", "HIGHGPA",
                 "GPA1", "GPA2", "GPA3", "GPA4", "GPA5", "GPA6")
```

### Exercise 3a

Use a parameterization with GPA1@0 and GPA6@1. The loadings for the other timepoints should be freely estimated. This can 
be done with, for example, the syntax GPA2* as shown in the handout.  
Interpret the factor loadings and estimate for S.  

<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows:

```{r}
m3 <- mplusObject(
  MODEL = "i s | gpa1@0 gpa2* gpa3* gpa4* gpa5* gpa6@1;",
  rdata = data,
  usevariables = c("GPA1", "GPA2", "GPA3", "GPA4", "GPA5", "GPA6"),
  modelout = "m3.inp"
)

res <- mplusModeler(m3, run = 1L)

# Get all columns of results
tab <- table_results(res, columns = NULL)
# Retain factor loadings and intercepts using op %in% c("=~", "~1") 
# for all parameters involving S (lhs == "S")
tab <- tab[tab$lhs == "S" & tab$op %in% c("=~", "~1"), ]
tab[, c("label", "est_sig", "pval", "confint")]
```
The factor loading indicates the proportion of change from the starting time point to the 
current one. Thus, 24% of the total change occurs between GPA1 and GPA2. Mean S = 0.55. This indicates the total change between GPA1 and GPA6. The intercept at GPA1 = 2.575. So the 
estimated score at GPA2 = 2.575 + 0.239*0.549 = 2.706, the estimated score at GPA3 = 
2.575 + 0.450*0.549 = 2.822, etcetera.  

```{r, echo = FALSE, results = "asis"}
row.names(tab) <- NULL
kbl(tab[, c("label", "est_sig", "pval", "confint")], digits = 2)
```

`r if(knitr::is_html_output()){"\\details"}`

### Exercise 3b

Now use a parameterization with GPA1@0 and GPA2@1. The other GPA’s should be freely estimated. 
Interpret the factor loadings and estimate for S.  

<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows:

```{r}
m3b <- m3 
m3b$MODEL <- "i s | gpa1@0 gpa2@1 gpa3* gpa4* gpa5* gpa6*;"

res_3b <- mplusModeler(m3b, run = 1L)

# Get all columns of results
tab <- table_results(res_3b, columns = NULL)
# Retain factor loadings and intercepts using op %in% c("=~", "~1") 
# for all parameters involving S (lhs == "S")
tab <- tab[tab$lhs == "S" & tab$op %in% c("=~", "~1"), ]
tab[, c("label", "est_sig", "pval", "confint")]
```

Mean S now indicates the difference between GPA1 and GPA2. The estimated factor loadings 
indicate the distance in units from the starting point, where 1 unit is S. You could also say 
that every distance compares to the increase between GPA1 and GPA2.  

```{r, echo = FALSE, results = "asis"}
row.names(tab) <- NULL
kbl(tab[, c("label", "est_sig", "pval", "confint")])
```

`r if(knitr::is_html_output()){"\\details"}`

Which parameterization do you like best?

### Exercise 3c

Draw the development of GPA over time based on your own calculations (by hand).
Compare this to the estimated means plot that you can get with the plot command: 
PLOT: SERIES = GPA1-GPA6 (s); 
TYPE = PLOT3;  
However, don’t forget that you need to ‘rescale’ that plot, since S is linear while the location of the 
estimated points is based on the factor loadings.

<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows. Note that you will have to load the plot in Mplus:

```{r}
m3b$PLOT <- "SERIES = GPA1-GPA6 (s);
             TYPE = PLOT3;"

res_3b <- mplusModeler(m3b, run = 1L)
```
`r if(knitr::is_html_output()){"\\details"}`

### Exercise 3d

Use sex as a predictor of the intercept and slope and interpret the result (with 0 = boys, 1 = girls). 


<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows:

```{r}
m3_sex <- m3
# Make 0 = boys and 1 = girls
m3_sex$rdata$SEX <- m3_sex$rdata$SEX - 1
m3_sex$usevariables <- c(m3_sex$usevariables, "SEX")
m3_sex$MODEL <- paste0(m3_sex$MODEL, "i s on sex;")
res_3sex <- mplusModeler(m3_sex, run = 1L)
# Get all columns of results
tab <- table_results(res_3sex, columns = NULL)
# Retain only regressions on I and S
tab <- tab[tab$lhs %in% c("I", "S") & tab$op == "~", ]
tab[, c("label", "est_sig", "pval", "confint")]
```

```{r, echo = FALSE, results = "asis"}
row.names(tab) <- NULL
kbl(tab[, c("label", "est_sig", "pval", "confint")])
```

Sex is a significant predictor of the intercept and a significant 
predictor of development, with girls having a higher initial level, and a greater 
development over time.  

`r if(knitr::is_html_output()){"\\details"}`

## Exercise 4: latent growth model on GPA data 

### Exercise 4a 

Continuing with the data used for the previous exercise, set up a latent growth model for GPA for the 6 consecutive occasions and run this model. Obtain the following parameters:

* AIC/BIC, Chi Square, RMSEA, CFI/TLI 
* Mean Intercept and Slope
* Variance of the Intercept and Slope


<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows, using m3 as starting point:

```{r}
m4 <- m3
m4$MODEL <- "i s | gpa1@0 gpa2@1 gpa3@2 gpa4@3 gpa5@4 gpa6@5;"
m4$modelout <- "m4.inp"
res_4 <- mplusModeler(m4, run = 1L)
# Get the requested fit indices:
get_summaries(res_4)[c("AIC", "BIC", "ChiSqM_Value",
                       "RMSEA_Estimate", "CFI", "TLI")]
# Get all columns of results
tab <- table_results(res_4, columns = NULL)
# Retain only regressions on I and S
tab <- tab[tab$lhs %in% c("I", "S") & tab$op %in% c("~~", "~1"), ]
tab[, c("label", "est_sig", "pval", "confint")]
```

```{r, echo = FALSE, results = "asis"}
invisible({
  m4 <- m3
m4$MODEL <- "i s | gpa1@0 gpa2@1 gpa3@2 gpa4@3 gpa5@4 gpa6@5;"
m4$modelout <- "m4.inp"
res_4 <- mplusModeler(m4, run = 1L)
# Get the requested fit indices:
})
get_summaries(res_4)[c("AIC", "BIC", "ChiSqM_Value",
                       "RMSEA_Estimate", "CFI", "TLI")]
# Get all columns of results
tab <- table_results(res_4, columns = NULL)
# Retain only regressions on I and S
tab <- tab[tab$lhs %in% c("I", "S") & tab$op %in% c("~~", "~1"), ]
row.names(tab) <- NULL
kbl(tab[, c("label", "est_sig", "pval", "confint")])
```

`r if(knitr::is_html_output()){"\\details"}`

### Exercise 4b

Then, set up a latent growth model for 3 years where each year is a latent variable measured by the GPA of two 
consecutive semesters. 

The factor loadings for GPA2, GPA4 and GPA6 ought to be constrained to be equal with a label (a) behind 
the loading in the syntax. As such, the scores relate in the same way to the year score over time. The GPA 
intercepts are constrained at 0.  

If you get the error message below, can you find out what the problem is?  

```
WARNING:  THE LATENT VARIABLE COVARIANCE MATRIX (PSI) IS NOT POSITIVE     DEFINITE. THIS 
COULD INDICATE A NEGATIVE VARIANCE/RESIDUAL VARIANCE FOR A LATENT VARIABLE, A CORRELATION 
GREATER OR EQUAL TO ONE BETWEEN TWO LATENT VARIABLES, OR A LINEAR DEPENDENCY AMONG MORE 
THAN TWO LATENT VARIABLES. CHECK THE TECH4 OUTPUT FOR MORE INFORMATION. 
```

A rough way to deal with this problem may be to fix the problematic parameter to a particular value (ie. .001), try this and re-run the model.  

Now examine the same parameters as for exercise 4a, and compare the two. Are there 
major differences? 

* AIC/BIC, Chi Square, RMSEA, CFI/TLI 
* Mean Intercept and Slope
* Variance of the Intercept and Slope

<details>
  <summary><b>Click to show answers</b></summary>

This can be done as follows, using m4 as starting point:

```{r}
m4b <- m4
m4b$MODEL <- "year1 by gpa1@1 gpa2 (a);
             year2 by gpa3@1 gpa4 (a); 
             year3 by gpa5@1 gpa6 (a);
             [gpa1@0 gpa2@0 gpa3@0 gpa4@0 gpa5@0 gpa6@0];
             i s | year1@0 year2@1 year3@2;
             [i s];
             year3@.001;"
res_4b <- mplusModeler(m4b, run = 1L)
# Get the requested fit indices:
get_summaries(res_4b)[c("AIC", "BIC", "ChiSqM_Value",
                        "RMSEA_Estimate", "CFI", "TLI")]
# Get all columns of results
tab <- table_results(res_4b, columns = NULL)
# Retain only regressions on I and S
tab <- tab[tab$lhs %in% c("I", "S") & tab$op %in% c("~~", "~1"), ]
tab[, c("label", "est_sig", "pval", "confint")]
```

Note that, without `year3@.001`, this code gives an error message: The variance of the latent variable year3 is 
estimated negatively which is problematic since variances should always be positive. A 
simple way to deal with the problem of the latent variance of year3 is to fix it to a very small 
value (.001) for instance, as it would also be illogical to fix a variance to 0. To do this, simply 
add this to your input file under model: year3@.001; 

```{r, echo = FALSE, results = "asis"}
suppressMessages(invisible({
m4b <- m4
m4b$MODEL <- "year1 by gpa1@1 gpa2 (a);
             year2 by gpa3@1 gpa4 (a); 
             year3 by gpa5@1 gpa6 (a);
             [gpa1@0 gpa2@0 gpa3@0 gpa4@0 gpa5@0 gpa6@0];
             i s | year1@0 year2@1 year3@2;
             [i s];
             year3@.001;"
res_4b <- mplusModeler(m4b, run = 1L)
# Get the requested fit indices:

}))
get_summaries(res_4b)[c("AIC", "BIC", "ChiSqM_Value", "RMSEA_Estimate", "CFI", "TLI")]
# Get all columns of results
tab <- table_results(res_4b, columns = NULL)
# Retain only regressions on I and S
tab <- tab[tab$lhs %in% c("I", "S") & tab$op %in% c("~~", "~1"), ]
row.names(tab) <- NULL
kbl(tab[, c("label", "est_sig", "pval", "confint")])
```

Compare the estimates from the two models. Are there major differences? 
If you inspect the output carefully (and provided you have requested standardized 
estimates) you will notice that the latent variables year2 and year3 have a correlation of 1. 
So the negative variance is the result of a multicollinearity problem. It is apparently better to 
analyze these data using only the observed variables gpa1-gpa6. Creating latent variables 
per year does not work well. 
In line with this interpretation, the fit and results of the simple latent growth model look better than the 2nd order latent growth curve model.

`r if(knitr::is_html_output()){"\\details"}`
